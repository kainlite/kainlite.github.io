{
  "version": "https://jsonfeed.org/version/1",
  "title": "Kubernetes, CI/CD, Git, Linux, Containers, Golang... and more",
  "home_page_url": "https://legacy.techsquad.rocks/",
  "feed_url": "https://legacy.techsquad.rocks/index.json",
  "items": [
    
    {
      "id": "https://legacy.techsquad.rocks/blog/legacy/",
      "url": "https://legacy.techsquad.rocks/blog/legacy/",
      "title": "Legacy",
      "date_published": "2024-03-17T00:00:00Z",
      "tags": null,
      "content_html": "\u003ch3 id=\"important\"\u003eImportant\u003c/h3\u003e\n\u003cp\u003eThis blog is no longer maintained, if you want to keep reading or find new content, head out to the new site:\n\u003ca href=\"https://techsquad.rocks/blog\"\u003ehttps://techsquad.rocks/blog\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/testing_tekton_to_build_and_push_images_for_my_k3s_arm_oracle_cluster/",
      "url": "https://legacy.techsquad.rocks/blog/testing_tekton_to_build_and_push_images_for_my_k3s_arm_oracle_cluster/",
      "title": "Testing tekton to build and push images for my K3S ARM Oracle cluster",
      "date_published": "2022-10-25T00:00:00Z",
      "tags": ["kubernetes","arm","linux","cicd","tekton"],
      "content_html": "\u003ch4 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIn this article we will explore how to deploy and configure tekton to build and push images to your registry to be\nconsumed from your cluster, we will also see how these are deployed in another article. In this one I want to show you\nhow to get the images ready to use, and also a handy solution for a CI system without having to rely on external\nfactors, in my case I was having issues with docker building cross-architecture images and after setting up tekton\neverything was faster and simpler, cross-architecture is slow by default but can also not work a 100% as you would\nexpect, by using this approach we can just forget about the architecture and just build where we run things, it is\ndefinitely faster and even some of your nodes will already have the images available meaning less bandwidth consumption\nas well in the long run.\u003c/p\u003e\n\u003ch5 id=\"sources\"\u003e\u003cstrong\u003eSources\u003c/strong\u003e\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kainlite/tr\"\u003etr\u003c/a\u003e, go ahead and check it out, my new blog runs there: \u003ca href=\"https://tr.techsquad.rocks\"\u003ehttps://tr.techsquad.rocks\u003c/a\u003e\nyou can check the manifests used here in the \u003ccode\u003emanifests\u003c/code\u003e folder.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe source code and/or documentation of the projects that we will be testing are listed here:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://tekton.dev/docs/\"\u003etekton\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://tekton.dev/docs/triggers/\"\u003etekton-triggers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/GoogleContainerTools/kaniko\"\u003ekaniko\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"installing-tekton-pipelines-and-tekton-triggers\"\u003eInstalling tekton-pipelines and tekton-triggers\u003c/h4\u003e\n\u003cp\u003eWhy do we need tekton-pipelines or tekton-triggers again? pipelines allows you to run multiple tasks in order and pass\nthings around (this is basic to tekton and to any CI/CD system), then we need to do something when we push for example\nto our git repository, that\u0026rsquo;s when tekton-triggers gets handy and let us react to changes and trigger a build or some\nprocess, interceptors are a part of tekton-triggers and let\u0026rsquo;s say it gives you flexibility using events.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ekubectl apply --filename https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml\nkubectl apply --filename https://storage.googleapis.com/tekton-releases/triggers/latest/release.yaml\nkubectl apply --filename https://storage.googleapis.com/tekton-releases/triggers/latest/interceptors.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen we need to install \u003ccode\u003etkn\u003c/code\u003e locally and configure some packages from the hub\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etkn -n tekton-pipelines hub install task git-clone\ntkn -n tekton-pipelines hub install task kaniko\ntkn -n tekton-pipelines hub install task kubernetes-actions\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn my deployment I used fixed versions which is recommended for any kind of \u0026ldquo;production\u0026rdquo; deployment, you can see the\nreadme \u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/README.md\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 id=\"lets-get-to-business\"\u003eLet\u0026rsquo;s get to business\u003c/h4\u003e\n\u003ch5 id=\"tekton-pipelines\"\u003etekton-pipelines\u003c/h5\u003e\n\u003cp\u003eOkay, so we have tekton and friends installed, ready for business, but what now? well, it\u0026rsquo;s a bit tricky and require a\nfew manifests to get going, so I will try to explain what is happening with each file and why do we need them.\u003c/p\u003e\n\u003cp\u003eYou can see this file in github as well\n\u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/pipelines/01-pipeline.yaml\"\u003e01-pipeline.yaml\u003c/a\u003e,\nbasically we need to define a pipeline which defines the steps and what it will happen, here we are cloning the\nrepository, then building it with kaniko and then pushing it to the docker registry, note that the script is hardcoded\nthere that could be dynamic but not really necessary for my use case.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: tekton.dev/v1beta1\nkind: Pipeline\nmetadata:\n  name: clone-build-push\n  namespace: tekton-pipelines\nspec:\n  description: | \n    This pipeline clones a git repo, builds a Docker image with Kaniko and\n    pushes it to a registry\n  params:\n  - name: repo-url\n    type: string\n  - name: image-reference\n    type: string\n  workspaces:\n  - name: shared-data\n  - name: docker-credentials\n  tasks:\n  - name: fetch-source\n    taskRef:\n      name: git-clone\n    workspaces:\n    - name: output\n      workspace: shared-data\n    params:\n    - name: url\n      value: $(params.repo-url)\n  - name: build-push\n    runAfter: [\u0026quot;fetch-source\u0026quot;]\n    taskRef:\n      name: kaniko\n    workspaces:\n    - name: source\n      workspace: shared-data\n    - name: dockerconfig\n      workspace: docker-credentials\n    params:\n    - name: IMAGE\n      value: $(params.image-reference)\n  - name: restart-deployment\n    runAfter: [\u0026quot;build-push\u0026quot;]\n    taskRef:\n      name: kubernetes-actions\n    params:\n    - name: script\n      value: |\n        kubectl -n tr rollout restart deployment/tr-deployment\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eYou can see this file in github as well\n\u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/pipelines/02-pipeline-run.yaml\"\u003e02-pipeline-run.yaml\u003c/a\u003e,\nThis is basically to run our defined pipeline with specific values, we will use something very similar from the trigger\nto run automatically when we push commits to our repo, the docker secret is a regular dockercfg secret mounted so we can\npush to that registry.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: tekton.dev/v1beta1\nkind: PipelineRun\nmetadata:\n  name: clone-build-push-run\n  namespace: tekton-pipelines\nspec:\n  pipelineRef:\n    name: clone-build-push\n  podTemplate:\n    securityContext:\n      fsGroup: 65532\n  workspaces:\n  - name: shared-data\n    volumeClaimTemplate:\n      spec:\n        accessModes:\n        - ReadWriteOnce\n        resources:\n          requests:\n            storage: 1Gi\n  - name: kubeconfig-dir\n    configMap:\n      name: kubeconfig\n  - name: docker-credentials\n    secret:\n      secretName: docker-credentials\n  params:\n  - name: repo-url\n    value: https://github.com/kainlite/tr.git\n  - name: image-reference\n    value: kainlite/tr:latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith all that we have a basic pipeline but we need to trigger it or run it manually, let\u0026rsquo;s add the necessary manifests\nfor it to react to changes in our github repository\u0026hellip;\u003c/p\u003e\n\u003chr\u003e\n\u003ch5 id=\"tekton-triggers\"\u003etekton-triggers\u003c/h5\u003e\n\u003cp\u003eYou can see this file in github as well \u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/triggers/01-rbac.yaml\"\u003e01-rbac.yaml\u003c/a\u003e,\nlet\u0026rsquo;s give tekton-triggers some permissions\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: tekton-triggers-sa\n  namespace: tekton-pipelines\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: tekton-triggers-minimal\n  namespace: tekton-pipelines\nrules:\n# EventListeners need to be able to fetch all namespaced resources\n- apiGroups: [\u0026quot;triggers.tekton.dev\u0026quot;]\n  resources: [\u0026quot;eventlisteners\u0026quot;, \u0026quot;triggerbindings\u0026quot;, \u0026quot;triggertemplates\u0026quot;, \u0026quot;triggers\u0026quot;]\n  verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;]\n- apiGroups: [\u0026quot;\u0026quot;]\n# configmaps is needed for updating logging config\n  resources: [\u0026quot;configmaps\u0026quot;]\n  verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;]\n# Permissions to create resources in associated TriggerTemplates\n- apiGroups: [\u0026quot;tekton.dev\u0026quot;]\n  resources: [\u0026quot;pipelineruns\u0026quot;, \u0026quot;pipelineresources\u0026quot;, \u0026quot;taskruns\u0026quot;]\n  verbs: [\u0026quot;create\u0026quot;]\n- apiGroups: [\u0026quot;\u0026quot;]\n  resources: [\u0026quot;serviceaccounts\u0026quot;]\n  verbs: [\u0026quot;impersonate\u0026quot;]\n- apiGroups: [\u0026quot;policy\u0026quot;]\n  resources: [\u0026quot;podsecuritypolicies\u0026quot;]\n  resourceNames: [\u0026quot;tekton-triggers\u0026quot;]\n  verbs: [\u0026quot;use\u0026quot;]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: tekton-triggers-binding\n  namespace: tekton-pipelines\nsubjects:\n- kind: ServiceAccount\n  name: tekton-triggers-sa\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: tekton-triggers-minimal\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: tekton-triggers-clusterrole\nrules:\n  # EventListeners need to be able to fetch any clustertriggerbindings\n- apiGroups: [\u0026quot;triggers.tekton.dev\u0026quot;]\n  resources: [\u0026quot;clustertriggerbindings\u0026quot;, \u0026quot;clusterinterceptors\u0026quot;]\n  verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: tekton-triggers-clusterbinding\nsubjects:\n- kind: ServiceAccount\n  name: tekton-triggers-sa\n  namespace: tekton-pipelines\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: tekton-triggers-clusterrole\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eYou can see this file on github as well\n\u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/triggers/02-eventlistener.yaml\"\u003e02-eventlistener.yaml\u003c/a\u003e,\nThis is where things get a bit tricky, in theory you don\u0026rsquo;t need a secret to read your repo if it is public, but it was\nprivate when I started testing this, then it was made public, if you are interested  in the format of the secret check\nbelow this yaml, however this only \u0026ldquo;listens\u0026rdquo; to events in our repo and triggers an event using our pipeline, we still\nneed an ingress for the webhook and other configs as we will see in the next steps.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eapiVersion: triggers.tekton.dev/v1alpha1\nkind: EventListener\nmetadata:\n  name: clone-build-push\n  namespace: tekton-pipelines\nspec:\n  serviceAccountName: tekton-triggers-sa\n  triggers:\n    - name: github-listener\n      interceptors:\n        - ref:\n            name: \u0026quot;github\u0026quot;\n          params:\n            - name: \u0026quot;secretRef\u0026quot;\n              value:\n                secretName: github-interceptor-secret\n                secretKey: secretToken\n            - name: \u0026quot;eventTypes\u0026quot;\n              value: [\u0026quot;push\u0026quot;]\n        - ref:\n            name: \u0026quot;cel\u0026quot;\n      bindings:\n        - ref: clone-build-push-binding\n      template:\n        ref: clone-build-push-template\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe secret would be something like the one depicted below, replace \u003ccode\u003esecretToken\u003c/code\u003e with your generated token this will be\nused for the webhook configuration so save it somewhere safe until it is configured there.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: v1\nkind: Secret\nmetadata:\n  name: github-interceptor-secret\ntype: Opaque\nstringData:\n  secretToken: \u0026quot;1234567\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eYou can see this file on github as well\n\u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/triggers/04-triggerbinding.yaml\"\u003e04-triggerbinding.yaml\u003c/a\u003e,\nWhen we receive the webhook we can get some information from it, basically we are interested in the repo URL and the\ncommit SHA.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: triggers.tekton.dev/v1alpha1\nkind: TriggerBinding\nmetadata:\n  name: clone-build-push-binding\n  namespace: tekton-pipelines\nspec:\n  params:\n    - name: gitrepositoryurl\n      value: $(body.repository.clone_url)\n    - name: gitrevision\n      value: $(body.pull_request.head.sha)\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eYou can see this file in github as well\n\u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/triggers/05-triggertemplate.yaml\"\u003e05-triggertemplate.yaml\u003c/a\u003e,\nThis would be the equivalent of the manually run pipelinerun that we have, but this uses the trigger and the template to\nautomatically trigger, hence the similarities.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: triggers.tekton.dev/v1alpha1\nkind: TriggerTemplate\nmetadata:\n  name: clone-build-push-template\n  namespace: tekton-pipelines\nspec:\n  params:\n    - name: gitrevision\n      description: The git revision (SHA)\n      default: master\n    - name: gitrepositoryurl\n      description: The git repository url (\u0026quot;https://github.com/foo/bar.git\u0026quot;)\n  resourcetemplates:\n    - apiVersion: tekton.dev/v1beta1\n      metadata:\n        namespace: tekton-pipelines\n        generateName: clone-build-push-\n      spec:\n        pipelineRef:\n          name: clone-build-push\n        podTemplate:\n          securityContext:\n            fsGroup: 65532\n        workspaces:\n        - name: shared-data\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 1Gi\n        - name: kubeconfig-dir\n          configMap:\n            name: kubeconfig\n        - name: docker-credentials\n          secret:\n            secretName: docker-credentials\n        params:\n        - name: repo-url\n          value: https://github.com/kainlite/tr.git\n        - name: image-reference\n          value: kainlite/tr:$(tt.params.gitrevision)\n      kind: PipelineRun\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eYou can see this file on github as well\n\u003ca href=\"https://github.com/kainlite/tr/blob/master/manifests/tekton/triggers/06-ingress.yaml\"\u003e06-ingress.yaml\u003c/a\u003e,\nAnd last but not least the ingress configuration, without this it won\u0026rsquo;t work because we need to receive a request from\ngithub, to configure that just go to settings on the repository, hit webhooks and create a new one with the secret token\nthat you generated and put your URL as \u003ccode\u003ehttps://subdomain.domain/hooks\u003c/code\u003e, then mark TLS on, only push and active.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: tr-ingress\n  namespace: tekton-pipelines\n  annotations:\n    kubernetes.io/ingress.class: \u0026quot;nginx\u0026quot;\n    nginx.ingress.kubernetes.io/rewrite-target: \u0026quot;/\u0026quot;\n    cert-manager.io/cluster-issuer: \u0026quot;letsencrypt-prod\u0026quot;\n    nginx.ingress.kubernetes.io/ssl-redirect: \u0026quot;true\u0026quot;\n    service.beta.kubernetes.io/do-loadbalancer-enable-proxy-protocol: \u0026quot;true\u0026quot;\n    use-proxy-protocol: \u0026quot;true\u0026quot;\nspec:\n  tls:\n  - hosts:\n      - trgh.techsquad.rocks\n    secretName: tr-prod-tls\n  rules:\n    - host: trgh.techsquad.rocks\n      http:\n        paths:\n          - path: /hooks\n            pathType: Exact\n            backend:\n              service:\n                name: el-clone-build-push\n                port:\n                  number: 8080\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWHEW! that was a lot of work but trust me it\u0026rsquo;s worth it, now you can build, push and run your images from your cluster,\nwith no external or weird CI/CD system and everything following a GitOps model since everything can be committed and\napplied from your repository, in my case I\u0026rsquo;m using ArgoCD and Kustomize to apply everything but that is for another\nchapter.\u003c/p\u003e\n\u003chr\u003e\n\u003ch4 id=\"then-lets-validate-that-it-works\"\u003eThen let\u0026rsquo;s validate that it works\u003c/h4\u003e\n\u003cp\u003eWe have the event listener ready:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e‚ùØ tkn -n tekton-pipelines eventlistener list\nNAME               AGE           URL                                                                  AVAILABLE\nclone-build-push   5 seconds ago   http://el-clone-build-push.tekton-pipelines.svc.cluster.local:8080   True\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe have the pipeline, notice that it says failed this is because there is an issue with ARM that it is still not solved\nbut everything actually works as expected:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e‚ùØ tkn -n tekton-pipelines pipeline list\nNAME               AGE           LAST RUN                 STARTED       DURATION   STATUS\nclone-build-push   5 seconds ago   clone-build-push-5qkv6   5 weeks ago   4m26s      Failed\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can see the pipelinerun being triggered, same issue as described before, see the notes for the github issues:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e‚ùØ tkn -n tekton-pipelines pipelinerun list\nNAME                           STARTED       DURATION   STATUS\nclone-build-push-5qkv6         5 seconds ago   4m26s      Failed\nclone-build-push-blkrm         5 seconds ago   3m58s      Failed\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can also see some of the other resources created for tekton:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e‚ùØ tkn -n tekton-pipelines triggertemplate list\nNAME                          AGE\nclone-build-push-template     5 seconds ago\n\n‚ùØ tkn -n tekton-pipelines triggertemplate describe clone-build-push-template\nName:        clone-build-push-template\nNamespace:   tekton-pipelines\n\n‚öì Params\n\n NAME                 DESCRIPTION              DEFAULT VALUE\n ‚àô gitrevision        The git revision (S...   master\n ‚àô gitrepositoryurl   The git repository ...   ---\n\nüì¶ ResourceTemplates\n\n NAME    GENERATENAME        KIND          APIVERSION\n ‚àô ---   clone-build-push-   PipelineRun   tekton.dev/v1beta1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can also see the pods created or logs using either \u003ccode\u003ekubectl\u003c/code\u003e or \u003ccode\u003etkn\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003etekton-pipelines   clone-build-push-vt6jz-fetch-source-pod                  0/1     Completed   0             1d\ntekton-pipelines   clone-build-push-wzlkb-build-push-pod                    0/2     Completed   0             1d\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI hope this is useful for someone and if you are having issues with your CI/CD system give tekton a go, you will love\nit, in my particular case I was having many issues with ARM and building for it, it was slow, had a ton of weird errors\nand all that went away by building the images where I run things, it\u0026rsquo;s faster and it also utilizes the idle computing\npower.\u003c/p\u003e\n\u003ch4 id=\"some-of-the-sources-and-known-issues\"\u003eSome of the sources and known issues\u003c/h4\u003e\n\u003cp\u003eThis post was heavily insipired by these articles, and it was configured and tested following these examples:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/tektoncd/triggers/blob/main/docs/getting-started/README.md\"\u003ehttps://github.com/tektoncd/triggers/blob/main/docs/getting-started/README.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://tekton.dev/docs/how-to-guides/kaniko-build-push/#full-code-samples\"\u003ehttps://tekton.dev/docs/how-to-guides/kaniko-build-push/#full-code-samples\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.arthurkoziel.com/tutorial-tekton-triggers-with-github-integration/\"\u003ehttps://www.arthurkoziel.com/tutorial-tekton-triggers-with-github-integration/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThere are some issues running on ARM, on other architectures it just works, see more:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/tektoncd/pipeline/issues/4247\"\u003ehttps://github.com/tektoncd/pipeline/issues/4247\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/tektoncd/pipeline/issues/5233\"\u003ehttps://github.com/tektoncd/pipeline/issues/5233\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eBut everything should just work tm.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e\nand the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e.\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/rust_on_arm32v7_via_qemu/",
      "url": "https://legacy.techsquad.rocks/blog/rust_on_arm32v7_via_qemu/",
      "title": "Running Rust on ARM32v7 via QEMU.",
      "date_published": "2022-09-03T00:00:00Z",
      "tags": ["rust","arm"],
      "content_html": "\u003ch4 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIn this article we will explore how to use \u003ca href=\"https://www.qemu.org/download/#linux\"\u003eQEMU\u003c/a\u003e to run emulating the ARM32v7\narchitecture to build and run \u003ca href=\"https://www.rust-lang.org/\"\u003eRust\u003c/a\u003e code like if it was a native\n\u003ca href=\"https://github.com/docker-library/official-images#architectures-other-than-amd64\"\u003eARM32v7 architecture\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere are some drawbacks and performance considerations when using this approach, it can be simpler but way slower for\nbig projects.\u003c/p\u003e\n\u003cp\u003eThe source for this article is here \u003ca href=\"https://github.com/kainlite/rcv/\"\u003eRCV\u003c/a\u003e and the docker image is\n\u003ca href=\"https://hub.docker.com/repository/docker/kainlite/rcv\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThis article can be considered a part 2 of\n\u003ca href=\"https://techsquad.rocks/blog/rust_on_arm32v7/\"\u003eRunning rust on ARM32v7K3S Oracle cluster\u003c/a\u003e\nso we will not be creating the rust project and all that here, but focusing on building and running the project.\u003c/p\u003e\n\u003ch5 id=\"prerequisites\"\u003e\u003cstrong\u003ePrerequisites\u003c/strong\u003e\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://hub.docker.com/?overlay=onboarding\"\u003eDocker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/containers/buildah/blob/main/install.md\"\u003eBuildah\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.qemu.org/download/#linux\"\u003eQEMU\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.rust-lang.org/tools/install\"\u003eRust\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"lets-jump-to-the-example\"\u003eLet\u0026rsquo;s jump to the example\u003c/h3\u003e\n\u003ch4 id=\"the-new-dockerfile\"\u003eThe new Dockerfile\u003c/h4\u003e\n\u003cp\u003eYou will notice that this \u003ca href=\"https://raw.githubusercontent.com/kainlite/rcv/master/Dockerfile.armv7v2\"\u003eDockerfile\u003c/a\u003e\nis way simpler than the ones from the previous article, since it runs natively\nas ARM32v7, the main difference is the base image being \u003ccode\u003earm32v7/rust:1.63.0\u003c/code\u003e, this can be further extended for more\narchitectures, see this \u003ca href=\"https://devopstales.github.io/home/running_and_building_multi_arch_containers/\"\u003earticle\u003c/a\u003e for\nmore information.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d983d330e95fd48c28313689d5d37215.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"last-steps-for-qemudocker\"\u003eLast steps for QEMU/Docker\u003c/h4\u003e\n\u003cp\u003eAfter installing the required packages you will still need to perform some simple steps in order for it to work with\ndocker and buildah, the first command is needed for docker to be able to use the required QEMU emulation and the second\nis just to validate that everything works fine\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/988c38925f7518764ef333f0453c3f7a.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"short-names-error\"\u003eShort names error\u003c/h5\u003e\n\u003cp\u003eIf you get an error about short names when pulling images add the following line to your \u003ccode\u003e/etc/containers/registries.conf\u003c/code\u003e\nfile\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/21157cba08e63ab9c4ba8d3fa396dd3e.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"lets-build-it\"\u003eLets build it\u003c/h4\u003e\n\u003cp\u003eFor the build we will use buildah because it is smarter than docker for this kind of scenarios.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/9c6ada7b91ac45aac9bc399c3a4aa921.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"lets-test-it\"\u003eLets test it\u003c/h4\u003e\n\u003cp\u003eAfter building it, we can push it to the docker daemon and then run it and test it from another terminal\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/4c13e33ab16c66b05efdb06a19465be1.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eNotice: you will see some warnings about the architecture, that\u0026rsquo;s fine as we are emulating things.\u003c/p\u003e\n\u003ch4 id=\"performance-considerations\"\u003ePerformance considerations\u003c/h4\u003e\n\u003cp\u003eThis project build with the rust toolchain and then copied to an ARM32v7 image took 2 minutes, but using QEMU and the\ngiven emulation it took around 8 minutes and a half, so it is something to be aware since the difference is quite big.\u003c/p\u003e\n\u003ch4 id=\"extra\"\u003eExtra\u003c/h4\u003e\n\u003cp\u003eYou can see it running \u003ca href=\"http://rcv.techsquad.rocks/\"\u003ehere\u003c/a\u003e, a very basic HTML Curriculum vitae.\u003c/p\u003e\n\u003cp\u003eFor more details and to see how everything fits together I encourage you to clone the repo, test it, and modify it to\nmake your own.\u003c/p\u003e\n\u003ch4 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eBe sure to check the links if you want to learn more about the examples, I hope you enjoyed it,\nsee you on \u003ca href=\"https://twitter.com/kainlite\"\u003etwitter\u003c/a\u003e or \u003ca href=\"https://github.com/kainlite\"\u003egithub\u003c/a\u003e!\u003c/p\u003e\n\u003cp\u003eThe source for this article is \u003ca href=\"https://github.com/kainlite/rcv/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e\nand the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/rust_on_arm32v7/",
      "url": "https://legacy.techsquad.rocks/blog/rust_on_arm32v7/",
      "title": "Running Rust on ARM32v7 K3S Oracle cluster.",
      "date_published": "2022-09-02T00:00:00Z",
      "tags": ["kubernetes","rust","arm"],
      "content_html": "\u003ch4 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIn this article we will explore how to create a sample \u003ca href=\"https://www.rust-lang.org/\"\u003eRust\u003c/a\u003e project and Dockerfile to\nrun it on \u003ca href=\"https://github.com/docker-library/official-images#architectures-other-than-amd64\"\u003eARM32v7 architectures\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo configure the cluster I used this project \u003ca href=\"https://github.com/garutilorenzo/k3s-oci-cluster\"\u003ek3s-oci-cluster\u003c/a\u003e, since\nOracle is providing a very generous free tier for ARM workloads you might as well give it a try, or maybe use your\nraspberry pi cluster.\u003c/p\u003e\n\u003cp\u003eThe source for this article is here \u003ca href=\"https://github.com/kainlite/rcv/\"\u003eRCV\u003c/a\u003e and the docker image is\n\u003ca href=\"https://hub.docker.com/repository/docker/kainlite/rcv\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003ch5 id=\"prerequisites\"\u003e\u003cstrong\u003ePrerequisites\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eThe cluster is optional if you have any device using linux on ARM32v7 or ARM64v8 you should be able to use the docker\nexamples.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/garutilorenzo/k3s-oci-cluster\"\u003ek3s-oci-cluster\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hub.docker.com/?overlay=onboarding\"\u003eDocker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.rust-lang.org/tools/install\"\u003eRust\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"lets-jump-to-the-example\"\u003eLet\u0026rsquo;s jump to the example\u003c/h3\u003e\n\u003ch4 id=\"creating-the-project\"\u003eCreating the project\u003c/h4\u003e\n\u003cp\u003eLets create a new Rust project with Cargo, as you might notice we will get a very basic project that will help us get\nget started:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/dec4806ac2bd054ac6a58526956485e7.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"our-example-and-the-dependencies\"\u003eOur example and the dependencies\u003c/h4\u003e\n\u003cp\u003eI was thinking in processing markdown files and show them as html, so that\u0026rsquo;s basically what the code does, it\u0026rsquo;s far from\noptimal but it is good enough to illustrate the example, first lets add some crates for the webserver\n(\u003ca href=\"https://actix.rs/docs/server/\"\u003eActix\u003c/a\u003e) and converting \u003ca href=\"https://github.com/johannhof/markdown.rs\"\u003emarkdown to html\u003c/a\u003e.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/8605014563ae858f179fcbb596a5b1da.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"lets-add-some-code\"\u003eLets add some code\u003c/h4\u003e\n\u003cp\u003eThis simple snippet only listens for \u003ccode\u003eGET\u003c/code\u003e requests to \u003ccode\u003e/\u003c/code\u003e and logs a line with the unix timestamp and IP and returns\nthe contents of the file \u003ccode\u003ecv.md\u003c/code\u003e which is my Curriculum Vitae.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/eadfce805786f3caf113abdc9e5fcc69.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"example-logs\"\u003eExample logs\u003c/h4\u003e\n\u003cp\u003eExample logs\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/df717357716c57d30c4d11ca8819da06.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eAt this point we have enough to run and test locally, but what about other architectures? (I\u0026rsquo;m running on linux-amd64),\nyou can test it locally if you want running \u003ccode\u003ecargo run\u003c/code\u003e.\u003c/p\u003e\n\u003ch4 id=\"arm32v7-dockerfile\"\u003eARM32v7 Dockerfile\u003c/h4\u003e\n\u003cp\u003eThis Dockerfile can be optimized and secured in many ways, but for the sake of simplicity it is good enough to start\nworking on something, also we will provide the security at runtime via kubernetes APIs.\nWe need to consider two things here, first we need to create an ARM32v7 binary using Rust, then we need a Docker image\nfor that architecture so that\u0026rsquo;s basically what the Dockerfile does.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/7f2747cc8088a5ac38ccae4e69ef6be7.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"building-and-pushing-docker-image\"\u003eBuilding and pushing (docker image)\u003c/h4\u003e\n\u003cp\u003eSo lets build it and push it \u003ca href=\"https://hub.docker.com/repository/docker/kainlite/rcv\"\u003ehere\u003c/a\u003e.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/f342c8200afd2c6172e8b8c215a208f6.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch3 id=\"lets-quickly-review-the-manifests\"\u003elets quickly review the manifests\u003c/h3\u003e\n\u003cp\u003eThe manifests are fairly simple, you can see them there, as you can see we are restricting the user and privileges of\nthe container using the SecurityContext of the pod and the container.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/df0cd2665e5b7f824bb455d72646c339.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"deploying-it\"\u003eDeploying it\u003c/h4\u003e\n\u003cp\u003eAssuming you already have a cluster up and running, this can be deployed like this, you will see a deployment, a service\nand the ingress resources, you will also need to have a DNS entry if you want to use it like I did there:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/b422bac1abf81433b117b608904227bb.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"extra\"\u003eExtra\u003c/h4\u003e\n\u003cp\u003eYou can see it running \u003ca href=\"http://rcv.techsquad.rocks/\"\u003ehere\u003c/a\u003e, a very basic HTML Curriculum vitae, if it doesn\u0026rsquo;t work don\u0026rsquo;t\nworry too much, I\u0026rsquo;m planning on upgrading the cluster and adding https to the example for another article, it will\neventually be back up, however if you want to see it anyway, try running the example and building the image on your\nmachine.\u003c/p\u003e\n\u003cp\u003eFor more details and to see how everything fits together I encourage you to clone the repo, test it, and modify it to\nmake your own.\u003c/p\u003e\n\u003ch3 id=\"cleaning-up\"\u003eCleaning up\u003c/h3\u003e\n\u003cp\u003eTo clean up the resources you can do this:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/6b09642cb04b42953fcdfd0792255ff6.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eBe sure to check the links if you want to learn more about the examples, I hope you enjoyed it,\nsee you on \u003ca href=\"https://twitter.com/kainlite\"\u003etwitter\u003c/a\u003e or \u003ca href=\"https://github.com/kainlite\"\u003egithub\u003c/a\u003e!\u003c/p\u003e\n\u003cp\u003eThe source for this article is \u003ca href=\"https://github.com/kainlite/rcv/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e\nand the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/custom_kubernetes_operator_with_typescript/",
      "url": "https://legacy.techsquad.rocks/blog/custom_kubernetes_operator_with_typescript/",
      "title": "Custom Kubernetes Operator With TypeScript (JavaScript).",
      "date_published": "2021-07-22T00:00:00Z",
      "tags": ["kubernetes","javascript","typescript","operators"],
      "content_html": "\u003ch4 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIn this article we will explore how to create a sample operator using typescript and to deploy it to our cluster, the operator will be pretty dummy in the sense that it will only deploy some resources based in a CRD, but you can customize it to do whatever you might need or want, the idea is to get an idea of all that it takes to do an operator outside of the magic land of \u003ca href=\"https://golang.org/\"\u003eGo\u003c/a\u003e and \u003ca href=\"https://github.com/kubernetes-sigs/kubebuilder\"\u003ekubebuilder\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf you want to check past articles that explore other alternative frameworks and languages go to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/blog/cloud_native_applications_with_kubebuilder_and_kind_aka_kubernetes_operators/\"\u003eCloud native applications with kubebuilder and kind aka kubernetes operators\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/testing_the_operator_sdk_and_making_a_prefetch_mechanism_for_kubernetes/\"\u003eTesting the Operator SDK and making a prefetch mechanism for Kubernetes\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou will notice that both are very similar and it is because the operator-sdk uses kubebuilder.\u003c/p\u003e\n\u003cp\u003eThe source for this article is here \u003ca href=\"https://github.com/kainlite/ts-operator/\"\u003eTypeScript Operator\u003c/a\u003e and the docker image is \u003ca href=\"https://github.com/kainlite/ts-operator/pkgs/container/ts-operator\"\u003ehere\u003c/a\u003e, also this article is based in this example from Nodeshift\u0026rsquo;s \u003ca href=\"https://github.com/nodeshift-blog-examples/operator-in-JavaScript\"\u003eOperator in JavaScript\u003c/a\u003e.\u003c/p\u003e\n\u003ch5 id=\"prerequisites\"\u003e\u003cstrong\u003ePrerequisites\u003c/strong\u003e\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/kind\"\u003eKind\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hub.docker.com/?overlay=onboarding\"\u003eDocker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/kustomize\"\u003ekustomize\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://nodejs.org/\"\u003eNode.js\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.typescriptlang.org/\"\u003eTypeScript\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"lets-jump-to-the-example\"\u003eLet\u0026rsquo;s jump to the example\u003c/h3\u003e\n\u003ch4 id=\"creating-the-cluster\"\u003eCreating the cluster\u003c/h4\u003e\n\u003cp\u003eWe will need a cluster to run and test our operator, so kind is pretty straight forward and lightweight enough to run anywhere.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/53f54d81934666457a46cb667f8cea58.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"creating-our-operator\"\u003eCreating our operator\u003c/h4\u003e\n\u003cp\u003eCreating all necessary resources for our operator to work\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/b11dd1e9dddb4e60a32961a911cbd9d3.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"deploying-our-operator\"\u003eDeploying our operator\u003c/h4\u003e\n\u003cp\u003eCreating our custom resource to see the operator in action\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/374b311fd746a81a2d67a9e4c75e73b4.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"logs-from-the-operator\"\u003eLogs from the operator\u003c/h4\u003e\n\u003cp\u003eExample logs based in the creation, update and deletion of our custom resource\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/eb9862192efa7a08ad964713b688a6e0.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"brief-comparison-operator-sdk-vs-custom-operator\"\u003eBrief comparison operator-sdk vs custom operator?\u003c/h4\u003e\n\u003cp\u003eThere are some main differences to have in mind, in Go you:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHave code generation from the framework for RBAC, controllers, etc.\u003c/li\u003e\n\u003cli\u003eOut of the box tooling to build, deploy and manage your operator.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn TypeScript or JavaScript you have to handle more things which can be easily done from a CI system, In this example I used github actions to build the image and the example already had everything else configured to make typescript usable with kubernetes as an example.\u003c/p\u003e\n\u003ch4 id=\"building-and-pushing-docker-image\"\u003eBuilding and pushing (docker image)\u003c/h4\u003e\n\u003cp\u003eIn this case we don\u0026rsquo;t have to do that it will be managed by actions using the free container registry that they provide, it will build and push the image matching the branch name, notice that it is fully transparent, you don\u0026rsquo;t need to configure anything on the repo, you can see the result \u003ca href=\"https://github.com/kainlite/ts-operator/pkgs/container/ts-operator\"\u003ehere\u003c/a\u003e.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/75c8ed737de39be95573942604ce3d21.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"local-development\"\u003eLocal development\u003c/h4\u003e\n\u003cp\u003eBonus: if you want to run the operator locally when developing or debugging you can do so easily with \u003ccode\u003ets-node\u003c/code\u003e, like this:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/f9bd40bfa9b3157dbd072e03bbc2200a.js\"\u003e\u003c/script\u003e\n\nThe reason I used it like this was mostly to assume zero configuration, and it is possible because ts-node is listed as a development dependency, also the docker image could have been used with a bit of configuration.\u003c/p\u003e\n\u003cp\u003eNote that I did not add all the code from the resources folder or the setup for the typescript project, I recommend you to check that directly in the repo to understand all the missing pieces.\u003c/p\u003e\n\u003ch3 id=\"now-lets-see-the-code\"\u003eNow let\u0026rsquo;s see the code\u003c/h3\u003e\n\u003cp\u003eEnough words, let\u0026rsquo;s see code, I have added comments and changed the original code a bit\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/672d2aabb44d1a988ce77e3df5da7495.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"the-deploymentjson-file\"\u003eThe \u003ccode\u003edeployment.json\u003c/code\u003e file\u003c/h4\u003e\n\u003cp\u003eThis file basically is what gets deployed when we create our custom resource\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d143f7fc382ae5db3fc3ea89bfdb142a.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"and-finally-our-custom-resource\"\u003eAnd finally our custom resource\u003c/h4\u003e\n\u003cp\u003eThis is how we tell our operator that we need our operator to create some resources for a given task\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/7121ff367b6ea7c997f40eaa12c21dae.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"extra\"\u003eExtra\u003c/h4\u003e\n\u003cp\u003eFor more details and to see how everything fits together I encourage you to clone the repo, test it, and modify it yourself.\u003c/p\u003e\n\u003ch3 id=\"cleaning-up\"\u003eCleaning up\u003c/h3\u003e\n\u003cp\u003eTo clean up the operator from the cluster you can do this\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/59aada5bfbaab0309b1e6108a4de2298.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eBe sure to check the links if you want to learn more about the examples from Nodeshift and I hope you enjoyed it, see you on \u003ca href=\"https://twitter.com/kainlite\"\u003etwitter\u003c/a\u003e or \u003ca href=\"https://github.com/kainlite\"\u003egithub\u003c/a\u003e!\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/nodeshift/nodeshift\"\u003ehttps://github.com/nodeshift/nodeshift\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe source for this article is \u003ca href=\"https://github.com/kainlite/ts-operator/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDISCLAIMER: I\u0026rsquo;m not using OpenShift, but all examples are easily translatables to a vanilla cluster.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/kubernetes_image_policy_webhook_explained/",
      "url": "https://legacy.techsquad.rocks/blog/kubernetes_image_policy_webhook_explained/",
      "title": "Kubernetes image policy webhook explained",
      "date_published": "2021-01-07T00:00:00Z",
      "tags": ["kubernetes","linux","security","docker"],
      "content_html": "\u003ch4 id=\"introduction\"\u003eIntroduction\u003c/h4\u003e\n\u003cp\u003eIn this article we will explore how webhook works in kubernetes and more specifically about the ImagePolicyWebhook, the kubernetes documentation about it is kind of vague, since there is no real example or implementation that you can get out of it, so here we will break it down to the different alternatives, in a real world scenario I would prefer to rely in \u003ca href=\"https://github.com/open-policy-agent/gatekeeper\"\u003eOPA Gatekeeper\u003c/a\u003e, I\u0026rsquo;m planning to make this trip worth by adding a database and make the webhook allow or disallow images based in the vulnerability scan, for example allow only medium or lower vulnerabilities in your containers, but that will be a post for another day, if you are interested you can help in this \u003ca href=\"https://github.com/kainlite/kube-image-bouncer\"\u003erepo\u003c/a\u003e, \u003ca href=\"#closing-words\"\u003esee more\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere are two ways to make this work each one has a slightly different behavior, one way is using the \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook\"\u003eImagePolicyWebhook\u003c/a\u003e and the other is using an \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/\"\u003eAdmission Controllers\u003c/a\u003e either works validating or mutating, here I used the validating webhook, you can learn more \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThis admission controller will reject all the pods that are using images with the \u003ccode\u003elatest\u003c/code\u003e tag and in the future we will see if all pods that are not able to meet the required security levels.\u003c/p\u003e\n\u003ch4 id=\"comparison\"\u003eComparison\u003c/h4\u003e\n\u003cp\u003eThe \u003ca href=\"https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook\"\u003eImagePolicyWebhook\u003c/a\u003e is an admission controller that evaluates only images, you need to parse the requests do the logic and the response in order to allow or deny images in the cluster.\u003c/p\u003e\n\u003cp\u003eThe good parts about the \u003ccode\u003eImagePolicyWebhook\u003c/code\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe API server can be instructed to reject the images if the webhook endpoint is not reachable, this is quite handy but it can also bring issues, like core pods won\u0026rsquo;t be able to schedule for example.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe bad parts about the \u003ccode\u003eImagePolicyWebhook\u003c/code\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe configuration is a bit more involved and requires access to the master nodes or to the apiserver configuration, the documentation is not clear and it can be hard to make changes, update, etc.\u003c/li\u003e\n\u003cli\u003eThe deployment is not so trivial as you need to deploy it with systemd or run it as a docker container in the host, update the dns, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOn the other hand the \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers\"\u003eValidatingAdmissionWebhook\u003c/a\u003e can be used for way more things that just images (if you use the mutating one, well, you can inject or change things on the fly).\u003c/p\u003e\n\u003cp\u003eThe good parts about the \u003ccode\u003eValidatingAdmissionWebhook\u003c/code\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEasier deployment since the service runs as a pod.\u003c/li\u003e\n\u003cli\u003eEverything can be a kubernetes resource.\u003c/li\u003e\n\u003cli\u003eLess manual intervention and access to the master is not required.\u003c/li\u003e\n\u003cli\u003eIf the pod or service is unavailable then all images are going to be allowed which can be a security risk in some cases, so if you are going this path be sure to make it highly available, this can actually be configured by specifying the \u003ccode\u003efailurePolicy\u003c/code\u003e to \u003ccode\u003eFail\u003c/code\u003e instead of \u003ccode\u003eIgnore\u003c/code\u003e (\u003ccode\u003eFail\u003c/code\u003e is the default).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe bad parts about the \u003ccode\u003eValidatingAdmissionWebhook\u003c/code\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAnyone with enough RBAC permissions can update/change the configuration since it\u0026rsquo;s just another kubernetes resource.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"building\"\u003eBuilding\u003c/h4\u003e\n\u003cp\u003eIf you intend to use it as a plain service:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go get github.com/kainlite/kube-image-bouncer\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can also use this \u003ca href=\"https://hub.docker.com/r/kainlite/kube-image-bouncer/\"\u003eDocker image\u003c/a\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ docker pull kainlite/kube-image-bouncer\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"certificates\"\u003eCertificates\u003c/h4\u003e\n\u003cp\u003eWe can rely in the kubernetes CA to generate the certificate that we need, if you want to learn more go \u003ca href=\"https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/\"\u003ehere\u003c/a\u003e:\u003c/p\u003e\n\u003cp\u003eCreate a CSR:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ cat \u0026lt;\u0026lt;EOF | cfssl genkey - | cfssljson -bare server\n{\n  \u0026quot;hosts\u0026quot;: [\n    \u0026quot;image-bouncer-webhook.default.svc\u0026quot;,\n    \u0026quot;image-bouncer-webhook.default.svc.cluster.local\u0026quot;,\n    \u0026quot;image-bouncer-webhook.default.pod.cluster.local\u0026quot;,\n    \u0026quot;192.0.2.24\u0026quot;,\n    \u0026quot;10.0.34.2\u0026quot;\n  ],\n  \u0026quot;CN\u0026quot;: \u0026quot;system:node:image-bouncer-webhook.default.pod.cluster.local\u0026quot;,\n  \u0026quot;key\u0026quot;: {\n    \u0026quot;algo\u0026quot;: \u0026quot;ecdsa\u0026quot;,\n    \u0026quot;size\u0026quot;: 256\n  },\n  \u0026quot;names\u0026quot;: [\n    {\n      \u0026quot;O\u0026quot;: \u0026quot;system:nodes\u0026quot;\n    }\n  ]\n}\nEOF\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen apply it to the cluster\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f -\napiVersion: certificates.k8s.io/v1\nkind: CertificateSigningRequest\nmetadata:\n  name: image-bouncer-webhook.default\nspec:\n  request: $(cat server.csr | base64 | tr -d '\\n')\n  signerName: kubernetes.io/kubelet-serving\n  usages:\n  - digital signature\n  - key encipherment\n  - server auth\nEOF\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eApprove and get your certificate for later use\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ kubectl get csr image-bouncer-webhook.default -o jsonpath='{.status.certificate}' | base64 --decode \u0026gt; server.crt\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"imagepolicywebhook-path\"\u003eImagePolicyWebhook path\u003c/h4\u003e\n\u003cp\u003eThere are two possible ways to deploy this controller (webhook), for this to work you will need to create the certificates as explained below, but first\nwe need to take care of other details add this to your hosts file in the master or where the bouncer will run:\u003c/p\u003e\n\u003cp\u003eWe use this name because it has to match with the names from the certificate, since this will run outside kuberntes and it could even be externally available, we just fake it with a hosts entry\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ echo \u0026quot;127.0.0.1 image-bouncer-webhook.default.svc\u0026quot; \u0026gt;\u0026gt; /etc/hosts\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAlso in the apiserver you need to update it with these settings:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e--admission-control-config-file=/etc/kubernetes/kube-image-bouncer/admission_configuration.json\n--enable-admission-plugins=ImagePolicyWebhook\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf you did this method you don\u0026rsquo;t need to create the \u003ccode\u003evalidating-webhook-configuration.yaml\u003c/code\u003e resource nor apply the kubernetes deployment to run in the cluster.\u003c/p\u003e\n\u003cp\u003eCreate an admission control configuration file named \u003ccode\u003e/etc/kubernetes/kube-image-bouncer/admission_configuration.json\u003c/code\u003e file with the following contents:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n  \u0026quot;imagePolicy\u0026quot;: {\n     \u0026quot;kubeConfigFile\u0026quot;: \u0026quot;/etc/kubernetes/kube-image-bouncer/kube-image-bouncer.yml\u0026quot;,\n     \u0026quot;allowTTL\u0026quot;: 50,\n     \u0026quot;denyTTL\u0026quot;: 50,\n     \u0026quot;retryBackoff\u0026quot;: 500,\n     \u0026quot;defaultAllow\u0026quot;: false\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAdjust the defaults if you want to allow images by default.\u003c/p\u003e\n\u003cp\u003eCreate a kubeconfig file \u003ccode\u003e/etc/kubernetes/kube-image-bouncer/kube-image-bouncer.yml\u003c/code\u003e with the following contents:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eapiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    certificate-authority: /etc/kubernetes/kube-image-bouncer/pki/server.crt\n    server: https://image-bouncer-webhook.default.svc:1323/image_policy\n  name: bouncer_webhook\ncontexts:\n- context:\n    cluster: bouncer_webhook\n    user: api-server\n  name: bouncer_validator\ncurrent-context: bouncer_validator\npreferences: {}\nusers:\n- name: api-server\n  user:\n    client-certificate: /etc/kubernetes/pki/apiserver.crt\n    client-key:  /etc/kubernetes/pki/apiserver.key\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis configuration file instructs the API server to reach the webhook server at \u003ccode\u003ehttps://image-bouncer-webhook.default.svc:1323\u003c/code\u003e and use its \u003ccode\u003e/image_policy\u003c/code\u003e endpoint, we\u0026rsquo;re reusing the certificates from the apiserver and the one for kube-image-bouncer that we already generated.\u003c/p\u003e\n\u003cp\u003eBe aware that you need to be sitting in the folder with the certs for that to work:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ docker run --rm -v `pwd`/server-key.pem:/certs/server-key.pem:ro -v `pwd`/server.crt:/certs/server.crt:ro -p 1323:1323 --network host kainlite/kube-image-bouncer -k /certs/server-key.pem -c /certs/server.crt\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"validatingadmissionwebhook-path\"\u003eValidatingAdmissionWebhook path\u003c/h4\u003e\n\u003cp\u003eIf you are going this path, all you need to do is generate the certificates, everything else can be done with kubectl, first of all you have to create a tls secret holding the webhook certificate and key (we just generated this in the previous step):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ kubectl create secret tls tls-image-bouncer-webhook \\\n  --key server-key.pem \\\n  --cert server.pem\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen create a kubernetes deployment for the \u003ccode\u003eimage-bouncer-webhook\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ kubectl apply -f kubernetes/image-bouncer-webhook.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFinally create \u003ccode\u003eValidatingWebhookConfiguration\u003c/code\u003e that makes use of our webhook endpoint, you can use this but be sure to update the caBundle with the \u003ccode\u003eserver.crt\u003c/code\u003e content in base64:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ kubectl apply -f kubernetes/validating-webhook-configuration.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOr you can can simply generate the \u003ccode\u003evalidating-webhook-configuration.yaml\u003c/code\u003e file like this and apply it in one go:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f -\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: image-bouncer-webook\nwebhooks:\n  - name: image-bouncer-webhook.default.svc\n    rules:\n      - apiGroups:\n          - \u0026quot;\u0026quot;\n        apiVersions:\n          - v1\n        operations:\n          - CREATE\n        resources:\n          - pods\n    failurePolicy: Ignore\n    sideEffects: None\n    admissionReviewVersions: [\u0026quot;v1\u0026quot;, \u0026quot;v1beta1\u0026quot;]\n    clientConfig:\n      caBundle: $(kubectl get csr image-bouncer-webhook.default -o jsonpath='{.status.certificate}')\n      service:\n        name: image-bouncer-webhook\n        namespace: default\nEOF\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis could be easily automated (helm chart coming soon\u0026hellip;), changes can take a bit to reflect, so wait a few seconds and give it a try.\u003c/p\u003e\n\u003ch4 id=\"testing\"\u003eTesting\u003c/h4\u003e\n\u003cp\u003eBoth paths should work the same way and you will see a similar error message, example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eError creating: pods \u0026quot;nginx-latest-sdsmb\u0026quot; is forbidden: image policy webhook backend denied one or more images: Images using latest tag are not allowed\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eor\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eWarning  FailedCreate  23s (x15 over 43s)  replication-controller  Error creating: admission webhook \u0026quot;image-bouncer-webhook.default.svc\u0026quot; denied the request: Images using latest tag are not allowed\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreate a nginx-versioned RC to validate that versioned releases still work:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yml\"\u003e$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-versioned\nspec:\n  replicas: 1\n  selector:\n    app: nginx-versioned\n  template:\n    metadata:\n      name: nginx-versioned\n      labels:\n        app: nginx-versioned\n    spec:\n      containers:\n      - name: nginx-versioned\n        image: nginx:1.13.8\n        ports:\n        - containerPort: 80\nEOF\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEnsure/check the replication controller is actually running:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ kubectl get rc\nNAME              DESIRED   CURRENT   READY     AGE\nnginx-versioned   1         1         0         2h\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow create one for nginx-latest to validate that our controller/webhook can actually reject pods with images using the latest tag:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yml\"\u003e$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-latest\nspec:\n  replicas: 1\n  selector:\n    app: nginx-latest\n  template:\n    metadata:\n      name: nginx-latest\n      labels:\n        app: nginx-latest\n    spec:\n      containers:\n      - name: nginx-latest\n        image: nginx\n        ports:\n        - containerPort: 80\nEOF\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf we check the pod it should not be created and the RC should show something similar to the following output, you can also check with \u003ccode\u003ekubectl get events --sort-by='{.lastTimestamp}'\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ kubectl describe rc nginx-latest\nName:         nginx-latest\nNamespace:    default\nSelector:     app=nginx-latest\nLabels:       app=nginx-latest\nAnnotations:  \u0026lt;none\u0026gt;\nReplicas:     0 current / 1 desired\nPods Status:  0 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=nginx-latest\n  Containers:\n   nginx-latest:\n    Image:        nginx\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  \u0026lt;none\u0026gt;\n    Mounts:       \u0026lt;none\u0026gt;\n  Volumes:        \u0026lt;none\u0026gt;\nConditions:\n  Type             Status  Reason\n  ----             ------  ------\n  ReplicaFailure   True    FailedCreate\nEvents:\n  Type     Reason        Age                 From                    Message\n  ----     ------        ----                ----                    -------\n  Warning  FailedCreate  23s (x15 over 43s)  replication-controller  Error creating: admission webhook \u0026quot;image-bouncer-webhook.default.svc\u0026quot; denied the request: Images using latest tag are not allowed\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"debugging\"\u003eDebugging\u003c/h4\u003e\n\u003cp\u003eIt\u0026rsquo;s always useful to see the apiserver logs if you are using the admission controller path since it will log there why did it fail, and also the logs from the image-bouncer, for example:\napiserver\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eW0107 17:39:00.619560       1 dispatcher.go:142] rejected by webhook \u0026quot;image-bouncer-webhook.default.svc\u0026quot;: \u0026amp;errors.StatusError{ErrStatus:v1.Status{TypeMeta:v1.TypeMeta{Kind:\u0026quot;\u0026quot;, APIVersion:\u0026quot;\u0026quot;}, ListMeta:v1.ListMeta{ SelfLink:\u0026quot;\u0026quot;, ResourceVersion:\u0026quot;\u0026quot;, Continue:\u0026quot;\u0026quot;, RemainingItemCount:(*int64)(nil)}, Status:\u0026quot;Failure\u0026quot;, Message:\u0026quot;admission webhook \\\u0026quot;image-bouncer-webhook.default.svc\\\u0026quot; denied the request: Images using latest tag are not allowed\u0026quot;, Reason:\u0026quot;\u0026quot;, Details:(*v1.StatusDetails)(nil), Code:400}}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ekube-image-bouncer:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eecho: http: TLS handshake error from 127.0.0.1:49414: remote error: tls: bad certificate\nmethod=POST, uri=/image_policy?timeout=30s, status=200\nmethod=POST, uri=/image_policy?timeout=30s, status=200\nmethod=POST, uri=/image_policy?timeout=30s, status=200\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe error is from a manual test, the others are successful requests from the apiserver.\u003c/p\u003e\n\u003ch4 id=\"the-code-itself\"\u003eThe code itself\u003c/h4\u003e\n\u003cp\u003eLets take a really brief look at the critical parts of creating an admission controller or webhook:\u003c/p\u003e\n\u003cp\u003eThis is a section of the \u003ccode\u003emain.go\u003c/code\u003e as we can see we are handling two \u003ccode\u003ePOST\u003c/code\u003e paths with different methods, and some other validations, what we need to know is that the we will receive a POST method call with a JSON payload and that we need to convert to an admission controller review request.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e    app.Action = func(c *cli.Context) error {\n        e := echo.New()\n        e.POST(\u0026quot;/image_policy\u0026quot;, handlers.PostImagePolicy())\n        e.POST(\u0026quot;/\u0026quot;, handlers.PostValidatingAdmission())\n\n        e.Use(middleware.LoggerWithConfig(middleware.LoggerConfig{\n            Format: \u0026quot;method=${method}, uri=${uri}, status=${status}\\n\u0026quot;,\n        }))\n\n        if debug {\n            e.Logger.SetLevel(log.DEBUG)\n        }\n\n        if whitelist != \u0026quot;\u0026quot; {\n            handlers.RegistryWhitelist = strings.Split(whitelist, \u0026quot;,\u0026quot;)\n            fmt.Printf(\n                \u0026quot;Accepting only images from these registries: %+v\\n\u0026quot;,\n                handlers.RegistryWhitelist)\n            fmt.Println(\u0026quot;WARN: this feature is implemented only by the ValidatingAdmissionWebhook code\u0026quot;)\n        } else {\n            fmt.Println(\u0026quot;WARN: accepting images from ALL registries\u0026quot;)\n        }\n\n        var err error\n        if cert != \u0026quot;\u0026quot; \u0026amp;\u0026amp; key != \u0026quot;\u0026quot; {\n            err = e.StartTLS(fmt.Sprintf(\u0026quot;:%d\u0026quot;, port), cert, key)\n        } else {\n            err = e.Start(fmt.Sprintf(\u0026quot;:%d\u0026quot;, port))\n        }\n\n        if err != nil {\n            return cli.NewExitError(err, 1)\n        }\n\n        return nil\n    }\n\n    app.Run(os.Args)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is a section from \u003ccode\u003ehandlers/validating_admission.go\u003c/code\u003e, basically it parses and validates if the image should be allowed or not and then it sends an \u003ca href=\"https://pkg.go.dev/k8s.io/api/admission/v1beta1\"\u003eAdmissionReponse\u003c/a\u003e back with the flag \u003ccode\u003eAllowed\u003c/code\u003e set to true or false. If you want to learm more about the different types used here you can explore the \u003ca href=\"https://pkg.go.dev/k8s.io/api/admission/v1beta1\"\u003ev1beta1.Admission Documentation\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efunc PostValidatingAdmission() echo.HandlerFunc {\n    return func(c echo.Context) error {\n        var admissionReview v1beta1.AdmissionReview\n\n        err := c.Bind(\u0026amp;admissionReview)\n        if err != nil {\n            c.Logger().Errorf(\u0026quot;Something went wrong while unmarshalling admission review: %+v\u0026quot;, err)\n            return c.JSON(http.StatusBadRequest, err)\n        }\n        c.Logger().Debugf(\u0026quot;admission review: %+v\u0026quot;, admissionReview)\n\n        pod := v1.Pod{}\n        if err := json.Unmarshal(admissionReview.Request.Object.Raw, \u0026amp;pod); err != nil {\n            c.Logger().Errorf(\u0026quot;Something went wrong while unmarshalling pod object: %+v\u0026quot;, err)\n            return c.JSON(http.StatusBadRequest, err)\n        }\n        c.Logger().Debugf(\u0026quot;pod: %+v\u0026quot;, pod)\n\n        admissionReview.Response = \u0026amp;v1beta1.AdmissionResponse{\n            Allowed: true,\n            UID:     admissionReview.Request.UID,\n        }\n        images := []string{}\n\n        for _, container := range pod.Spec.Containers {\n            images = append(images, container.Image)\n            usingLatest, err := rules.IsUsingLatestTag(container.Image)\n            if err != nil {\n                c.Logger().Errorf(\u0026quot;Error while parsing image name: %+v\u0026quot;, err)\n                return c.JSON(http.StatusInternalServerError, \u0026quot;error while parsing image name\u0026quot;)\n            }\n            if usingLatest {\n                admissionReview.Response.Allowed = false\n                admissionReview.Response.Result = \u0026amp;metav1.Status{\n                    Message: \u0026quot;Images using latest tag are not allowed\u0026quot;,\n                }\n                break\n            }\n\n            if len(RegistryWhitelist) \u0026gt; 0 {\n                validRegistry, err := rules.IsFromWhiteListedRegistry(\n                    container.Image,\n                    RegistryWhitelist)\n                if err != nil {\n                    c.Logger().Errorf(\u0026quot;Error while looking for image registry: %+v\u0026quot;, err)\n                    return c.JSON(\n                        http.StatusInternalServerError,\n                        \u0026quot;error while looking for image registry\u0026quot;)\n                }\n                if !validRegistry {\n                    admissionReview.Response.Allowed = false\n                    admissionReview.Response.Result = \u0026amp;metav1.Status{\n                        Message: \u0026quot;Images from a non whitelisted registry\u0026quot;,\n                    }\n                    break\n                }\n            }\n        }\n\n        if admissionReview.Response.Allowed {\n            c.Logger().Debugf(\u0026quot;All images accepted: %v\u0026quot;, images)\n        } else {\n            c.Logger().Infof(\u0026quot;Rejected images: %v\u0026quot;, images)\n        }\n\n        c.Logger().Debugf(\u0026quot;admission response: %+v\u0026quot;, admissionReview.Response)\n\n        return c.JSON(http.StatusOK, admissionReview)\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEverything is in this \u003ca href=\"https://github.com/kainlite/kube-image-bouncer\"\u003erepo\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 id=\"closing-words\"\u003eClosing words\u003c/h4\u003e\n\u003cp\u003eThis example and the original post were done \u003ca href=\"https://github.com/flavio/kube-image-bouncer\"\u003ehere\u003c/a\u003e, so thank you \u003ca href=\"https://flavio.castelli.me/\"\u003eFlavio Castelli\u003c/a\u003e for creating such a great example, my changes are mostly about explaining how it works and the required changes for it to work in the latest kubernetes release (at the moment v1.20.0), as I was learning to use it and to create my own.\u003c/p\u003e\n\u003cp\u003eThe readme file in the project might not match this article but both should work, I didn\u0026rsquo;t update the entire readme yet.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/kubernetes_authentication_and_authorization/",
      "url": "https://legacy.techsquad.rocks/blog/kubernetes_authentication_and_authorization/",
      "title": "Kubernetes authentication and authorization",
      "date_published": "2020-11-29T00:00:00Z",
      "tags": ["kubernetes","linux","security"],
      "content_html": "\u003ch4 id=\"introduction\"\u003eIntroduction\u003c/h4\u003e\n\u003cp\u003eIn this article we will explore how authentication and authorization works in kubernetes. But first what\u0026rsquo;s the difference?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAuthentication\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eWhen you validate your identity against a service or system you are authenticated meaning that the system recognizes you as a valid user. In kubernetes when you are creating the clusters you basically create a CA (Certificate Authority) that then you use to generate certificates for all components and users.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAuthorization\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eAfter you are authenticated the system needs to know if you have enough privileges to do whatever you might want to do. In kubernetes this is known as RBAC (Role based access control) and it translates to Roles as entities with permissions and are associated to service accounts via role bindings when things are scoped to a given namespace, otherwise you can have a cluster role and cluster role binding.\u003c/p\u003e\n\u003cp\u003eSo we are going to create a namespace, a serviceaccount, a role and a role binding and then generate a kubeconfig for it and then test it.\u003c/p\u003e\n\u003cp\u003eThe sources for this article can be found at: \u003ca href=\"https://github.com/kainlite/rbac-example\"\u003eRBAC Example\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"lets-get-to-it\"\u003eLet\u0026rsquo;s get to it\u003c/h4\u003e\n\u003cp\u003eLet\u0026rsquo;s start, I will use these generators but I\u0026rsquo;m saving these to a file and then applying.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNamespace\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eThe namespace resource is like a container for other resources and it\u0026rsquo;s often useful when deploying many apps to the same cluster or there are multiple users:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/828785468668500a414d944ad88916e1.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eYou can see more \u003ca href=\"https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eService account\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eThe service account is your identity as part of the system, there are some important distinctions in user accounts vs service accounts, for example:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUser accounts are for humans. Service accounts are for processes, which run in pods.\u003c/li\u003e\n\u003cli\u003eUser accounts are intended to be global. Names must be unique across all namespaces of a cluster. Service accounts are namespaced.\nFor this example we are generating a serviceaccount for a pod and a user account for us to use with kubectl (if we wanted a global user we should have used clusterrole and clusterrolebinding).\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/de549aad7fd64ab9ee0ecc23fd2e8cf9.js\"\u003e\u003c/script\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can see more \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/authentication/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRole\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eThis role has admin-like privileges, the allowed verbs are, we are using * which means all:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003elist\u003c/li\u003e\n\u003cli\u003eget\u003c/li\u003e\n\u003cli\u003ewatch\u003c/li\u003e\n\u003cli\u003ecreate\u003c/li\u003e\n\u003cli\u003epatch\u003c/li\u003e\n\u003cli\u003eupdate\u003c/li\u003e\n\u003cli\u003edelete\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/2e0bf3309f59e4ccccd8293f24792fcd.js\"\u003e\u003c/script\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can see more \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/authorization/#determine-the-request-verb\"\u003ehere\u003c/a\u003e\nand \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/rbac/#clusterrole-example\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRole binding\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eThis is the glue that gives the permissions in the role to the service account that we created.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/1662dc711fca25f786868baabb1ae0c4.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eYou can see more \u003ca href=\"https://kubernetes.io/docs/reference/access-authn-authz/rbac/#clusterrolebinding-example\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eExample pod\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eHere we create a sample pod with curl and give it the service account with \u003ccode\u003e--serviceaccount=\u003c/code\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/888e39b3c16c17f6a0ae7eeee9fe7329.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eApplying\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eHere we create all resources\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/9e6cbc9a5913cda59e9fc79445c40969.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValidating from the pod\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eHere we will export the token for our service account and query the kubernetes API.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/b881d73776369645c03aa0863fe79d17.js\"\u003e\u003c/script\u003e\n\nNotice that to be able to reach the kubernetes service since it\u0026rsquo;s in a different namespace we need to specify it with \u003ccode\u003e.default\u003c/code\u003e (because it\u0026rsquo;s in the default namespace) try: \u003ccode\u003ekubectl get svc -A\u003c/code\u003e to see all services.\u003c/p\u003e\n\u003cp\u003eEverything went well from our pod and we can communicate to the API from our pod, let\u0026rsquo;s see if it works for kubectl as well.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGenerate kubectl config\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFetch the token (as you can see it\u0026rsquo;s saved as a kubernetes secret, so it\u0026rsquo;s mounted to pods as any other secret but automatically thanks to the service account)\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/6c0956e49301b938f6e29cf9b31dbb10.js\"\u003e\u003c/script\u003e\n\nNotes: I used \u003ccode\u003ekubectl config view\u003c/code\u003e to discover the kind endpoint which is \u003ccode\u003eserver: https://127.0.0.1:35617\u003c/code\u003e in my case, then replaced the values from the secret for the CA and the service account token/secret, also note that you need to decode from base64 when using \u003ccode\u003ekubectl get -o yaml\u003c/code\u003e, also note that we will get errors when trying to do things outside of our namespace because we simply don\u0026rsquo;t have permissions, this is a really powerful way to give permissions to users and this works because we created the role binding for our extra user and for the pod service account (be careful when wiring things up).\u003c/p\u003e\n\u003cp\u003eYou can see more \u003ca href=\"http://docs.shippable.com/deploy/tutorial/create-kubeconfig-for-self-hosted-kubernetes-cluster/\"\u003ehere\u003c/a\u003e\nand \u003ca href=\"https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"clean-up\"\u003eClean up\u003c/h4\u003e\n\u003cp\u003eAlways remember to clean up your local machine / cluster / etc, in my case \u003ccode\u003ekind delete cluster\u003c/code\u003e will do it.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/kubernetes_local_playground_alternatives/",
      "url": "https://legacy.techsquad.rocks/blog/kubernetes_local_playground_alternatives/",
      "title": "Kubernetes local playground alternatives",
      "date_published": "2020-11-27T00:00:00Z",
      "tags": ["kubernetes","vagrant","linux"],
      "content_html": "\u003ch5 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eIn this article we will explore different alternatives for spinning up a cluster locally for testing, practicing or just developing an application.\u003c/p\u003e\n\u003cp\u003eThe source code and/or documentation of the projects that we will be testing are listed here:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://minikube.sigs.k8s.io/docs/start/\"\u003eminikube\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kind.sigs.k8s.io/docs/user/quick-start/\"\u003ekind\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kainlite/kubernetes-the-easy-way-with-vagrant\"\u003eKubernetes the hard way using vagrant\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kainlite/kubernetes-the-easy-way-with-vagrant-and-kubeadm\"\u003eKubernetes with kubeadm using vagrant\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are more alternatives like \u003ca href=\"https://microk8s.io/\"\u003eMicrok8s\u003c/a\u003e but I will leave that as an exercise for the reader.\u003c/p\u003e\n\u003cp\u003eIf you want to give it a try to each one make sure to follow their recommended way of install or your distro/system way.\u003c/p\u003e\n\u003cp\u003eThe first two (minikube and kind) we will see how to configure a CNI plugin in order to be able to use \u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/network-policies/\"\u003eNetwork Policies\u003c/a\u003e, in the other two environments you can customize everything and these are best for learning rather than for daily usage but if you have enough ram you could do that as well.\u003c/p\u003e\n\u003cp\u003eWe will be using the following pods and network policy to test that it works, we will create 3 pods, 1 client and 2 app backends, one backend will be listening in port TCP/1111 and the other in the port TCP/2222, in our netpolicy we will only allow our client to connect to app1:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/296e4987866f383d7cc64a70ee92cea9.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eIf you want to learn more about netcat and friends go to: \u003ca href=\"https://techsquad.rocks/blog/cat_and_friends_netcat_socat/\"\u003eCat and friends: netcat and socat\u003c/a\u003e\u003c/p\u003e\n\u003ch5 id=\"minikube\"\u003eMinikube\u003c/h5\u003e\n\u003cp\u003eMinikube is heavily used but it can be too heavy sometimes, in any case we will see an example of making it work with network policies, the good thing is that it has a lot of documentation because a lot of people use it and it is updated often:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/15e74a5f662d182a03b1b4c449ebc0ef.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch6 id=\"give-it-a-couple-of-minutes-to-start-for-new-versions-of-minikube-you-can-install-it-like-this-otherwise-you-can-specify-that-you-will-install-the-cni-plugin-and-then-just-install-the-manifests\"\u003eGive it a couple of minutes to start, for new versions of minikube you can install it like this, otherwise you can specify that you will install the CNI plugin and then just install the manifests.\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/a9f0f1cd7a62438e0f0272c73e68f2d3.js\"\u003e\u003c/script\u003e\n\n\u003ch6 id=\"then-lets-validate-that-it-works\"\u003eThen let\u0026rsquo;s validate that it works\u003c/h6\u003e\n\u003cp\u003e\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/56d4c6dfc868e59d592ab8814df80247.js\"\u003e\u003c/script\u003e\n\nNote that we add the timeout command with 5 seconds wait so we don\u0026rsquo;t have to really wait for nc timeout which by default is no timeout, we also tested with nc timeout.\u003c/p\u003e\n\u003cp\u003eYou can get more info for minikube using Cilium on their \u003ca href=\"https://docs.cilium.io/en/v1.9/gettingstarted/minikube/\"\u003edocs\u003c/a\u003e\u003c/p\u003e\n\u003ch6 id=\"remember-to-clean-up\"\u003eRemember to clean up\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/1122ca58d12e56bc7b411df4a817a687.js\"\u003e\u003c/script\u003e\n\n\u003ch5 id=\"kind\"\u003eKIND\u003c/h5\u003e\n\u003cp\u003eKIND is really lightweight and fast, I usually test and develop using KIND the main reason is that almost everything works like in a real cluster but it has no overhead, it\u0026rsquo;s simple to install and easy to run, first we need to put this config in place to tell kind not to use it\u0026rsquo;s default CNI.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/5970458ddef9722e28a4ab195a3fbe44.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eThen we can create the cluster and install calico (there is a small gotcha here, you need to check that the calico node pods come up if not kill them and they should come up and everything will start working normally, this is due to the environment variable that gets added after the deployment for it to work with KIND):\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/fb1b68aa8ecbf7d5d1f6a8290693fabc.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eYou can check for more config options for KIND \u003ca href=\"https://kind.sigs.k8s.io/docs/user/configuration/#networking\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch6 id=\"validation\"\u003eValidation\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/881e08f6d86fccfc19c90f137d141d1a.js\"\u003e\u003c/script\u003e\n\n\u003ch6 id=\"testing-again\"\u003eTesting again:\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/723c34e69d516d92a2dc8a2fb36eba94.js\"\u003e\u003c/script\u003e\n\n\u003ch5 id=\"kubeadm-and-vagrant\"\u003eKubeadm and vagrant\u003c/h5\u003e\n\u003cp\u003eThis is an interesting scenario and it\u0026rsquo;s great to understand how clusters are configured using kubeadm also to practice things such as adding/removing/upgrading the nodes, backup and restore etcd, etc. if you want to test this one clone this repo: \u003ca href=\"https://github.com/kainlite/kubernetes-the-easy-way-with-vagrant-and-kubeadm\"\u003eKubernetes with kubeadm using vagrant\u003c/a\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/4c220572ef64fc5632eaca9dd61274d6.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch6 id=\"next-lets-copy-the-kubeconfig-and-deploy-our-resources-then-test-this-deployment-is-using-weave\"\u003eNext, lets copy the kubeconfig and deploy our resources then test (this deployment is using weave)\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/c0b82abded8570313e880cbc53d7307f.js\"\u003e\u003c/script\u003e\n\n\u003ch6 id=\"test-it-wait-until-the-pods-are-in-ready-state\"\u003eTest it (wait until the pods are in ready state)\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d0c52595f9e1fe390bcc67674c752449.js\"\u003e\u003c/script\u003e\n\n\u003ch6 id=\"for-more-info-refer-to-the-readme-in-the-repo-and-the-scripts-in-there-it-should-be-straight-forward-to-follow-and-reproduce-remember-to-clean-up\"\u003eFor more info refer to the readme in the repo and the scripts in there, it should be straight forward to follow and reproduce, remember to clean up:\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d56933b3f8f625dce31ee3009544137b.js\"\u003e\u003c/script\u003e\n\n\u003ch5 id=\"kubernetes-the-hard-way-and-vagrant\"\u003eKubernetes the hard way and vagrant\u003c/h5\u003e\n\u003cp\u003eThis is probably the most complex scenario and it\u0026rsquo;s purely educational you get to generate all the certificates by hand basically and configure everything by yourself (see the original repo for instructions in how to do that in gcloud if you are interested), if you want to test this one clone this repo: \u003ca href=\"https://github.com/kainlite/kubernetes-the-easy-way-with-vagrant\"\u003eKubernetes the hard way using vagrant\u003c/a\u003e, but be patient and ready to debug if something doesn\u0026rsquo;t go well.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/ad908b7a3ba2ac7b62847547e6543cda.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch6 id=\"validation-1\"\u003eValidation:\u003c/h6\u003e\n\u003cp\u003e\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/ecee83106224d044305f626ee594aaf6.js\"\u003e\u003c/script\u003e\n\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/411720203edc931ea3b3eed70208364a.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch6 id=\"install-the-manifests-and-test-it\"\u003eInstall the manifests and test it:\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/e4d357f4d32d4d2c4e39124e47bfa2ed.js\"\u003e\u003c/script\u003e\n\n\u003ch6 id=\"clean-up\"\u003eClean up\u003c/h6\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/b905f5a7efe4a6a86090008e89229173.js\"\u003e\u003c/script\u003e\n\n\u003ch5 id=\"wrap-up\"\u003eWrap up\u003c/h5\u003e\n\u003cp\u003eEach alternative has its use case, test each one and pick the one that best fit your needs.\u003c/p\u003e\n\u003ch5 id=\"clean-up-1\"\u003eClean up\u003c/h5\u003e\n\u003cp\u003eRemember to clean up to recover some resources in your machine.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/testing_the_operator_sdk_and_making_a_prefetch_mechanism_for_kubernetes/",
      "url": "https://legacy.techsquad.rocks/blog/testing_the_operator_sdk_and_making_a_prefetch_mechanism_for_kubernetes/",
      "title": "Testing the Operator SDK and making a prefetch mechanism for Kubernetes",
      "date_published": "2020-11-01T00:00:00Z",
      "tags": ["kubernetes","go","golang"],
      "content_html": "\u003ch4 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIn this article we will explore how to create an operator that can prefetch our images (from our deployments to all nodes) using the Operator SDK, you might be wondering why would you want to do this? the main idea is to get the images in advance so you don\u0026rsquo;t have to pull them when the pod actually needs to start running in a given node, this can speed up things a bit and it\u0026rsquo;s also an interesting exercise.\u003c/p\u003e\n\u003cp\u003eIf you have read the article \u003ca href=\"/blog/cloud_native_applications_with_kubebuilder_and_kind_aka_kubernetes_operators/\"\u003eCloud native applications with kubebuilder and kind aka kubernetes operators\u003c/a\u003e you will note that the commands are really similar between each other, since now the operator-sdk uses kubebuilder, you can read more \u003ca href=\"https://github.com/operator-framework/operator-sdk/issues/3558#issuecomment-664206538\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe source for this article is \u003ca href=\"https://github.com/kainlite/kubernetes-prefetch-operator/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch5 id=\"prerequisites\"\u003e\u003cstrong\u003ePrerequisites\u003c/strong\u003e\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://sdk.operatorframework.io/docs/installation/install-operator-sdk/\"\u003eOperator SDK\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://golang.org/dl/\"\u003eGo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/kind\"\u003eKind\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hub.docker.com/?overlay=onboarding\"\u003eDocker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/kustomize\"\u003ekustomize\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"creating-our-local-cluster\"\u003eCreating our local cluster\u003c/h4\u003e\n\u003ch5 id=\"kind-config-for-multi-cluster\"\u003eKind config for multi-cluster\u003c/h5\u003e\n\u003cp\u003eThis is the kind config necessary to have a multi-node setup locally: \u003ccode\u003ekind create cluster --config kind.yaml\u003c/code\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/6efa9269df15fd1b7eb47c16bd568268.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"creating-the-cluster\"\u003eCreating the cluster\u003c/h5\u003e\n\u003cp\u003eWe will need a cluster to run and test our operator, so kind is pretty straight forward and lightweight enough to run anywhere.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/a15cfb1f2262f4a21f8c25d4b4e35679.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"creating-our-operator\"\u003eCreating our operator\u003c/h4\u003e\n\u003cp\u003eHere we bootstrap our go project aka as kubernetes operator\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/20914ab8e9b8ecdb74be9d3ad7c671d3.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"creating-our-api\"\u003eCreating our API\u003c/h4\u003e\n\u003cp\u003eThis will be the object that it will hold all the important information for a given image, the files that we need to modify at first hand are in: \u003ccode\u003econtrollers/*_controller.go\u003c/code\u003e and \u003ccode\u003eapi/v1/*_types.go\u003c/code\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/20914ab8e9b8ecdb74be9d3ad7c671d3.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"building-and-pushing-docker-image\"\u003eBuilding and pushing (docker image)\u003c/h4\u003e\n\u003cp\u003eBasic build and push of the operator image with the projects helper\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/c809a58f25650ca9960b1a44abd2f17b.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch4 id=\"deploying\"\u003eDeploying\u003c/h4\u003e\n\u003cp\u003eNow that we have the project built into a docker image and stored in dockerhub then we can install our CRD and then deploy the operator\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/fba8082e152058023fdd8141b86ad3b3.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"deploy-the-operator\"\u003eDeploy the operator\u003c/h5\u003e\n\u003cp\u003eThen we can deploy our operator\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/dbda7b13664467190c7c4d71469a824b.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"validate-that-our-operator-was-deployed\"\u003eValidate that our operator was deployed\u003c/h5\u003e\n\u003cp\u003eCheck that our pods are running\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/671d64d07acab19ff5fabeb5f1665867.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eSo far everything is peachy but our operator is kind of useless at the moment, so let\u0026rsquo;s drop some code to make it do what we want\u0026hellip;\u003c/p\u003e\n\u003ch4 id=\"our-code\"\u003eOur code\u003c/h4\u003e\n\u003cp\u003eA lot of what we use is generated however we need to give it some specific permissions and behaviour to our operator so it does what we want when we create an object in kubernetes\u003c/p\u003e\n\u003ch5 id=\"our-manifest\"\u003eOur manifest\u003c/h5\u003e\n\u003cp\u003eThis will be the manifest that we will be using to tell our operator which deployments we want to prefetch images for\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/483f816f36237c3e1b99f1e2391ce0f0.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"sample-nginx-deployment\"\u003eSample nginx deployment\u003c/h5\u003e\n\u003cp\u003eThis nginx deployment will be used to validate that the images are fetched in all nodes\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/33387c03e2d2df059d28239f28f165d1.js\"\u003e\u003c/script\u003e\n\nWe don\u0026rsquo;t actually need to do this, but this way it\u0026rsquo;s easy to make sure that a pod won\u0026rsquo;t be scheduled if the label is not present: \u003ccode\u003ekubectl label nodes kind-worker3 nginx-schedulable=\u0026quot;true\u0026quot;\u003c/code\u003e\u003c/p\u003e\n\u003ch5 id=\"our-actual-logic-this-made-me-chuckle-so-much-bootstrap-just-to-get-here-but-imagine-having-to-do-all-that-by-yourself\"\u003eOur actual logic (this made me chuckle so much bootstrap just to get here, but imagine having to do all that by yourself)\u003c/h5\u003e\n\u003cp\u003eThis is where things actually happen, first we get our Spec updated:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/52c068ebde15e585c973b9e33439f971.js\"\u003e\u003c/script\u003e\n\nYou can find this file \u003ca href=\"https://github.com/kainlite/kubernetes-prefetch-operator/blob/master/api/v1/prefetch_types.go\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThen we can put some code, I will add more comments later in the code to explain what everything does:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/3f9ed270890b26c5e9d4b8b4d527cc45.js\"\u003e\u003c/script\u003e\n\nBasically what we do is set a timer to create a pod in each node to force it fetch the image that the deployments (that we filter by labels) needs or is going to use, by doing this if the node already has the image nothing happens and it will be removed in the next run, however if the image is not there it will be fetched so if anything happens and a pod needs to be actually scheduled there it won\u0026rsquo;t need to download everything so it should be relatively faster.\nYou can find this file \u003ca href=\"https://github.com/kainlite/kubernetes-prefetch-operator/blob/master/controllers/prefetch_controller.go\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch5 id=\"what-we-should-be-seeing-in-our-cluster\"\u003eWhat we should be seeing in our cluster\u003c/h5\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/b4dcc0f43758e47544fc072844ae491e.js\"\u003e\u003c/script\u003e\n\n\u003ch4 id=\"cleaning-up\"\u003eCleaning up\u003c/h4\u003e\n\u003cp\u003eTo clean up the operator from the cluster you can do, and also remember to clean up your clusters or whatever you are using if it\u0026rsquo;s in the cloud to avoid unexpected bills\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/1ca0940c3b8e775db3d083bd1c7d4d42.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eBe sure to check the links if you want to learn more about the project and I hope you enjoyed it, see you on \u003ca href=\"https://twitter.com/kainlite\"\u003etwitter\u003c/a\u003e or \u003ca href=\"https://github.com/kainlite\"\u003egithub\u003c/a\u003e!\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://sdk.operatorframework.io/docs/building-operators/golang/tutorial/\"\u003ehttps://sdk.operatorframework.io/docs/building-operators/golang/tutorial/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://sdk.operatorframework.io/docs/building-operators/golang/operator-scope/\"\u003ehttps://sdk.operatorframework.io/docs/building-operators/golang/operator-scope/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://opensource.com/article/20/3/kubernetes-operator-sdk\"\u003ehttps://opensource.com/article/20/3/kubernetes-operator-sdk\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe source for this article is \u003ca href=\"https://github.com/kainlite/kubernetes-prefetch-operator/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/terraform_linter/",
      "url": "https://legacy.techsquad.rocks/blog/terraform_linter/",
      "title": "Automatic terraform linting with reviewdog and tflint",
      "date_published": "2020-05-21T00:00:00Z",
      "tags": ["development","github","terraform"],
      "content_html": "\u003ch5 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eIn this article we will test how to lint and get automatic checks in our github pull requests for our terraform code using \u003ca href=\"https://github.com/reviewdog/reviewdog\"\u003ereviewdog\u003c/a\u003e and the \u003ca href=\"https://github.com/reviewdog/action-tflint\"\u003etflint github action\u003c/a\u003e, this is particularly useful to prevent unwanted changes or buggy commits to be merged into your principal branch whatever that is. In order for this to work you just need to configure a Github action in your repo and that\u0026rsquo;s it, you don\u0026rsquo;t need to generate any token or do any extra step.\u003c/p\u003e\n\u003cp\u003eIn order to make the example easier I have created this \u003ca href=\"https://github.com/kainlite/reviewdog\"\u003erepo\u003c/a\u003e with the basic configuration to make it work.\u003c/p\u003e\n\u003ch5 id=\"terraform\"\u003e\u003cstrong\u003eTerraform\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eFirst of all we need to get our terraform code, as you can see it\u0026rsquo;s a simple ec2 instance in AWS, but the instance type doesn\u0026rsquo;t exist, we will fix that in a bit.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/46e52cccce0a9ef98c18429b77b1e0aa.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"github-workflow\"\u003e\u003cstrong\u003eGithub Workflow\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eSince we\u0026rsquo;re using Github we can take advantage of \u003ca href=\"https://github.com/features/actions\"\u003eActions\u003c/a\u003e in order to run a linter for our code and mark our PR if something is wrong.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/a584551ed1f974e9432f986c3fb6e73d.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"example-pr\"\u003e\u003cstrong\u003eExample PR\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eFirst we will run a PR with an issue to see it fail and how reporting works (To get here you can click in the checks tab in the PR and then the tflint step see \u003ca href=\"https://github.com/kainlite/reviewdog/pull/1/checks?check_run_id=793169790\"\u003ehere\u003c/a\u003e).\n\u003cfigure\u003e\u003cimg src=\"/img/reviewdog-1.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"one-that-actually-works\"\u003e\u003cstrong\u003eOne that actually works\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eSince we already tested it and it failed as expected we can now fix it, and now that reviewdog and tflint are happy with our commit we can just merge it (just change t1 to t2 in the main.tf file).\n\u003cfigure\u003e\u003cimg src=\"/img/reviewdog-2.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eFor me this seems particularly useful because it can catch a lot of errors that sometimes are hard for the eye to catch, specially when we are talking of typos, it\u0026rsquo;s also a good practice to lint your code so there you go, I hope you give this a shot and have in mind that reviewdog can review a lot of different languages, I just picked terraform because it\u0026rsquo;s what I\u0026rsquo;m using the most lately.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/gitlab_ci_basics/",
      "url": "https://legacy.techsquad.rocks/blog/gitlab_ci_basics/",
      "title": "Gitlab-CI Basics",
      "date_published": "2020-02-02T00:00:00Z",
      "tags": ["go","golang","kubernetes","linux","docker","kubebuilder","gitlab","continuous-integration","continuous-delivery"],
      "content_html": "\u003ch5 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eIn this article we will continue where we left off the \u003ca href=\"https://github.com/kainlite/forward\"\u003eforward\u003c/a\u003e project last time, in this article we will use \u003ca href=\"https://gitlab.com\"\u003egitlab-ci\u003c/a\u003e to test, build and push the image of our operator to \u003ca href=\"https://hub.docker.com/repository/docker/kainlite/forward\"\u003edockerhub\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eGitlab offers a pretty complete solution, but we will only sync our repo from github and set a basic pipeline to test, build and push our docker image to the registry, note that I do not have any kind of affiliation with gitlab, but I like their platform. Also this article demonstrates that you can use github and gitlab in a straight forward manner using the free tier in both sides, we rely in the free shared runners to make our custom CI system.\u003c/p\u003e\n\u003cp\u003eIf you want to check the previous article \u003ca href=\"https://legacy.techsquad.rocks/blog/cloud_native_applications_with_kubebuilder_and_kind_aka_kubernetes_operators/\"\u003ego here\u003c/a\u003e, that way you will know what the project is all about.\u003c/p\u003e\n\u003ch5 id=\"prerequisites\"\u003e\u003cstrong\u003ePrerequisites\u003c/strong\u003e\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kainlite/forward\"\u003eA project in github in this case\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://gitlab.com/users/sign_up\"\u003eA gitlab.com account\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hub.docker.com/u/kainlite\"\u003eA dockerhub account\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"create-the-project\"\u003e\u003cstrong\u003eCreate the project\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eOnce you have your accounts configured, let\u0026rsquo;s create a project, the page should look something like this\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-1.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\nWe want to create a repo or sync a repo in this case, so we select \u003ccode\u003eCreate a project\u003c/code\u003e and continue\u003c/p\u003e\n\u003ch5 id=\"project-type\"\u003e\u003cstrong\u003eProject type\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eIn this step we have a few options and since we have our code in Github and we want to work there, we only want to sync it, so we need to choose \u003ccode\u003eCI/CD for external repo\u003c/code\u003e\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-2.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\nNote that if the repo is public you can fetch/clone using the repo URL, but since I want to check also private repos I went for the github token alternative. Once you hit github it will ask you for the token then it will show you the full list of repos in your account\u003c/p\u003e\n\u003ch5 id=\"github-token\"\u003e\u003cstrong\u003eGithub Token\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eI picked to use a personal token to fetch the repos to be able to grab private repos, etc, so you will need to go to your github account, \u003ccode\u003eSettings-\u0026gt;Developer settings\u003c/code\u003e and then create a new token or \u003ca href=\"https://github.com/settings/tokens\"\u003eclick here\u003c/a\u003e\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-3.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eNow you only need to give it access to repo, and hit save or create new personal token\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-4.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\nMake sure you don\u0026rsquo;t expose or publish that token in any way, otherwise someone could gain access to your account\u003c/p\u003e\n\u003ch5 id=\"back-to-gitlab-select-the-repository-to-sync\"\u003e(Back to gitlab) \u003cstrong\u003eSelect the repository to sync\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eHere we need to select the repo that we want to sync and hit connect, it will automatically fetch everything periodically from github.\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-5.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"dockerhub-token\"\u003e\u003cstrong\u003eDockerhub token\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eNow we will need to create a token for dockerhub so we can push our image from the build runner, go to your dockerhub account and create a token\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-6.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\nBasically you have to go to \u003ccode\u003eAccount settings-\u0026gt;Security-\u0026gt;New Access Token\u003c/code\u003e or \u003ca href=\"https://hub.docker.com/settings/security\"\u003eclick here\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThen we need to save that token as \u003ccode\u003eDOCKERHUB_TOKEN\u003c/code\u003e in this case as an environment variable in the gitlab project, \u003ccode\u003eSettings-\u0026gt;CI/CD-\u0026gt;Variables\u003c/code\u003e\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-7.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\nmake sure masked is marked but not protected, protected is only used when you want to use that secret in specific branches\u003c/p\u003e\n\u003ch5 id=\"gitlab-ci-config\"\u003e\u003cstrong\u003eGitlab-CI config\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eAfter that we only need to add the code to the repo and that will trigger a build, the file needs to be called \u003ccode\u003e.gitlab-ci.yml\u003c/code\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/1cb1aeb54f12830f4bcef6f0df02a250.js\"\u003e\u003c/script\u003e\n\nbasically we just install everything we need run the tests if everything goes well, then the build and push process. There is a lot of room for improvement in that initial config, but for now we only care in having some sort of CI system\u003c/p\u003e\n\u003cp\u003eThen we will see something like this in the \u003ccode\u003eCI/CD-\u0026gt;Pipelines\u003c/code\u003e tab, after each commit it will trigger a test, build and push\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-8.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"checking-the-results\"\u003e\u003cstrong\u003eChecking the results\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eAnd we can validate that the images are in dockerhub\n\u003cfigure\u003e\u003cimg src=\"/img/gitlab-9.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"useful-links\"\u003e\u003cstrong\u003eUseful links\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eSome useful links:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.gitlab.com/ee/ci/variables/\"\u003eVariables\u003c/a\u003e and \u003ca href=\"https://docs.gitlab.com/ee/ci/variables/predefined_variables.html\"\u003ePredefined variables\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.gitlab.com/ee/ci/docker/using_docker_images.html\"\u003eUsing docker images\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.gitlab.com/ee/ci/docker/using_docker_build.html\"\u003eBuild docker images\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eI hope you enjoyed it and hope to see you on \u003ca href=\"https://twitter.com/kainlite\"\u003etwitter\u003c/a\u003e or \u003ca href=\"https://github.com/kainlite\"\u003egithub\u003c/a\u003e!\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/cat_and_friends_netcat_socat/",
      "url": "https://legacy.techsquad.rocks/blog/cat_and_friends_netcat_socat/",
      "title": "Cat and friends (Netcat and Socat)",
      "date_published": "2020-01-20T00:00:00Z",
      "tags": ["networking","linux"],
      "content_html": "\u003ch4 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIn this article we will see how to use \u003ccode\u003ecat\u003c/code\u003e, \u003ccode\u003enetcat\u003c/code\u003e and \u003ccode\u003esocat\u003c/code\u003e at least some basic examples and why do we have so many cats\u0026hellip;\u003c/p\u003e\n\u003cp\u003eAlso sorry for the awful recordings, but couldn\u0026rsquo;t figure out why it looks so bad with tmux.\u003c/p\u003e\n\u003ch4 id=\"cat\"\u003e\u003cstrong\u003ecat\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eCat as you might have guessed or know already is to con-cat-enate things, when used in conjunction with the shell redirections it can do a lot of powerful things but it\u0026rsquo;s often used when it\u0026rsquo;s not needed due to that, let\u0026rsquo;s see some examples.\u003c/p\u003e\n\u003cscript src=\"https://asciinema.org/a/a48k8B7cUHXPsK0aJ3QNfL1zd.js\" async data-preload=\"true\" data-speed=\"2\" data-size=\"small\" data-cols=\"120\" data-rows=\"20\" id=\"asciicast-a48k8B7cUHXPsK0aJ3QNfL1zd\" async\u003e\u003c/script\u003e\n\u003cp\u003eSo what happened there? Basically when you want to end the file or the input you send the keyword Ctrl+D, when typed at the start of a line on a terminal, signifies the end of the input. This is not a signal in the unix sense: when an application is reading from the terminal and the user presses Ctrl+D, the application is notified that the end of the file has been reached (just like if it was reading from a file and had passed the last byte). This can be used also to terminate ssh sessions or just log you out from a terminal.\u003c/p\u003e\n\u003cp\u003eIf you want to copy and paste something there you go:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/bb03d32945ca285572a17e974deffee9.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eWhile cat is overly simplified here, it can do a lot of interesting things and it is usually misused \u003ca href=\"http://porkmail.org/era/unix/award.html\"\u003esee here\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMore info:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.tecmint.com/13-basic-cat-command-examples-in-linux/\"\u003eCat examples\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Redirections\"\u003eBash redirections\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://zsh.sourceforge.net/Doc/Release/Redirection.html\"\u003eZsh redirections\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"netcat\"\u003e\u003cstrong\u003enetcat\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eNetcat is a bit more interesting since it can use the network and it\u0026rsquo;s really simple also, so it let us use network sockets without too much complication, let\u0026rsquo;s see a couple of examples, first we spin up a server (listener), then connect from the other side and send some data, be aware that connections are bi-directional then Ctrl-C to finish the process. Then in the second example we spin up a server and wait for a compressed file to be sent from the client.\u003c/p\u003e\n\u003cscript src=\"https://asciinema.org/a//aRoZYNLIr1EwCLYBpyhY5N2iC.js\" async data-preload=\"true\" data-speed=\"2\" data-size=\"small\" data-cols=\"125\" data-rows=\"40\" data-loop=\"true\" id=\"asciicast-aRoZYNLIr1EwCLYBpyhY5N2iC\" async\u003e\u003c/script\u003e\n\u003cp\u003eThere are many more things that you can do with netcat and is usually really helpful to debug networking issues or to do a quick copy of files over the network.\u003c/p\u003e\n\u003cp\u003eIf you want to copy and paste something there you go:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/0a37bfba1ae350695790b7f5c842df63.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eNetcat is pretty good at it\u0026rsquo;s job and it\u0026rsquo;s always a good tool to have at hand, but there are other more complex tasks with sockets and for that we have socat.\u003c/p\u003e\n\u003cp\u003eMore info:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.varonis.com/blog/netcat-commands/\"\u003eMany uses for netcat (with a cheatsheet)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.poftut.com/netcat-nc-command-tutorial-examples/\"\u003eSeveral examples\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"socat\"\u003e\u003cstrong\u003esocat\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eSocat is a command line based utility that establishes two bidirectional byte streams and transfers data between them. Because the streams can be constructed from a large set of different types of data sinks and sources (see address types), and because lots of address options may be applied to the streams, socat can be used for many different purposes. That bit was extracted from the man page, socat stands for SOcket CAT and it\u0026rsquo;s a multipurpose relay, we will see a few examples to clarify on what that means and some cool stuff that you can use socat for, at first it might look a bit intimidating, but trust me it worth learning to use it.\u003c/p\u003e\n\u003cp\u003eSomething to have in mind when using socat it\u0026rsquo;s that it needs two addresses, sometimes you can skip them with a \u003ccode\u003e-\u003c/code\u003e. While socat has a gazillion more use cases than cat or netcat, I will just show you a few, but hand you a few links in case you are interested in learning more, what I find particularly useful it\u0026rsquo;s the ability to do a port-forward in just one line.\u003c/p\u003e\n\u003cscript src=\"https://asciinema.org/a/HUuq9N8wUqZFhSKPGkpMKKzzg.js\" async data-preload=\"true\" data-speed=\"2\" data-size=\"small\" data-cols=\"125\" data-rows=\"40\" data-loop=\"true\" id=\"asciicast-HUuq9N8wUqZFhSKPGkpMKKzzg\" async\u003e\u003c/script\u003e\n\u003cp\u003eBasically with socat your imagination is the limit in what you can do.\u003c/p\u003e\n\u003cp\u003eIf you want to copy and paste something there you go:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/27d5f53a45f6da4a65f1a94fa4dfeda5.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eMore info:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/craSH/socat/blob/master/EXAMPLES\"\u003eSocat Examples (great resource)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.poftut.com/linux-multipurpose-relay-socat-command-tutorial-with-examples/\"\u003eMore socat examples\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.cyberciti.biz/faq/linux-unix-tcp-port-forwarding/\"\u003eLinux unix TCP Port Forwarder\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eBe sure to check the links if you want to learn more about each different tool and I hope you enjoyed it, see you on \u003ca href=\"https://twitter.com/kainlite\"\u003etwitter\u003c/a\u003e or \u003ca href=\"https://github.com/kainlite\"\u003egithub\u003c/a\u003e!\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/cloud_native_applications_with_kubebuilder_and_kind_aka_kubernetes_operators/",
      "url": "https://legacy.techsquad.rocks/blog/cloud_native_applications_with_kubebuilder_and_kind_aka_kubernetes_operators/",
      "title": "Cloud native applications with kubebuilder and kind aka kubernetes operators",
      "date_published": "2020-01-17T00:00:00Z",
      "tags": ["go","golang","kubernetes","linux","security","docker","kustomize","kubebuilder","kind"],
      "content_html": "\u003ch5 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eIn this article we will see how to use \u003ca href=\"https://github.com/kubernetes-sigs/kubebuilder\"\u003ekubebuilder\u003c/a\u003e and \u003ca href=\"https://github.com/kubernetes-sigs/kind\"\u003eKind\u003c/a\u003e to create a local test cluster and an operator, then deploy that operator in the cluster and test it, the repository with the files can be found here, also if you want to learn more about the idea and the project go: \u003ca href=\"https://github.com/kainlite/forward\"\u003eforward\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eBasically what the code does is create an alpine/socat pod and you can specify the host, port and protocol and it will make a tunnel for you, so then you can use port-forward or a service or ingress or whatever to expose things that are in another private subnet, while this might not sound like a good idea it has some use cases, so check your security constraints before doing any of that in a normal scenario it should be safe, it can be useful for testing or for reaching a DB while doing some debugging or test, but well, that is for another discussion, the tools used here is what makes this so interesting, this is a cloud native application, since it native to kubernetes and that\u0026rsquo;s what we will explore here.\u003c/p\u003e\n\u003cp\u003eWhile Kind is not actually a requirement I used that for testing and really liked it, it\u0026rsquo;s faster and simpler than minikube.\u003c/p\u003e\n\u003cp\u003eAlso if you are interested how I got the idea to make this operator check this \u003ca href=\"https://github.com/kubernetes/kubernetes/issues/72597\"\u003egithub issue\u003c/a\u003e.\u003c/p\u003e\n\u003ch5 id=\"prerequisites\"\u003e\u003cstrong\u003ePrerequisites\u003c/strong\u003e\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/kubebuilder\"\u003ekubebuilder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/kustomize\"\u003ekustomize\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://golang.org/dl/\"\u003eGo 1.13\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/kind\"\u003eKind\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hub.docker.com/?overlay=onboarding\"\u003eDocker\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"create-the-project\"\u003eCreate the project\u003c/h5\u003e\n\u003cp\u003eIn this step we need to create the kubebuilder project, so in an empty folder we run:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/fcb512051b1f9aa1abb7ee9d8fd177f5.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"create-the-api\"\u003eCreate the API\u003c/h5\u003e\n\u003cp\u003eNext let\u0026rsquo;s create an API, something for us to have control of (our controller).\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/99c415e6bbaf6d92b2c971acddc42221.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eRight until here we only have some boilerplate and basic or empty project with defaults, if you test it now it will work, but it won\u0026rsquo;t do anything interesting, but it covers a lot of ground and we should be grateful that such a tool exists.\u003c/p\u003e\n\u003ch5 id=\"add-our-code-to-the-mix\"\u003eAdd our code to the mix\u003c/h5\u003e\n\u003cp\u003eFirst we will add it to \u003ccode\u003eapi/v1beta1/map_types.go\u003c/code\u003e, which will add our fields to our type.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/6e823ba4160fb12b9414494c9b16be7b.js\"\u003e\u003c/script\u003e\n\nBasically we just edited the \u003ccode\u003eMapSpec\u003c/code\u003e and the \u003ccode\u003eMapStatus\u003c/code\u003e struct.\u003c/p\u003e\n\u003cp\u003eNow we need to add the code to our controller in \u003ccode\u003econtrollers/map_controller.go\u003c/code\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d2e59c468a6864a96647054ac616285d.js\"\u003e\u003c/script\u003e\n\nIn this controller we added two functions one to create a pod and modified basically the entire Reconcile function (this one takes care of checking the status and make the transitions in other words makes a controller work like a controller), also notice the kubebuilder annotations which will generate the rbac config for us, pretty handy! right?\u003c/p\u003e\n\u003ch5 id=\"starting-the-cluster\"\u003eStarting the cluster\u003c/h5\u003e\n\u003cp\u003eNow we will use \u003ca href=\"https://github.com/kubernetes-sigs/kind\"\u003eKind\u003c/a\u003e to create a local cluster to test\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/3d5c7eb58a0ede8e34f0824d927deeca.js\"\u003e\u003c/script\u003e\n\nit could be that easy!?!?! yes, it is!\u003c/p\u003e\n\u003ch5 id=\"running-our-operator-locally\"\u003eRunning our operator locally\u003c/h5\u003e\n\u003cp\u003eFor testing you can run your operator locally like this:\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/8184c8ae455e033602b81965cacf593b.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"testing-it\"\u003eTesting it\u003c/h5\u003e\n\u003cp\u003eFirst we spin up a pod, and launch \u003ccode\u003enc -l -p 8000\u003c/code\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d940b280bd2f3fdf732b9b259e9da841.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003cp\u003eThen we edit our manifest and apply it, check that everything is in place, and do the port-forward and launch another \u003ccode\u003enc localhost 8000\u003c/code\u003e to test if everything went well.\nFirst the manifest\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d609ef25c2bc621d365781e6f3d9826b.js\"\u003e\u003c/script\u003e\n\nThen the port-forward and test\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/d9455e6a17b2a396f486d48cf159f5f2.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"making-it-publicly-ready\"\u003eMaking it publicly ready\u003c/h5\u003e\n\u003cp\u003eHere we just build and push the docker image to dockerhub or our favorite public registry.\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/c45158dd378d09b82c8153dbdd122953.js\"\u003e\u003c/script\u003e\n\nThen you can install it with \u003ccode\u003emake deploy IMG=kainlite/forward:0.0.1\u003c/code\u003e and uninstall it with \u003ccode\u003emake uninstall\u003c/code\u003e\u003c/p\u003e\n\u003ch5 id=\"closing-notes\"\u003e\u003cstrong\u003eClosing notes\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eBe sure to check the \u003ca href=\"https://book.kubebuilder.io/\"\u003ekubebuilder book\u003c/a\u003e if you want to learn more and the \u003ca href=\"https://kind.sigs.k8s.io/docs/user/quick-start\"\u003ekind docs\u003c/a\u003e, I hope you enjoyed it and hope to see you on \u003ca href=\"https://twitter.com/kainlite\"\u003etwitter\u003c/a\u003e or \u003ca href=\"https://github.com/kainlite\"\u003egithub\u003c/a\u003e!\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/how_to_report_spam_to_spamcop_from_gmail/",
      "url": "https://legacy.techsquad.rocks/blog/how_to_report_spam_to_spamcop_from_gmail/",
      "title": "How to report spam to spamcop from gmail",
      "date_published": "2020-01-04T00:00:00Z",
      "tags": ["linux"],
      "content_html": "\u003ch5 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eEasy method to report spam to \u003ca href=\"https://www.spamcop.net/\"\u003eSpamCop.net\u003c/a\u003e using GMail, this helps to reduce the true Spam from unknown sources, since for some reason I started to get like 40 emails per day (all went to spam), but it is still somewhat annoying, so I started reporting it to spamcop, this alternative method doesn\u0026rsquo;t need a script and it\u0026rsquo;s really easy to do as well, same result as with the script from \u003ca href=\"https://techsquad.rocks/blog/how_to_report_your_gmail_spam_folder_to_spamcop/\"\u003ethe previous post\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePre-requisites:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGMail account\u003c/li\u003e\n\u003cli\u003eSetup a spamcop account which you will be using to send your reports, you can do that \u003ca href=\"https://www.spamcop.net/anonsignup.shtml\"\u003ehere\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"forwarding-as-attachment\"\u003e\u003cstrong\u003eForwarding as attachment\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eFirst of all you need to select all emails and then click on the three dots and select \u0026ldquo;Forward as attachment\u0026rdquo;\n\u003cfigure\u003e\u003cimg src=\"/img/spamcop-1.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"sending-it-to-your-spamcop-email\"\u003e\u003cstrong\u003eSending it to your spamcop email\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eIn this step the only thing that you need to do is put your Spamcop email (it gives you this address to report spam when you create the account and in the report spam tab), you do not need to put anything in the body or the subject, just send it as is.\n\u003cfigure\u003e\u003cimg src=\"/img/spamcop-2.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"confirming-each-one\"\u003e\u003cstrong\u003eConfirming each one\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eThen you will get an email with a link to each spam message to submit the report.\n\u003cfigure\u003e\u003cimg src=\"/img/spamcop-3.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch5 id=\"sending-the-reports\"\u003e\u003cstrong\u003eSending the reports\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eThis is a sample report, you can add additional notes if needed and then confirm to send it to the abuse addresses of the owners of the IPs and links found in the email.\n\u003cfigure\u003e\u003cimg src=\"/img/spamcop-4.png\" width=\"100%\"/\u003e\n\u003c/figure\u003e\n\u003c/p\u003e\n\u003ch3 id=\"additional-notes\"\u003eAdditional notes\u003c/h3\u003e\n\u003cp\u003eThis method is pretty easy for someone who doesn\u0026rsquo;t want to run a script or whatever and is still able to report the spam to the sources, however if you want something a bit less manual you can try with the script or just create a filter to delete everything in the spam folder.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://legacy.techsquad.rocks/blog/how_to_report_your_gmail_spam_folder_to_spamcop/",
      "url": "https://legacy.techsquad.rocks/blog/how_to_report_your_gmail_spam_folder_to_spamcop/",
      "title": "How to report your gmail spam folder to spamcop",
      "date_published": "2019-12-31T00:00:00Z",
      "tags": ["development","golang","go","linux"],
      "content_html": "\u003ch5 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eThis post is a bit different from the others in the sense that it\u0026rsquo;s a small \u0026ldquo;tool\u0026rdquo; I did to ease spam reporting to \u003ca href=\"https://www.spamcop.net/\"\u003eSpamCop.net\u003c/a\u003e, this helps to reduce the true Spam from unknown sources, since for some reason I started to get like 40 emails per day (all went to spam), but it is still somewhat annoying, so I started reporting it to spamcop, but the process was kind of slow and I got tired of that quickly, so I created this \u0026ldquo;script\u0026rdquo; to make things easier. Basically what it does is list all messages in the spam folders fetches them and then forwards each one as an attachment to spamcop, then you get an email with a link to confirm the submission and that\u0026rsquo;s it.\u003c/p\u003e\n\u003cp\u003eThere are a few pre-requisites, like enabling the GMail API for your account, you can do that \u003ca href=\"https://developers.google.com/gmail/api/quickstart/go#step_1_turn_on_the\"\u003ehere\u003c/a\u003e, after that the first time you use the app you have to authorize it, you do this by pasting the URL that the app gives you in the browser, then clicking Allow, and then pasting the token that it gives you back in the terminal (this only needs to be done once), after that you just run the binary in a cronjob or maybe even as a lambda (but I haven\u0026rsquo;t gone there yet), I usually check the spam folder remove what I don\u0026rsquo;t think it\u0026rsquo;s spam or whatever and then run the script to report everything else that it is clearly spam, it takes a few seconds and then I get the link to confirm all reports (one by one, sadly), this script is not perfect as sometimes spamcop cannot read properly the forwarded email, but I have checked exporting those as a file and I do see them all right, so that will be an investigation for another day, this only took like 2-4 hours, having 0 knowledge of the GMail API, etc.\u003c/p\u003e\n\u003cp\u003eAlso you need to setup a spamcop account which you will be using to send your reports, you can do that \u003ca href=\"https://www.spamcop.net/anonsignup.shtml\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe source code can be found \u003ca href=\"https://github.com/kainlite/spamcop\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch5 id=\"code\"\u003e\u003cstrong\u003eCode\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eI have added some comments along the code to make things easy to understand\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/557731e9b398e593fc6a176cd9f705e5.js\"\u003e\u003c/script\u003e\n\u003c/p\u003e\n\u003ch5 id=\"running-it\"\u003e\u003cstrong\u003eRunning it\u003c/strong\u003e\u003c/h5\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/kainlite/244d04580a8ca63e4bbecdcecd649840.js\"\u003e\u003c/script\u003e\n\n\u003ch5 id=\"sources\"\u003e\u003cstrong\u003eSources\u003c/strong\u003e\u003c/h5\u003e\n\u003cp\u003eSome articles, pages, and files that I used and helped me to do what I wanted to do:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://developers.google.com/gmail/api/quickstart/go\"\u003ehttps://developers.google.com/gmail/api/quickstart/go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/gsuitedevs/go-samples/blob/master/gmail/quickstart/quickstart.go\"\u003ehttps://github.com/gsuitedevs/go-samples/blob/master/gmail/quickstart/quickstart.go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://socketloop.com/tutorials/golang-send-email-with-attachment-rfc2822-using-gmail-api-example\"\u003ehttps://socketloop.com/tutorials/golang-send-email-with-attachment-rfc2822-using-gmail-api-example\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://raw.githubusercontent.com/googleapis/google-api-go-client/master/examples/gmail.go\"\u003ehttps://raw.githubusercontent.com/googleapis/google-api-go-client/master/examples/gmail.go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/xDinomode/Go-Gmail-Api-Example/blob/master/email.go\"\u003ehttps://github.com/xDinomode/Go-Gmail-Api-Example/blob/master/email.go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.spamcop.net/reporter.pl\"\u003ehttps://www.spamcop.net/reporter.pl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://godoc.org/google.golang.org/api/gmail/v1#Message\"\u003ehttps://godoc.org/google.golang.org/api/gmail/v1#Message\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"additional-notes\"\u003eAdditional notes\u003c/h3\u003e\n\u003cp\u003eWhile this still needs some work hopefully will keep my account clean and probably help someone wondering about how to do the same.\u003c/p\u003e\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }
  ]
}
