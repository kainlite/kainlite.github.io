{
  "version": "https://jsonfeed.org/version/1",
  "title": "Tech experiments",
  "home_page_url": "https://kainlite.github.io/",
  "feed_url": "https://kainlite.github.io/index.json",
  "items": [
    
    {
      "id": "https://kainlite.github.io/blog/getting_started_with_skaffold/",
      "url": "https://kainlite.github.io/blog/getting_started_with_skaffold/",
      "title": "Getting started with skaffold",
      "date_published": "2019-01-03T00:00:00Z",
      "content_html": "\n\n\u003ch3 id=\"skaffold\"\u003e\u003cstrong\u003eSkaffold\u003c/strong\u003e\u003c/h3\u003e\n\n\u003cp\u003eThis time we will see how to get started with \u003ca href=\"https://github.com/GoogleContainerTools/skaffold\"\u003eSkaffold\u003c/a\u003e, it seems a relatively mature project, and it does a lot more than some of the previous explored alternatives: \u003cem\u003eSkaffold is a command line tool that facilitates continuous development for Kubernetes applications. You can iterate on your application source code locally then deploy to local or remote Kubernetes clusters. Skaffold handles the workflow for building, pushing and deploying your application. It also provides building blocks and describe customizations for a CI/CD pipeline.\u003c/em\u003e (Extracted from \u003ca href=\"https://github.com/GoogleContainerTools/skaffold\"\u003egithub\u003c/a\u003e)\u003c/p\u003e\n\n\u003cp\u003eIn this example I will be using \u003ca href=\"https://m.do.co/c/01d040b789de\"\u003eDigital Ocean\u003c/a\u003e (that\u0026rsquo;s my referral link), note that I do not have any association with Digital Ocean but they give you $100 to test their products for 60 days, if you spend $25 I get another $25, I got the idea from \u003ca href=\"https://www.youtube.com/watch?v=fhYSKEy0s8w\"\u003ePelado Nerd Spanish Youtube Channel\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch3 id=\"let-s-get-started\"\u003eLet\u0026rsquo;s get started\u003c/h3\u003e\n\n\u003cp\u003eOnce you have created your account and added your credit card you will get the $100 of free credit, then you will have to go to Manage on the left side panel and click on Kubernetes, then create your cluster with the amount of nodes that you consider necessary but remember to power them off or delete these resources so you don\u0026rsquo;t waste the free credit or your credit card itself. Once you have created your cluster and downloaded the kubectl config you\u0026rsquo;re ready to go.\u003c/p\u003e\n\n\u003cp\u003eWe will be working with the chat bot again you can see the original \u003ca href=\"https://kainlite.github.io/blog/go_echobot/\"\u003earticle here\u003c/a\u003e, and the repo \u003ca href=\"https://github.com/kainlite/echobot/tree/skaffold\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s tell our kubectl to use our recently downloaded config:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ export KUBECONFIG=/home/kainlite/Downloads/k8s-1-13-1-do-2-nyc1-1546545313076-kubeconfig.yaml\n$ kubectl get nodes -o wide\n\nNAME                 STATUS    ROLES     AGE       VERSION   EXTERNAL-IP       OS-IMAGE                       KERNEL-VERSION   CONTAINER-RUNTIME\ncrazy-wozniak-8306   Ready     \u0026lt;none\u0026gt;    6h        v1.13.1   178.128.154.205   Debian GNU/Linux 9 (stretch)   4.9.0-8-amd64    docker://18.9.0\ncrazy-wozniak-830t   Ready     \u0026lt;none\u0026gt;    6h        v1.13.1   167.99.224.115    Debian GNU/Linux 9 (stretch)   4.9.0-8-amd64    docker://18.9.0\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eYour config might have a slightly different name, but it should be similar. We can see in the output a lot of information about our nodes (workers).\u003c/p\u003e\n\n\u003cp\u003eBut let\u0026rsquo;s cut to the chase, we are here for \u003cem\u003eSkaffold\u003c/em\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003ecurl -Lo skaffold https://storage.googleapis.com/skaffold/releases/v0.20.0/skaffold-linux-amd64 \u0026amp;\u0026amp; chmod +x skaffold \u0026amp;\u0026amp; sudo mv skaffold /usr/local/bin\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eYou can install the binary using the provided line (linux) or downloading it from the \u003ca href=\"https://github.com/GoogleContainerTools/skaffold/releases\"\u003ereleases page\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eOnce installed we can see the \u003ca href=\"https://github.com/GoogleContainerTools/skaffold/tree/master/examples\"\u003eexamples\u003c/a\u003e, I will be using the getting-started example:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003eapiVersion: skaffold/v1beta2\nkind: Config\nbuild:\n  artifacts:\n  - image: kainlite/echobot\ndeploy:\n  kubectl:\n    manifests:\n      - k8s-*\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eYAML lovers, there you go with some of it.\u003c/p\u003e\n\n\u003cp\u003eWe need a manifest file that matches that pattern so skaffold can deploy/re-deploy our application, so let\u0026rsquo;s generate one with \u003ccode\u003ekubectl run echobot --image=kainlite/echobot --dry-run -o yaml\u003c/code\u003e\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003eapiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    run: echobot\n  name: echobot\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: echobot\n  strategy: {}\n  template:\n    metadata:\n      labels:\n        run: echobot\n    spec:\n      containers:\n      - image: kainlite/echobot\n        name: echobot\n        env:\n        - name: SLACK_API_TOKEN\n          value: really_long_token\n        livenessProbe:\n          exec:\n            command:\n            - '/bin/sh'\n            - '-c'\n            - '/app/health_check.sh'\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe above command can be used to generate any kind of k8s resource :), I stripped it a bit, because there were fields that I didn\u0026rsquo;t want in and added some that we need for it to work.\u003c/p\u003e\n\n\u003cp\u003eThen the only thing left to do is testing that everything works properly:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ skaffold build\n\nStarting build...\nBuilding [kainlite/echobot]...\nSending build context to Docker daemon  66.56kB\nStep 1/12 : FROM golang:1.11.2-alpine as builder\n ---\u0026gt; 57915f96905a\nStep 2/12 : WORKDIR /app\n ---\u0026gt; Using cache\n ---\u0026gt; e04488a7f16b\nStep 3/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app \u0026amp;\u0026amp;     apk add git \u0026amp;\u0026amp; apk add gcc musl-dev\n ---\u0026gt; Running in 1339601fff6f\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz\n(1/6) Installing nghttp2-libs (1.32.0-r0)\n(2/6) Installing libssh2 (1.8.0-r3)\n(3/6) Installing libcurl (7.61.1-r1)\n(4/6) Installing expat (2.2.5-r0)\n(5/6) Installing pcre2 (10.31-r0)\n(6/6) Installing git (2.18.1-r0)\nExecuting busybox-1.28.4-r1.trigger\nOK: 19 MiB in 20 packages\n(1/12) Installing binutils (2.30-r5)\n(2/12) Installing gmp (6.1.2-r1)\n(3/12) Installing isl (0.18-r0)\n(4/12) Installing libgomp (6.4.0-r9)\n(5/12) Installing libatomic (6.4.0-r9)\n(6/12) Installing pkgconf (1.5.3-r0)\n(7/12) Installing libgcc (6.4.0-r9)\n(8/12) Installing mpfr3 (3.1.5-r1)\n(9/12) Installing mpc1 (1.0.3-r1)\n(10/12) Installing libstdc++ (6.4.0-r9)\n(11/12) Installing gcc (6.4.0-r9)\n(12/12) Installing musl-dev (1.1.19-r10)\nExecuting busybox-1.28.4-r1.trigger\nOK: 113 MiB in 32 packages\n ---\u0026gt; 0e7a97e577dc\nStep 4/12 : ADD . /app/\n ---\u0026gt; 72cfd4dea99b\nStep 5/12 : RUN go get -d -v ./... \u0026amp;\u0026amp; go build -o main . \u0026amp;\u0026amp; chown -R app:app /app /home/app\n ---\u0026gt; Running in 4482bfd3e8f7\ngo: finding github.com/gorilla/websocket v1.4.0\ngo: finding github.com/nlopes/slack v0.4.0\ngo: finding github.com/pkg/errors v0.8.0\ngo: downloading github.com/nlopes/slack v0.4.0\ngo: downloading github.com/pkg/errors v0.8.0\ngo: downloading github.com/gorilla/websocket v1.4.0\n ---\u0026gt; 8ea604c7fb37\nStep 6/12 : FROM golang:1.11.2-alpine\n ---\u0026gt; 57915f96905a\nStep 7/12 : WORKDIR /app\n ---\u0026gt; Using cache\n ---\u0026gt; e04488a7f16b\nStep 8/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app\n ---\u0026gt; Using cache\n ---\u0026gt; 33b206dba7e4\nStep 9/12 : COPY --from=builder --chown=app /app/health_check.sh /app/health_check.sh\n ---\u0026gt; Using cache\n ---\u0026gt; 34d3cd1a5bb0\nStep 10/12 : COPY --from=builder --chown=app /app/main /app/main\n ---\u0026gt; Using cache\n ---\u0026gt; 0c3d838b25dc\nStep 11/12 : USER app\n ---\u0026gt; Using cache\n ---\u0026gt; 95c2bf90800c\nStep 12/12 : CMD [\u0026quot;/app/main\u0026quot;]\n ---\u0026gt; Using cache\n ---\u0026gt; 3541257ff16c\nSuccessfully built 3541257ff16c\nSuccessfully tagged 1fca8a8c999a8cd9b943456b70d90807:latest\nThe push refers to repository [docker.io/kainlite/echobot]\nee06a8f42495: Preparing\n12468476a0ef: Preparing\nec122f36b39d: Preparing\ne94f3271cc73: Preparing\n93391cb9fd4b: Preparing\ncb9d0f9550f6: Preparing\n93448d8c2605: Preparing\nc54f8a17910a: Preparing\ndf64d3292fd6: Preparing\ncb9d0f9550f6: Waiting\nc54f8a17910a: Waiting\n93448d8c2605: Waiting\ne94f3271cc73: Layer already exists\n93391cb9fd4b: Layer already exists\n12468476a0ef: Layer already exists\nec122f36b39d: Layer already exists\nee06a8f42495: Layer already exists\n93448d8c2605: Layer already exists\ncb9d0f9550f6: Layer already exists\ndf64d3292fd6: Layer already exists\nc54f8a17910a: Layer already exists\nfc03e3d-dirty-3541257: digest: sha256:99c6d3d5b226a1947e8f96c0a5f963c8e499848d271f121ad50551046a0dc7ca size: 2197\nBuild complete in 48.642618413s\nStarting test...\nTest complete in 9.15Âµs\nkainlite/echobot -\u0026gt; kainlite/echobot:fc03e3d-dirty-3541257\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAs we can see skaffold build not only did the docker build but also tagged and pushed the image to \u003ca href=\"https://cloud.docker.com/repository/docker/kainlite/echobot/tags\"\u003edocker hub\u003c/a\u003e, which is really nice and really useful to build a CI/CD system with it.\u003c/p\u003e\n\n\u003cp\u003eBut wait, we need to deploy that to our cluster, right on:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ skaffold deploy\nStarting build...\nBuilding [kainlite/echobot]...\nSending build context to Docker daemon  66.56kB\nStep 1/12 : FROM golang:1.11.2-alpine as builder\n ---\u0026gt; 57915f96905a\nStep 2/12 : WORKDIR /app\n ---\u0026gt; Using cache\n ---\u0026gt; e04488a7f16b\nStep 3/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app \u0026amp;\u0026amp;     apk add git \u0026amp;\u0026amp; apk add gcc musl-dev\n ---\u0026gt; Using cache\n ---\u0026gt; 0e7a97e577dc\nStep 4/12 : ADD . /app/\n ---\u0026gt; Using cache\n ---\u0026gt; 72cfd4dea99b\nStep 5/12 : RUN go get -d -v ./... \u0026amp;\u0026amp; go build -o main . \u0026amp;\u0026amp; chown -R app:app /app /home/app\n ---\u0026gt; Using cache\n ---\u0026gt; 8ea604c7fb37\nStep 6/12 : FROM golang:1.11.2-alpine\n ---\u0026gt; 57915f96905a\nStep 7/12 : WORKDIR /app\n ---\u0026gt; Using cache\n ---\u0026gt; e04488a7f16b\nStep 8/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app\n ---\u0026gt; Using cache\n ---\u0026gt; 33b206dba7e4\nStep 9/12 : COPY --from=builder --chown=app /app/health_check.sh /app/health_check.sh\n ---\u0026gt; Using cache\n ---\u0026gt; 34d3cd1a5bb0\nStep 10/12 : COPY --from=builder --chown=app /app/main /app/main\n ---\u0026gt; Using cache\n ---\u0026gt; 0c3d838b25dc\nStep 11/12 : USER app\n ---\u0026gt; Using cache\n ---\u0026gt; 95c2bf90800c\nStep 12/12 : CMD [\u0026quot;/app/main\u0026quot;]\n ---\u0026gt; Using cache\n ---\u0026gt; 3541257ff16c\nSuccessfully built 3541257ff16c\nSuccessfully tagged 510226574761304cc9d64a343d5bdbff:latest\nThe push refers to repository [docker.io/kainlite/echobot]\nee06a8f42495: Preparing\n12468476a0ef: Preparing\nec122f36b39d: Preparing\ne94f3271cc73: Preparing\n93391cb9fd4b: Preparing\ncb9d0f9550f6: Preparing\n93448d8c2605: Preparing\nc54f8a17910a: Preparing\ndf64d3292fd6: Preparing\ncb9d0f9550f6: Waiting\n93448d8c2605: Waiting\nc54f8a17910a: Waiting\ndf64d3292fd6: Waiting\n12468476a0ef: Layer already exists\ne94f3271cc73: Layer already exists\ncb9d0f9550f6: Layer already exists\nec122f36b39d: Layer already exists\n93391cb9fd4b: Layer already exists\nee06a8f42495: Layer already exists\nc54f8a17910a: Layer already exists\ndf64d3292fd6: Layer already exists\n93448d8c2605: Mounted from library/golang\nfc03e3d-dirty-3541257: digest: sha256:99c6d3d5b226a1947e8f96c0a5f963c8e499848d271f121ad50551046a0dc7ca size: 2197\nBuild complete in 15.136865292s\nStarting test...\nTest complete in 17.912Âµs\nStarting deploy...\nkubectl client version: 1.10\nkubectl version 1.12.0 or greater is recommended for use with skaffold\ndeployment.extensions \u0026quot;echobot\u0026quot; configured\nDeploy complete in 5.676513226s\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eDeploy does a lot like with gitkube, it build the image, pushes it to the registry and then makes the deployment to the cluster, as you can see in there skaffold relies on kubectl and I have an old version of it.\u003c/p\u003e\n\n\u003cp\u003eAfter a few seconds we can see that our deployment has been triggered and we have a new pod being created for it.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ kubectl get pods\nNAME                       READY     STATUS              RESTARTS   AGE\nechobot-57fdcccf76-4qwvq   0/1       ContainerCreating   0          5s\nechobot-6fcd78658c-njvpx   0/1       Terminating         0          9m\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eSkaffold also has another nice option that it\u0026rsquo;s called \u003cem\u003edev\u003c/em\u003e it watches the folder for changes and re-deploys the app so you can focus on code.\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s clean up and call it a day:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003eskaffold delete\nCleaning up...\ndeployment.extensions \u0026quot;echobot\u0026quot; deleted\nCleanup complete in 3.833219278s\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3 id=\"notes\"\u003eNotes\u003c/h3\u003e\n\n\u003cp\u003eI really liked the workflow that skaffold provides, I hope that I can use it some more in the near future. And remember to shutdown the kubernetes cluster if you are using Digital Ocean so you don\u0026rsquo;t get charged by surprise later on.\u003c/p\u003e\n\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://kainlite.github.io/blog/getting_started_with_gitkube/",
      "url": "https://kainlite.github.io/blog/getting_started_with_gitkube/",
      "title": "Getting started with gitkube",
      "date_published": "2019-01-01T00:00:00Z",
      "content_html": "\n\n\u003ch3 id=\"gitkube\"\u003e\u003cstrong\u003eGitkube\u003c/strong\u003e\u003c/h3\u003e\n\n\u003cp\u003eThis time we will see how to get started with \u003ca href=\"https://gitkube.sh/\"\u003eGitkube\u003c/a\u003e, it\u0026rsquo;s a young project but it seems to work fine and it has an interesting approach compared to other alternatives, since it only relies on git and kubectl, other than that it\u0026rsquo;s just a \u003ca href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\"\u003eCRD\u003c/a\u003e and a controller, so you end up with 2 pods in kube-system one for the controller and the other for gitkubed, gitkubed is in charge of cloning your repos and also build the docker images, it seems that the idea behind gitkube is for the daily use in a dev/test environment where you need to try your changes quickly and without hassle. You can find more \u003ca href=\"https://github.com/hasura/gitkube-example\"\u003eexamples here\u003c/a\u003e, also be sure to check their page and documentation if you like it or want to learn more.\u003c/p\u003e\n\n\u003cp\u003eIn the examples I will be using \u003ca href=\"https://kubernetes.io/docs/tasks/tools/install-minikube\"\u003eminikube\u003c/a\u003e or you can \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003echeck out this repo\u003c/a\u003e that has a good overview of minikube, once installed and started (\u003ccode\u003eminikube start\u003c/code\u003e) that command will download and configure the local environment, if you have been following the previous posts you already have minikube installed and working, \u003cem\u003ebut in this post be sure to use \u003cem\u003eminikube tunnel\u003c/em\u003e\u003c/em\u003e if you configure gitkube with a load balancer (or if you configure any service type as load balancer):\u003c/p\u003e\n\n\u003ch3 id=\"let-s-get-started\"\u003eLet\u0026rsquo;s get started\u003c/h3\u003e\n\n\u003cp\u003eWe\u0026rsquo;re going to deploy or re-deploy our echo bot one more time but this time using gitkube.\nYou can find the chat bot: \u003ca href=\"https://kainlite.github.io/blog/go_echobot/\"\u003earticle here\u003c/a\u003e, and the repo: \u003ca href=\"https://github.com/kainlite/echobot/tree/gitkube\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eFirst of all we need to install the gitkube binary in our machine and then the CRD in our kubernetes cluster:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ kubectl create -f https://storage.googleapis.com/gitkube/gitkube-setup-stable.yaml\ncustomresourcedefinition.apiextensions.k8s.io \u0026quot;remotes.gitkube.sh\u0026quot; created\nserviceaccount \u0026quot;gitkube\u0026quot; created\nclusterrolebinding.rbac.authorization.k8s.io \u0026quot;gitkube\u0026quot; created\nconfigmap \u0026quot;gitkube-ci-conf\u0026quot; created\ndeployment.extensions \u0026quot;gitkubed\u0026quot; created\ndeployment.extensions \u0026quot;gitkube-controller\u0026quot; created\n\n$ kubectl --namespace kube-system expose deployment gitkubed --type=LoadBalancer --name=gitkubed\nservice \u0026quot;gitkubed\u0026quot; exposed\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eNote that there are 2 ways to install gitkube into our cluster, using the manifests as displayed there or using the gitkube binary and doing \u003ccode\u003egitkube install\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eTo install the gitkube binary, the easiest way is to do:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003ecurl https://raw.githubusercontent.com/hasura/gitkube/master/gimme.sh | sudo bash\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThis will download and copy the binary into: \u003ccode\u003e/usr/local/bin\u003c/code\u003e, as a general rule I recommend reading whatever you are going to pipe into bash in your terminal to avoid potential dangers of \u003cem\u003ethe internet\u003c/em\u003e.\u003c/p\u003e\n\n\u003cp\u003eThen we need to generate (and then create it in the cluster) a file called \u003ccode\u003eremote.yaml\u003c/code\u003e (or any name you like), it\u0026rsquo;s necessary in order to tell gitkube how to deploy our application once we \u003ccode\u003egit push\u003c/code\u003e it:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e$ gitkube remote generate -f remote.yaml\nRemote name: minikube\nnamespace: default\nSSH public key file: ~/.ssh/id_rsa.pub\nInitialisation: K8S YAML Manifests\nManifests/Chart directory: Enter\nChoose docker registry: docker.io/kainlite\nDeployment name: echobot\nContainer name: echobot\nDockerfile path: Dockerfile\nBuild context path: ./\nAdd another container? [y/N] Enter\nAdd another deployment? [y/N] Enter\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd this will yield the following \u003ccode\u003eremote.yaml\u003c/code\u003e file that we then need to create in our cluster as it is a custom resource it might look a bit different from the default kubernetes resources.\u003c/p\u003e\n\n\u003cp\u003eThe actual file \u003ccode\u003eremote.yaml\u003c/code\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003eapiVersion: gitkube.sh/v1alpha1\nkind: Remote\nmetadata:\n  creationTimestamp: null\n  name: minikube\n  namespace: default\nspec:\n  authorizedKeys:\n  - |\n    ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA8jvVVtDSVe25p2U2tDGQyVrnv3YcWjJc6AXTUMc0YNi+QDm6s+hMTwkf2wDRD7b6Y3kmgNSqLEE0EEgOkA69c8PgypM7AwbKZ51V9XcdPd7NyLabpomNiftpUwi01DGfBr25lJV9h2MHwsI/6w1izDvQyN7fAl+aTFgx+VGg1p4FygXWeBqm0n0DfHmBI7PDXxGbuFTJHUmRVS+HPd5Bi31S9Kq6eoodBWtV2MlVnZkpF67FWt2Xo2rFKVf4pZR4N1yjZKRsvIaI5i14LvtOoOqNQ+/tPMAFAif3AhldOW06fgnddYGi/iF+CatVttwNDWmClSOek9LO72UzR4s0xQ== gabriel@kainlite\n  deployments:\n  - containers:\n    - dockerfile: Dockerfile\n      name: echobot\n      path: ./\n    name: echobot\n  manifests:\n    helm: {}\n    path: \u0026quot;\u0026quot;\n  registry:\n    credentials:\n      secretKeyRef:\n        key: \u0026quot;\u0026quot;\n      secretRef: minikube-regsecret\n    url: docker.io/kainlite\nstatus:\n  remoteUrl: \u0026quot;\u0026quot;\n  remoteUrlDesc: \u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThere are a few details to have in mind here, the \u003cem\u003edeployment\u003c/em\u003e name because gitkube expects a deployment to be already present with that name in order to update/upgrade it, the path to the Dockerfile, or helm chart, credentials for the registry if any, I\u0026rsquo;m using a public image, so we don\u0026rsquo;t need any of that. The \u003cem\u003ewizard\u003c/em\u003e will let you choose and customize a few options for your deployment.\u003c/p\u003e\n\n\u003cp\u003eThe last step would be to finally create the resource:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ gitkube remote create -f remote.yaml\nINFO[0000] remote minikube created\nINFO[0000] waiting for remote url\nINFO[0000] remote url: ssh://default-minikube@10.98.213.202/~/git/default-minikube\n\n  # add the remote to your git repo and push:\n  git remote add minikube ssh://default-minikube@10.98.213.202/~/git/default-minikube\n  git push minikube master\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAfter adding the new remote called \u003cem\u003eminikube\u003c/em\u003e  we have everything ready to go, so let\u0026rsquo;s test it and see what happens:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ git push minikube master\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (10/10), done.\nWriting objects: 100% (10/10), 1.92 KiB | 1.92 MiB/s, done.\nTotal 10 (delta 2), reused 0 (delta 0)\nremote: Gitkube build system : Tue Jan  1 23:47:55 UTC 2019: Initialising\nremote:\nremote: Creating the build directory\nremote: Checking out 'master:a0265bc5d0229dce0cffc985ca22ebe28532ee95' to '/home/default-minikube/build/default-minikube'\nremote:\nremote: 1 deployment(s) found in this repo\nremote: Trying to build them...\nremote:\nremote: Building Docker image for : echobot\nremote:\nremote: Building Docker image : docker.io/kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95\nremote: Sending build context to Docker daemon   7.68kB\nremote: Step 1/12 : FROM golang:1.11.2-alpine as builder\nremote:  ---\u0026gt; 57915f96905a\nremote: Step 2/12 : WORKDIR /app\nremote: Removing intermediate container d2f9ab49935a\nremote:  ---\u0026gt; 997342e65c61\nremote: Step 3/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app \u0026amp;\u0026amp;     apk add git \u0026amp;\u0026amp; apk add gcc musl-dev\nremote:  ---\u0026gt; Running in f2aac9f74aad\nremote: fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz\nremote: fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz\nremote: (1/6) Installing nghttp2-libs (1.32.0-r0)\nremote: (2/6) Installing libssh2 (1.8.0-r3)\nremote: (3/6) Installing libcurl (7.61.1-r1)\nremote: (4/6) Installing expat (2.2.5-r0)\nremote: (5/6) Installing pcre2 (10.31-r0)\nremote: (6/6) Installing git (2.18.1-r0)\nremote: Executing busybox-1.28.4-r1.trigger\nremote: OK: 19 MiB in 20 packages\nremote: (1/12) Installing binutils (2.30-r5)\nremote: (2/12) Installing gmp (6.1.2-r1)\nremote: (3/12) Installing isl (0.18-r0)\nremote: (4/12) Installing libgomp (6.4.0-r9)\nremote: (5/12) Installing libatomic (6.4.0-r9)\nremote: (6/12) Installing pkgconf (1.5.3-r0)\nremote: (7/12) Installing libgcc (6.4.0-r9)\nremote: (8/12) Installing mpfr3 (3.1.5-r1)\nremote: (9/12) Installing mpc1 (1.0.3-r1)\nremote: (10/12) Installing libstdc++ (6.4.0-r9)\nremote: (11/12) Installing gcc (6.4.0-r9)\nremote: (12/12) Installing musl-dev (1.1.19-r10)\nremote: Executing busybox-1.28.4-r1.trigger\nremote: OK: 113 MiB in 32 packages\nremote: Removing intermediate container f2aac9f74aad\nremote:  ---\u0026gt; 7c6d8b9d1137\nremote: Step 4/12 : ADD . /app/\nremote:  ---\u0026gt; ca751c2678c4\nremote: Step 5/12 : RUN go get -d -v ./... \u0026amp;\u0026amp; go build -o main . \u0026amp;\u0026amp; chown -R app:app /app /home/app\nremote:  ---\u0026gt; Running in be54522345e4\nremote: go: finding github.com/gorilla/websocket v1.4.0\nremote: go: finding github.com/nlopes/slack v0.4.0\nremote: go: finding github.com/pkg/errors v0.8.0\nremote: go: downloading github.com/nlopes/slack v0.4.0\nremote: go: downloading github.com/gorilla/websocket v1.4.0\nremote: go: downloading github.com/pkg/errors v0.8.0\nremote: Removing intermediate container be54522345e4\nremote:  ---\u0026gt; 16e44978b140\nremote: Step 6/12 : FROM golang:1.11.2-alpine\nremote:  ---\u0026gt; 57915f96905a\nremote: Step 7/12 : WORKDIR /app\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 997342e65c61\nremote: Step 8/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app\nremote:  ---\u0026gt; Running in e578037b1d2f\nremote: Removing intermediate container e578037b1d2f\nremote:  ---\u0026gt; 55f48da0f9ac\nremote: Step 9/12 : COPY --from=builder --chown=app /app/health_check.sh /app/health_check.sh\nremote:  ---\u0026gt; 139250fd6c77\nremote: Step 10/12 : COPY --from=builder --chown=app /app/main /app/main\nremote:  ---\u0026gt; 2f1eb9f16e9f\nremote: Step 11/12 : USER app\nremote:  ---\u0026gt; Running in 5b53baa5ea2c\nremote: Removing intermediate container 5b53baa5ea2c\nremote:  ---\u0026gt; a72f27dccff2\nremote: Step 12/12 : CMD [\u0026quot;/app/main\u0026quot;]\nremote:  ---\u0026gt; Running in b12d58002f16\nremote: Removing intermediate container b12d58002f16\nremote:  ---\u0026gt; 034275449e08\nremote: Successfully built 034275449e08\nremote: Successfully tagged kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95\nremote: pushing docker.io/kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95 to registry\nremote: The push refers to repository [docker.io/kainlite/default-minikube-default.echobot-echobot]\nremote: bba61bf193fe: Preparing\nremote: 3f0355bbea40: Preparing\nremote: 2ebcdc9e5e8f: Preparing\nremote: 6f1324339fd4: Preparing\nremote: 93391cb9fd4b: Preparing\nremote: cb9d0f9550f6: Preparing\nremote: 93448d8c2605: Preparing\nremote: c54f8a17910a: Preparing\nremote: df64d3292fd6: Preparing\nremote: c54f8a17910a: Waiting\nremote: cb9d0f9550f6: Waiting\nremote: 93448d8c2605: Waiting\nremote: df64d3292fd6: Waiting\nremote: 93391cb9fd4b: Mounted from kainlite/echobot\nremote: 3f0355bbea40: Pushed\nremote: 2ebcdc9e5e8f: Pushed\nremote: cb9d0f9550f6: Mounted from kainlite/echobot\nremote: 93448d8c2605: Mounted from kainlite/echobot\nremote: 6f1324339fd4: Pushed\nremote: bba61bf193fe: Pushed\nremote: c54f8a17910a: Mounted from kainlite/echobot\nremote: df64d3292fd6: Mounted from kainlite/echobot\nremote: a0265bc5d0229dce0cffc985ca22ebe28532ee95: digest: sha256:3046c989fe1b1c4f700aaad875658c73ef571028f731546df38fb404ac22a9c9 size: 2198\nremote:\nremote: Updating Kubernetes deployment: echobot\nremote: Error from server (NotFound): deployments.extensions \u0026quot;echobot\u0026quot; not found\nTo ssh://10.98.213.202/~/git/default-minikube\n ! [remote rejected] master -\u0026gt; master (pre-receive hook declined)\nerror: failed to push some refs to 'ssh://default-minikube@10.98.213.202/~/git/default-minikube'\nkainlite@skynet-pc ~/Webs/echobot/code î  gitkube  $ git push minikube master\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (10/10), done.\nWriting objects: 100% (10/10), 1.92 KiB | 1.92 MiB/s, done.\nTotal 10 (delta 2), reused 0 (delta 0)\nremote: Gitkube build system : Tue Jan  1 23:50:58 UTC 2019: Initialising\nremote:\nremote: Creating the build directory\nremote: Checking out 'master:a0265bc5d0229dce0cffc985ca22ebe28532ee95' to '/home/default-minikube/build/default-minikube'\nremote:\nremote: 1 deployment(s) found in this repo\nremote: Trying to build them...\nremote:\nremote: Building Docker image for : echobot\nremote:\nremote: Building Docker image : docker.io/kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95\nremote: Sending build context to Docker daemon   7.68kB\nremote: Step 1/12 : FROM golang:1.11.2-alpine as builder\nremote:  ---\u0026gt; 57915f96905a\nremote: Step 2/12 : WORKDIR /app\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 997342e65c61\nremote: Step 3/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app \u0026amp;\u0026amp;     apk add git \u0026amp;\u0026amp; apk add gcc musl-dev\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 7c6d8b9d1137\nremote: Step 4/12 : ADD . /app/\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; ca751c2678c4\nremote: Step 5/12 : RUN go get -d -v ./... \u0026amp;\u0026amp; go build -o main . \u0026amp;\u0026amp; chown -R app:app /app /home/app\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 16e44978b140\nremote: Step 6/12 : FROM golang:1.11.2-alpine\nremote:  ---\u0026gt; 57915f96905a\nremote: Step 7/12 : WORKDIR /app\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 997342e65c61\nremote: Step 8/12 : RUN adduser -D -g 'app' app \u0026amp;\u0026amp;     chown -R app:app /app\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 55f48da0f9ac\nremote: Step 9/12 : COPY --from=builder --chown=app /app/health_check.sh /app/health_check.sh\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 139250fd6c77\nremote: Step 10/12 : COPY --from=builder --chown=app /app/main /app/main\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 2f1eb9f16e9f\nremote: Step 11/12 : USER app\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; a72f27dccff2\nremote: Step 12/12 : CMD [\u0026quot;/app/main\u0026quot;]\nremote:  ---\u0026gt; Using cache\nremote:  ---\u0026gt; 034275449e08\nremote: Successfully built 034275449e08\nremote: Successfully tagged kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95\nremote: pushing docker.io/kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95 to registry\nremote: The push refers to repository [docker.io/kainlite/default-minikube-default.echobot-echobot]\nremote: bba61bf193fe: Preparing\nremote: 3f0355bbea40: Preparing\nremote: 2ebcdc9e5e8f: Preparing\nremote: 6f1324339fd4: Preparing\nremote: 93391cb9fd4b: Preparing\nremote: cb9d0f9550f6: Preparing\nremote: 93448d8c2605: Preparing\nremote: c54f8a17910a: Preparing\nremote: df64d3292fd6: Preparing\nremote: cb9d0f9550f6: Waiting\nremote: 93448d8c2605: Waiting\nremote: c54f8a17910a: Waiting\nremote: df64d3292fd6: Waiting\nremote: 2ebcdc9e5e8f: Layer already exists\nremote: 6f1324339fd4: Layer already exists\nremote: 3f0355bbea40: Layer already exists\nremote: bba61bf193fe: Layer already exists\nremote: 93391cb9fd4b: Layer already exists\nremote: 93448d8c2605: Layer already exists\nremote: cb9d0f9550f6: Layer already exists\nremote: df64d3292fd6: Layer already exists\nremote: c54f8a17910a: Layer already exists\nremote: a0265bc5d0229dce0cffc985ca22ebe28532ee95: digest: sha256:3046c989fe1b1c4f700aaad875658c73ef571028f731546df38fb404ac22a9c9 size: 2198\nremote:\nremote: Updating Kubernetes deployment: echobot\nremote: deployment \u0026quot;echobot\u0026quot; image updated\nremote: deployment \u0026quot;echobot\u0026quot; successfully rolled out\nremote: NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nremote: echobot   1         1         1            1           31s\nremote:\nremote: Removing build directory\nremote:\nremote: Gitkube build system : Tue Jan  1 23:51:16 UTC 2019: Finished build\nremote:\nremote:\nTo ssh://10.98.213.202/~/git/default-minikube\n * [new branch]      master -\u0026gt; master\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eQuite a lot happened there, first of all gitkubed checked out the commit from the branch or HEAD that we pushed to \u003ccode\u003e/home/default-minikube/build/default-minikube\u003c/code\u003e and then started building and tagged the docker image with the corresponding SHA, after that it pushed the image to \u003ca href=\"https://cloud.docker.com/u/kainlite/repository/docker/kainlite/default-minikube-default.echobot-echobot\"\u003edocker hub\u003c/a\u003e and then updated the deployment that we already had in there for the echo bot.\u003c/p\u003e\n\n\u003cp\u003eThe last step would be to verify that the pod was actually updated, so we can inspect the pod configuration with \u003ccode\u003ekubectl describe pod echobot-654cdbfb99-g4bwv\u003c/code\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e $ kubectl describe pod echobot-654cdbfb99-g4bwv\nName:               echobot-654cdbfb99-g4bwv\nNamespace:          default\nPriority:           0\nPriorityClassName:  \u0026lt;none\u0026gt;\nNode:               minikube/10.0.2.15\nStart Time:         Tue, 01 Jan 2019 20:51:10 -0300\nLabels:             app=echobot\n                    pod-template-hash=654cdbfb99\nAnnotations:        \u0026lt;none\u0026gt;\nStatus:             Running\nIP:                 172.17.0.9\nControlled By:      ReplicaSet/echobot-654cdbfb99\nContainers:\n  echobot:\n    Container ID:   docker://fe26ba9be6e2840c0d43a4fcbb4d79af38a00aa3a16411dee5e4af3823d44664\n    Image:          docker.io/kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95\n    Image ID:       docker-pullable://kainlite/default-minikube-default.echobot-echobot@sha256:3046c989fe1b1c4f700aaad875658c73ef571028f731546df38fb404ac22a9c9\n    Port:           \u0026lt;none\u0026gt;\n    Host Port:      \u0026lt;none\u0026gt;\n    State:          Running\n      Started:      Tue, 01 Jan 2019 20:51:11 -0300\n    Ready:          True\n    Restart Count:  0\n    Liveness:       exec [/bin/sh -c /app/health_check.sh] delay=0s timeout=1s period=10s #success=1 #failure=3\n    Environment:\n      SLACK_API_TOKEN:  really_long_token\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-ks4jx (ro)\nConditions:\n  Type              Status\n  Initialized       True\n  Ready             True\n  ContainersReady   True\n  PodScheduled      True\nVolumes:\n  default-token-ks4jx:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-ks4jx\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  \u0026lt;none\u0026gt;\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  39m   default-scheduler  Successfully assigned default/echobot-654cdbfb99-g4bwv to minikube\n  Normal  Pulled     39m   kubelet, minikube  Container image \u0026quot;docker.io/kainlite/default-minikube-default.echobot-echobot:a0265bc5d0229dce0cffc985ca22ebe28532ee95\u0026quot; already present on machine\n  Normal  Created    39m   kubelet, minikube  Created container\n  Normal  Started    39m   kubelet, minikube  Started container\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAs we can see the image is the one that got built from our \u003ccode\u003egit push\u003c/code\u003e and everything is working as expected.\u003c/p\u003e\n\n\u003cp\u003eAnd that\u0026rsquo;s it for now, I think this tool has a lot of potential, it\u0026rsquo;s simple, nice and fast.\u003c/p\u003e\n\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://kainlite.github.io/blog/go_echobot/",
      "url": "https://kainlite.github.io/blog/go_echobot/",
      "title": "Go echo bot",
      "date_published": "2018-12-29T00:00:00Z",
      "content_html": "\n\n\u003ch3 id=\"echo-bot\"\u003e\u003cstrong\u003eEcho bot\u003c/strong\u003e\u003c/h3\u003e\n\n\u003cp\u003eThis post was going to be about advanced ksonnet usage, but it went more about the echo bot itself, so I decided to rename it.\u003c/p\u003e\n\n\u003cp\u003eTo be honest, there is no other way to get the benefits of having \u003ca href=\"https://ksonnet.io/\"\u003eksonnet\u003c/a\u003e if you\u0026rsquo;re not going to take advantage of the \u003cem\u003edeployments as code\u003c/em\u003e facilities that it brings thanks to Jsonnet.\u003c/p\u003e\n\n\u003cp\u003eThis time we will see how to use \u003ca href=\"https://github.com/cybermaggedon/ksonnet-cheat-sheet\"\u003eproper templates\u003c/a\u003e, it seems that the templates generated with \u003ccode\u003eks\u003c/code\u003e are outdated at the time of this writing ksonnet version is: 0.13.1, no surprise here because it\u0026rsquo;s not a really mature tool. It does require a lot of effort in learning, hacking and reading to get things to work, but hopefully soon it will be easier, of course this is my personal opinion and I have not used it for a real project yet, but I expect it to grow and become more usable before I attempt to do something for the real world with it.\u003c/p\u003e\n\n\u003cp\u003eIn the examples I will be using \u003ca href=\"https://kubernetes.io/docs/tasks/tools/install-minikube\"\u003eminikube\u003c/a\u003e or you can \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003echeck out this repo\u003c/a\u003e that has a good overview of minikube, once installed and started (\u003ccode\u003eminikube start\u003c/code\u003e) that command will download and configure the local environment, if you have been following the previous posts you already have minikube installed and working:\u003c/p\u003e\n\n\u003ch3 id=\"let-s-get-started\"\u003eLet\u0026rsquo;s get started\u003c/h3\u003e\n\n\u003cp\u003eThis time I\u0026rsquo;m not going to deploy another wordpress instance but a simple Slack echo bot made with go:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003epackage main\n\nimport (\n        \u0026quot;fmt\u0026quot;\n        \u0026quot;os\u0026quot;\n        \u0026quot;strings\u0026quot;\n\n        slack \u0026quot;github.com/nlopes/slack\u0026quot;\n)\n\nfunc main() {\n        api := slack.New(\n                os.Getenv(\u0026quot;SLACK_API_TOKEN\u0026quot;),\n        )\n\n        rtm := api.NewRTM()\n        go rtm.ManageConnection()\n\n        for msg := range rtm.IncomingEvents {\n                fmt.Print(\u0026quot;Event Received: \u0026quot;)\n                switch ev := msg.Data.(type) {\n                case *slack.HelloEvent:\n                        // Ignore hello\n\n                case *slack.ConnectedEvent:\n                        fmt.Println(\u0026quot;Infos:\u0026quot;, ev.Info)\n                        fmt.Println(\u0026quot;Connection counter:\u0026quot;, ev.ConnectionCount)\n\n                case *slack.MessageEvent:\n                        // Only echo what it said to me\n                        fmt.Printf(\u0026quot;Message: %v\\n\u0026quot;, ev)\n                        info := rtm.GetInfo()\n                        prefix := fmt.Sprintf(\u0026quot;\u0026lt;@%s\u0026gt; \u0026quot;, info.User.ID)\n\n                        if ev.User != info.User.ID \u0026amp;\u0026amp; strings.HasPrefix(ev.Text, prefix) {\n                                rtm.SendMessage(rtm.NewOutgoingMessage(ev.Text, ev.Channel))\n                        }\n\n                case *slack.PresenceChangeEvent:\n                        fmt.Printf(\u0026quot;Presence Change: %v\\n\u0026quot;, ev)\n\n                case *slack.LatencyReport:\n                        fmt.Printf(\u0026quot;Current latency: %v\\n\u0026quot;, ev.Value)\n\n                case *slack.RTMError:\n                        fmt.Printf(\u0026quot;Error: %s\\n\u0026quot;, ev.Error())\n\n                case *slack.InvalidAuthEvent:\n                        fmt.Printf(\u0026quot;Invalid credentials\u0026quot;)\n                        return\n\n                default:\n\n                        // Ignore other events..\n                        // fmt.Printf(\u0026quot;Unexpected: %v\\n\u0026quot;, msg.Data)\n                }\n        }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAs you can see it\u0026rsquo;s the simplest example from the readme of the \u003ca href=\"https://github.com/nlopes/slack\"\u003eGo Slack API\u003c/a\u003e project, it only connects to Slack and when it reads a message if it\u0026rsquo;s addressed to the bot then it echoes the message back, creating a bot and everything else is out of the scope of this article but it\u0026rsquo;s really simple, you only need to create an app in the Slack workspace, set it as a bot and grab the token (there is a lot more that you can customize but that is the most basic procedure to get started with a bot), then you just invite it to any channel that you want and start interacting with it.\u003c/p\u003e\n\n\u003cp\u003eHere you can see the \u003ccode\u003eDockerfile\u003c/code\u003e, for security we create an app user for the build and for running it, and to save space and bandwidth we only ship what we need using a multi-stage build:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e# Build\nFROM golang:1.11.2-alpine as builder\n\nWORKDIR /app\nRUN adduser -D -g 'app' app \u0026amp;\u0026amp; \\\n    chown -R app:app /app \u0026amp;\u0026amp; \\\n    apk add git \u0026amp;\u0026amp; apk add gcc musl-dev\n\nADD . /app/\nRUN go get -d -v ./... \u0026amp;\u0026amp; go build -o main . \u0026amp;\u0026amp; chown -R app:app /app /home/app\n\n# Run\nFROM golang:1.11.2-alpine\n\nWORKDIR /app\nRUN adduser -D -g 'app' app \u0026amp;\u0026amp; \\\n    chown -R app:app /app\n\nCOPY --from=builder --chown=app /app/health_check.sh /app/health_check.sh\nCOPY --from=builder --chown=app /app/main /app/main\n\nUSER app\nCMD [\u0026quot;/app/main\u0026quot;]\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThere are a few more files in there, you can see the full sources \u003ca href=\"https://github.com/kainlite/echobot\"\u003ehere\u003c/a\u003e, for example \u003ccode\u003ehealth_check.sh\u003c/code\u003e, as our app doesn\u0026rsquo;t listen on any port we need a way to tell kubernetes how to check if our app is alive.\u003c/p\u003e\n\n\u003cp\u003eOkay, enough boilerplate let\u0026rsquo;s get to business, so let\u0026rsquo;s create a new ksonnet application:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ ks init echobot\nINFO Using context \u0026quot;minikube\u0026quot; from kubeconfig file \u0026quot;~/.kube/config\u0026quot;\nINFO Creating environment \u0026quot;default\u0026quot; with namespace \u0026quot;default\u0026quot;, pointing to \u0026quot;version:v1.8.0\u0026quot; cluster at address \u0026quot;https://192.168.99.100:8443\u0026quot;\nINFO Generating ksonnet-lib data at path '~/Webs/echobot/echobot/lib/ksonnet-lib/v1.8.0'\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd now let\u0026rsquo;s grab a template and modify it accordingly to be able to create the deployment for the bot \u003ccode\u003ecomponents/echobot.jsonnet\u003c/code\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e// Import KSonnet library\nlocal params = std.extVar('__ksonnet/params').components.demo;\nlocal k = import 'k.libsonnet';\n\n// Specify the import objects that we need\nlocal container = k.extensions.v1beta1.deployment.mixin.spec.template.spec.containersType;\nlocal depl = k.extensions.v1beta1.deployment;\n\n// Environment variables, instead of hardcoding it here we could use a param or a secret\n// But I will leave that as an exercise for you :)\nlocal envs = [\n  {\n    name: 'SLACK_API_TOKEN',\n    value: 'really-long-token',\n  },\n];\n\nlocal livenessProbe = {\n  exec: {\n    command: [\n      '/bin/sh',\n      '-c',\n      '/app/health_check.sh',\n    ],\n  },\n};\n\n// Define containers\nlocal containers = [\n  container.new('echobot', 'kainlite/echobot:0.0.2') {\n    env: (envs),\n    livenessProbe: livenessProbe,\n  },\n];\n\n// Define deployment with 3 replicas\nlocal deployment =\n  depl.new('echobot', 1, containers, { app: 'echobot' });\n\nlocal resources = [deployment];\n\n// Return list of resources.\nk.core.v1.list.new(resources)\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eNote that I have uploaded that image to docker hub so you can use it to follow the example if you want, after that just replace \u003ccode\u003ereally-long-token\u003c/code\u003e with your token, and then do:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e$ ks apply default\nINFO Applying deployments echobot\nINFO Creating non-existent deployments echobot\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd now if we check our deployment and pod, we should see something like this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/echobot.png\" alt=\"Echo bot\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAnd in the logs:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-plain\"\u003e $ kubectl get pods\nNAME                               READY     STATUS    RESTARTS   AGE\nechobot-7456f7d7dd-twg4r           1/1       Running   0          53s\n\n$ kubectl logs -f echobot-7456f7d7dd-twg4r\nEvent Received: Event Received: Infos: \u0026amp;{wss://cerberus-xxxx.lb.slack-msgs.com/websocket/1gvXP_yQCFE-Y= 0xc000468000 0xc0004482a0 [] [] [] [] []}\nConnection counter: 0\nEvent Received: Event Received: Current latency: 1.256397423s\nEvent Received: Current latency: 1.25679313s\nEvent Received: Current latency: 1.256788737s\nEvent Received: Message: \u0026amp;{{message CEDGU6EA0 UEDJT5DDH \u0026lt;@UED48HD33\u0026gt; echo! 1546124966.002300  false [] [] \u0026lt;nil\u0026gt;  false 0  false  1546124966.002300   \u0026lt;nil\u0026gt;      [] 0 []  [] false \u0026lt;nil\u0026gt;  0 TEDJT5CTD []  false false} \u0026lt;nil\u0026gt;}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd that folks is all I have for now, I hope you enjoyed this small tour of ksonnet. The source code for the bot can be found \u003ca href=\"https://github.com/kainlite/echobot\"\u003ehere\u003c/a\u003e. In a future post I might explore \u003ca href=\"https://ksonnet.io/docs/examples/helm/\"\u003eksonnet and helm charts\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch3 id=\"upcoming-topics\"\u003eUpcoming topics\u003c/h3\u003e\n\n\u003cp\u003eAs promised I will be doing one post about \u003ca href=\"https://github.com/hasura/gitkube\"\u003eGitkube\u003c/a\u003e and \u003ca href=\"https://github.com/GoogleContainerTools/skaffold\"\u003eSkaffold\u003c/a\u003e, there are a lot of deployment tools for kubernetes but those are the most promising ones to me, also after that I will start covering more topics about \u003ca href=\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e, \u003ca href=\"https://containerd.io/\"\u003eContainerD\u003c/a\u003e, \u003ca href=\"https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\"\u003eKubeADM\u003c/a\u003e, and Kubernetes in general.\u003c/p\u003e\n\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\n\u003cp\u003eAlso, you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://kainlite.github.io/blog/getting_started_with_ksonnet/",
      "url": "https://kainlite.github.io/blog/getting_started_with_ksonnet/",
      "title": "Getting started with ksonnet",
      "date_published": "2018-12-27T00:00:00Z",
      "content_html": "\n\n\u003ch3 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h3\u003e\n\n\u003cp\u003eThis tutorial will show you how to create a simple application and also how to deploy it to kubernetes using \u003ca href=\"https://ksonnet.io/\"\u003eksonnet\u003c/a\u003e, in the examples I will be using \u003ca href=\"https://kubernetes.io/docs/tasks/tools/install-minikube\"\u003eminikube\u003c/a\u003e or you can \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003echeck out this repo\u003c/a\u003e that has a good overview of minikube, once installed and started (\u003ccode\u003eminikube start\u003c/code\u003e) that command will download and configure the local environment, if you have been following the previous posts you already have minikube installed and working, before we dive into an example let\u0026rsquo;s review some terminology from ksonnet (extracted from the \u003ca href=\"https://ksonnet.io/docs/concepts/\"\u003eofficial documentation\u003c/a\u003e):\u003c/p\u003e\n\n\u003ch4 id=\"application\"\u003eApplication\u003c/h4\u003e\n\n\u003cp\u003eA ksonnet application represents a well-structured directory of Kubernetes manifests (this is generated using the \u003ccode\u003eks init\u003c/code\u003e).\u003c/p\u003e\n\n\u003ch4 id=\"environment\"\u003eEnvironment\u003c/h4\u003e\n\n\u003cp\u003eAn environment consists of four elements, some of which can be pulled from your current kubeconfig context: Name, Server, Namespace, API version. The environment determines to which cluster you\u0026rsquo;re going to deploy the application.\u003c/p\u003e\n\n\u003ch4 id=\"component\"\u003eComponent\u003c/h4\u003e\n\n\u003cp\u003eA component can be as simple as a Kubernetes resource (a Pod, Deployment, etc), or a fully working stack for example EFK/ELK, you can generate components using \u003ccode\u003eks generate\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch4 id=\"prototype\"\u003ePrototype\u003c/h4\u003e\n\n\u003cp\u003ePrototype + Parameters = Component. Think of a prototype as a base template before you apply the parameters, to set a name, replicas, etc for the resource, you can explore some system prototypes with \u003ccode\u003eks prototype\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch4 id=\"parameter\"\u003eParameter\u003c/h4\u003e\n\n\u003cp\u003eIt gives live to a component with dynamic values, you can use \u003ccode\u003eks param\u003c/code\u003e to view or modify params, there are App params (global), Component params, and Environment params (overrides app params).\u003c/p\u003e\n\n\u003ch4 id=\"module\"\u003eModule\u003c/h4\u003e\n\n\u003cp\u003eModules provide a way for you to share components across environments. More concisely, a module refers to a subdirectory in components/ containing its own params.libsonnet. To create a module \u003ccode\u003eks module create \u0026lt;module name\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch4 id=\"part\"\u003ePart\u003c/h4\u003e\n\n\u003cp\u003eIt provides a way to organize and re-use code.\u003c/p\u003e\n\n\u003ch4 id=\"package\"\u003ePackage\u003c/h4\u003e\n\n\u003cp\u003eA package is a set of related prototypes and associates helper libraries, it allows you to create and share packages between applications.\u003c/p\u003e\n\n\u003ch4 id=\"registry\"\u003eRegistry\u003c/h4\u003e\n\n\u003cp\u003eIt\u0026rsquo;s essentially a repository for packages, it supports the incubator registry, github, filesystem, and Helm.\u003c/p\u003e\n\n\u003ch4 id=\"manifest\"\u003eManifest\u003c/h4\u003e\n\n\u003cp\u003eThe same old YAML or JSON manifest but this time written in \u003ca href=\"https://jsonnet.org/learning/tutorial.html\"\u003eJsonnet\u003c/a\u003e, basically Jsonnet is a simple extension of JSON.\u003c/p\u003e\n\n\u003cp\u003ePhew, that\u0026rsquo;s a lot of names and terminology at once, let\u0026rsquo;s get started with the terminal already.\u003c/p\u003e\n\n\u003ch3 id=\"let-s-get-started\"\u003eLet\u0026rsquo;s get started\u003c/h3\u003e\n\n\u003cp\u003eThis command will generate the following folder structure \u003ccode\u003eks init wordpress\u003c/code\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eINFO Using context \u0026quot;minikube\u0026quot; from kubeconfig file \u0026quot;~/.kube/config\u0026quot;\nINFO Creating environment \u0026quot;default\u0026quot; with namespace \u0026quot;default\u0026quot;, pointing to \u0026quot;version:v1.12.4\u0026quot; cluster at address \u0026quot;https://192.168.99.100:8443\u0026quot;\nINFO Generating ksonnet-lib data at path '~/k8s-examples/wordpress/lib/ksonnet-lib/v1.12.4'\n\n$ ls -l |  awk '{ print $9 }'\napp.yaml        \u0026lt;--- Defines versions, namespace, cluster address, app name, registry.\ncomponents      \u0026lt;--- Components by default it's empty and has a params file.\nenvironments    \u0026lt;--- By default there is only one environment called default.\nlib             \u0026lt;--- Here we can find the ksonnet helpers that match the Kubernetes API with the common resources (Pods, Deployments, etc).\nvendor          \u0026lt;--- Here is where the installed packages/apps go, it can be seen as a dependencies folder.\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eLet\u0026rsquo;s generate a \u003cem\u003edeployed-service\u003c/em\u003e and inspect it\u0026rsquo;s context:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ ks generate deployed-service wordpress \\\n  --image bitnami/wordpress:5.0.2 \\\n  --type ClusterIP\n\nINFO Writing component at '~/k8s-examples/wordpress/components/wordpress.jsonnet'\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAt the moment of this writing the latest version of Wordpress is 5.0.2, it\u0026rsquo;s always recommended to use static version numbers instead of tags like latest (because latest can not be latest).\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s see how our component looks like:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003elocal env = std.extVar(\u0026quot;__ksonnet/environments\u0026quot;);\nlocal params = std.extVar(\u0026quot;__ksonnet/params\u0026quot;).components.wordpress;\n[\n  {\n    \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;,\n    \u0026quot;kind\u0026quot;: \u0026quot;Service\u0026quot;,\n    \u0026quot;metadata\u0026quot;: {\n      \u0026quot;name\u0026quot;: params.name\n    },\n    \u0026quot;spec\u0026quot;: {\n      \u0026quot;ports\u0026quot;: [\n        {\n          \u0026quot;port\u0026quot;: params.servicePort,\n          \u0026quot;targetPort\u0026quot;: params.containerPort\n        }\n      ],\n      \u0026quot;selector\u0026quot;: {\n        \u0026quot;app\u0026quot;: params.name\n      },\n      \u0026quot;type\u0026quot;: params.type\n    }\n  },\n  {\n    \u0026quot;apiVersion\u0026quot;: \u0026quot;apps/v1beta2\u0026quot;,\n    \u0026quot;kind\u0026quot;: \u0026quot;Deployment\u0026quot;,\n    \u0026quot;metadata\u0026quot;: {\n      \u0026quot;name\u0026quot;: params.name\n    },\n    \u0026quot;spec\u0026quot;: {\n      \u0026quot;replicas\u0026quot;: params.replicas,\n      \u0026quot;selector\u0026quot;: {\n        \u0026quot;matchLabels\u0026quot;: {\n          \u0026quot;app\u0026quot;: params.name\n        },\n      },\n      \u0026quot;template\u0026quot;: {\n        \u0026quot;metadata\u0026quot;: {\n          \u0026quot;labels\u0026quot;: {\n            \u0026quot;app\u0026quot;: params.name\n          }\n        },\n        \u0026quot;spec\u0026quot;: {\n          \u0026quot;containers\u0026quot;: [\n            {\n              \u0026quot;image\u0026quot;: params.image,\n              \u0026quot;name\u0026quot;: params.name,\n              \u0026quot;ports\u0026quot;: [\n                {\n                  \u0026quot;containerPort\u0026quot;: params.containerPort\n                }\n              ]\n            }\n          ]\n        }\n      }\n    }\n  }\n]\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eIt\u0026rsquo;s just another template for some known resources, a \u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/service/\"\u003eservice\u003c/a\u003e and a \u003ca href=\"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\"\u003edeployment\u003c/a\u003e that\u0026rsquo;s where the name came from: \u003cem\u003edeployed-service\u003c/em\u003e, but where are those params coming from?\u003c/p\u003e\n\n\u003cp\u003eIf we run \u003ccode\u003eks show default\u003c/code\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003e---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    ksonnet.io/component: wordpress\n  name: wordpress\nspec:\n  ports:\n  - port: 80\n    targetPort: 80\n  selector:\n    app: wordpress\n  type: ClusterIP\n---\napiVersion: apps/v1beta2\nkind: Deployment\nmetadata:\n  labels:\n    ksonnet.io/component: wordpress\n  name: wordpress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: bitnami/wordpress:5.0.2\n        name: wordpress\n        ports:\n        - containerPort: 80\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eWe will see what our package will generate in \u003cem\u003eYAML\u003c/em\u003e with some good defaults. And by default if you remember from the definitions a component needs a params file to fill the blanks in this case it is \u003ccode\u003ecomponents/params.libsonnet\u003c/code\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n  global: {\n    // User-defined global parameters; accessible to all component and environments, Ex:\n    // replicas: 4,\n  },\n  components: {\n    // Component-level parameters, defined initially from 'ks prototype use ...'\n    // Each object below should correspond to a component in the components/ directory\n    wordpress: {\n      containerPort: 80,\n      image: \u0026quot;bitnami/wordpress:5.0.2\u0026quot;,\n      name: \u0026quot;wordpress\u0026quot;,\n      replicas: 1,\n      servicePort: 80,\n      type: \u0026quot;ClusterIP\u0026quot;,\n    },\n  },\n}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eBut that\u0026rsquo;s not enough to run wordpress is it?, No is not, we need a database with persistent storage for it to work properly, so we will need to generate and extend another \u003cem\u003edeployed-service\u003c/em\u003e.\u003c/p\u003e\n\n\u003cp\u003eThe next step would be to create another component:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ ks generate deployed-service mariadb \\\n  --image bitnami/mariadb:10.1.37 \\\n  --type ClusterIP\n\nINFO Writing component at '/home/kainlite/Webs/k8s-examples/wordpress/components/mariadb.jsonnet'\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe latest stable version of MariaDB 10.1 GA at the moment of this writting is 10.1.37.\u003c/p\u003e\n\n\u003cp\u003eThen we will need to add a persistent volume and also tell Wordpress to use this MariaDB instance. How do we do that, we will need to modify a few files, like this (in order to re-use things I placed the mysql variables in the global section, for this example that will simplify things, but it might not be the best approach for a production environment):\nThe resulting \u003ccode\u003ecomponents/params.json\u003c/code\u003e will be:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n  global: {\n    // User-defined global parameters; accessible to all component and environments, Ex:\n    // replicas: 4,\n    mariadbEmptyPassword: \u0026quot;no\u0026quot;,\n    mariadbUser: \u0026quot;mywordpressuser\u0026quot;,\n    mariadbPassword: \u0026quot;mywordpresspassword\u0026quot;,\n    mariadbDatabase: \u0026quot;bitnami_wordpress\u0026quot;,\n  },\n  components: {\n    // Component-level parameters, defined initially from 'ks prototype use ...'\n    // Each object below should correspond to a component in the components/ directory\n    wordpress: {\n      containerPort: 80,\n      image: \u0026quot;bitnami/wordpress:5.0.2\u0026quot;,\n      name: \u0026quot;wordpress\u0026quot;,\n      replicas: 1,\n      servicePort: 80,\n      type: \u0026quot;ClusterIP\u0026quot;,\n    },\n    mariadb: {\n      containerPort: 3306,\n      image: \u0026quot;bitnami/mariadb:10.1.37\u0026quot;,\n      name: \u0026quot;mariadb\u0026quot;,\n      replicas: 1,\n      servicePort: 3306,\n      type: \u0026quot;ClusterIP\u0026quot;,\n    },\n  },\n}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe resulting \u003ccode\u003ecomponents/wordpress.jsonnet\u003c/code\u003e will be:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003elocal env = std.extVar(\u0026quot;__ksonnet/environments\u0026quot;);\nlocal params = std.extVar(\u0026quot;__ksonnet/params\u0026quot;).components.wordpress;\n[\n  {\n    \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;,\n    \u0026quot;kind\u0026quot;: \u0026quot;Service\u0026quot;,\n    \u0026quot;metadata\u0026quot;: {\n      \u0026quot;name\u0026quot;: params.name\n    },\n    \u0026quot;spec\u0026quot;: {\n      \u0026quot;ports\u0026quot;: [\n        {\n          \u0026quot;port\u0026quot;: params.servicePort,\n          \u0026quot;targetPort\u0026quot;: params.containerPort\n        }\n      ],\n      \u0026quot;selector\u0026quot;: {\n        \u0026quot;app\u0026quot;: params.name\n      },\n      \u0026quot;type\u0026quot;: params.type\n    }\n  },\n  {\n    \u0026quot;apiVersion\u0026quot;: \u0026quot;apps/v1beta2\u0026quot;,\n    \u0026quot;kind\u0026quot;: \u0026quot;Deployment\u0026quot;,\n    \u0026quot;metadata\u0026quot;: {\n      \u0026quot;name\u0026quot;: params.name\n    },\n    \u0026quot;spec\u0026quot;: {\n      \u0026quot;replicas\u0026quot;: params.replicas,\n      \u0026quot;selector\u0026quot;: {\n        \u0026quot;matchLabels\u0026quot;: {\n          \u0026quot;app\u0026quot;: params.name\n        },\n      },\n      \u0026quot;template\u0026quot;: {\n        \u0026quot;metadata\u0026quot;: {\n          \u0026quot;labels\u0026quot;: {\n            \u0026quot;app\u0026quot;: params.name\n          }\n        },\n        \u0026quot;spec\u0026quot;: {\n          \u0026quot;containers\u0026quot;: [\n            {\n              \u0026quot;image\u0026quot;: params.image,\n              \u0026quot;name\u0026quot;: params.name,\n              \u0026quot;ports\u0026quot;: [\n                {\n                  \u0026quot;containerPort\u0026quot;: params.containerPort\n                }\n              ],\n              \u0026quot;env\u0026quot;: [\n                {\n                    \u0026quot;name\u0026quot;: \u0026quot;WORDPRESS_DATABASE_USER\u0026quot;,\n                    \u0026quot;value\u0026quot;: params.mariadbUser,\n                },\n                {\n                    \u0026quot;name\u0026quot;: \u0026quot;WORDPRESS_DATABASE_PASSWORD\u0026quot;,\n                    \u0026quot;value\u0026quot;: params.mariadbPassword,\n                },\n                {\n                    \u0026quot;name\u0026quot;: \u0026quot;WORDPRESS_DATABASE_NAME\u0026quot;,\n                    \u0026quot;value\u0026quot;: params.mariadbDatabase,\n                },\n                {\n                    \u0026quot;name\u0026quot;: \u0026quot;WORDPRESS_HOST\u0026quot;,\n                    \u0026quot;value\u0026quot;: \u0026quot;mariadb\u0026quot;,\n                }\n              ]\n            }\n          ]\n        }\n      }\n    }\n  }\n]\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe only thing that changed here is \u003ccode\u003espec.containers.env\u003c/code\u003e which wasn\u0026rsquo;t present before.\u003c/p\u003e\n\n\u003cp\u003eThe resulting \u003ccode\u003ecomponents/mariadb.jsonnet\u003c/code\u003e will be:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003elocal env = std.extVar(\u0026quot;__ksonnet/environments\u0026quot;);\nlocal params = std.extVar(\u0026quot;__ksonnet/params\u0026quot;).components.mariadb;\n[\n{\n    \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;,\n        \u0026quot;kind\u0026quot;: \u0026quot;Service\u0026quot;,\n        \u0026quot;metadata\u0026quot;: {\n            \u0026quot;name\u0026quot;: params.name\n        },\n        \u0026quot;spec\u0026quot;: {\n            \u0026quot;ports\u0026quot;: [\n            {\n                \u0026quot;port\u0026quot;: params.servicePort,\n                \u0026quot;targetPort\u0026quot;: params.containerPort\n            }\n            ],\n            \u0026quot;selector\u0026quot;: {\n                \u0026quot;app\u0026quot;: params.name\n            },\n            \u0026quot;type\u0026quot;: params.type\n        }\n},\n{\n    \u0026quot;apiVersion\u0026quot;: \u0026quot;apps/v1beta2\u0026quot;,\n    \u0026quot;kind\u0026quot;: \u0026quot;Deployment\u0026quot;,\n    \u0026quot;metadata\u0026quot;: {\n        \u0026quot;name\u0026quot;: params.name\n    },\n    \u0026quot;spec\u0026quot;: {\n        \u0026quot;replicas\u0026quot;: params.replicas,\n        \u0026quot;selector\u0026quot;: {\n            \u0026quot;matchLabels\u0026quot;: {\n                \u0026quot;app\u0026quot;: params.name\n            },\n        },\n        \u0026quot;template\u0026quot;: {\n            \u0026quot;metadata\u0026quot;: {\n                \u0026quot;labels\u0026quot;: {\n                    \u0026quot;app\u0026quot;: params.name\n                }\n            },\n            \u0026quot;spec\u0026quot;: {\n                \u0026quot;containers\u0026quot;: [\n                {\n                    \u0026quot;image\u0026quot;: params.image,\n                    \u0026quot;name\u0026quot;: params.name,\n                    \u0026quot;ports\u0026quot;: [\n                    {\n                        \u0026quot;containerPort\u0026quot;: params.containerPort\n                    },\n                    ],\n                    \u0026quot;env\u0026quot;: [\n                    {\n                        \u0026quot;name\u0026quot;: \u0026quot;ALLOW_EMPTY_PASSWORD\u0026quot;,\n                        \u0026quot;value\u0026quot;: params.mariadbEmptyPassword,\n                    },\n                    {\n                        \u0026quot;name\u0026quot;: \u0026quot;MARIADB_USER\u0026quot;,\n                        \u0026quot;value\u0026quot;: params.mariadbUser,\n                    },\n                    {\n                        \u0026quot;name\u0026quot;: \u0026quot;MARIADB_PASSWORD\u0026quot;,\n                        \u0026quot;value\u0026quot;: params.mariadbPassword,\n                    },\n                    {\n                        \u0026quot;name\u0026quot;: \u0026quot;MARIADB_ROOT_PASSWORD\u0026quot;,\n                        \u0026quot;value\u0026quot;: params.mariadbPassword,\n                    },\n                    {\n                        \u0026quot;name\u0026quot;: \u0026quot;MARIADB_DATABASE\u0026quot;,\n                        \u0026quot;value\u0026quot;: params.mariadbDatabase,\n                    },\n                    ],\n                    \u0026quot;volumeMounts\u0026quot;: [\n                    {\n                        \u0026quot;mountPath\u0026quot;: \u0026quot;/var/lib/mysql\u0026quot;,\n                        \u0026quot;name\u0026quot;: \u0026quot;mariadb\u0026quot;\n                    }\n                    ]\n                }\n                ],\n                \u0026quot;volumes\u0026quot;: [\n                {\n                    \u0026quot;name\u0026quot;: \u0026quot;mariadb\u0026quot;,\n                    \u0026quot;hostPath\u0026quot;: {\n                        \u0026quot;path\u0026quot;: \u0026quot;/home/docker/mariadb-data\u0026quot;\n                    }\n                }\n                ]\n            }\n        }\n    }\n}\n]\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eI know, I know, that is a lot of JSON, I trust you have a decent scroll :).\u003c/p\u003e\n\n\u003cp\u003eThe only things that changed here are \u003ccode\u003espec.containers.env\u003c/code\u003e, \u003ccode\u003espec.containers.volumeMount\u003c/code\u003e and \u003ccode\u003espec.volumes\u003c/code\u003e which weren\u0026rsquo;t present before, that\u0026rsquo;s all you need to make wordpress work with mariadb.\u003c/p\u003e\n\n\u003cp\u003eThis post only scratched the surface of what Ksonnet and Jsonnet can do, in another post I will describe more advances features with less \u003cem\u003eJSON\u003c/em\u003e / \u003cem\u003eYAML\u003c/em\u003e. There are a lot of things that can be improved and we will cover those things in the next post, if you want to see all the source code for this post go \u003ca href=\"https://github.com/kainlite/ksonnet-wordpress-example\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s clean up \u003ccode\u003eks delete default\u003c/code\u003e:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eINFO Deleting services mariadb\nINFO Deleting deployments mariadb\nINFO Deleting services wordpress\nINFO Deleting deployments wordpress\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3 id=\"notes\"\u003eNotes\u003c/h3\u003e\n\n\u003cp\u003eIf you want to check the wordpress installation via browser you can do \u003ccode\u003eminikube proxy\u003c/code\u003e and then look up the following URL: \u003ca href=\"http://localhost:8001/api/v1/namespaces/default/services/wordpress/proxy/\"\u003eWordpress\u003c/a\u003e (I\u0026rsquo;m using the default namespace here and the service name is wordpress, if you use ingress you don\u0026rsquo;t need to do this step)\u003c/p\u003e\n\n\u003cp\u003eI\u0026rsquo;m not aware if Ksonnet supports releases and rollbacks like Helm, but it seems it could be emulated using git tags and just some git hooks.\u003c/p\u003e\n\n\u003cp\u003eIf everything goes well, you should see something like this in the logs:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ kubectl logs -f wordpress-5b4d6bd47c-bdtmw\n\nWelcome to the Bitnami wordpress container\nSubscribe to project updates by watching https://github.com/bitnami/bitnami-docker-wordpress\nSubmit issues and feature requests at https://github.com/bitnami/bitnami-docker-wordpress/issues\n\nnami    INFO  Initializing apache\napache  INFO  ==\u0026gt; Patching httpoxy...\napache  INFO  ==\u0026gt; Configuring dummy certificates...\nnami    INFO  apache successfully initialized\nnami    INFO  Initializing php\nnami    INFO  php successfully initialized\nnami    INFO  Initializing mysql-client\nnami    INFO  mysql-client successfully initialized\nnami    INFO  Initializing libphp\nnami    INFO  libphp successfully initialized\nnami    INFO  Initializing wordpress\nmysql-c INFO  Trying to connect to MySQL server\nmysql-c INFO  Found MySQL server listening at mariadb:3306\nmysql-c INFO  MySQL server listening and working at mariadb:3306\nwordpre INFO\nwordpre INFO  ########################################################################\nwordpre INFO   Installation parameters for wordpress:\nwordpre INFO     First Name: FirstName\nwordpre INFO     Last Name: LastName\nwordpre INFO     Username: user\nwordpre INFO     Password: **********\nwordpre INFO     Email: user@example.com\nwordpre INFO     Blog Name: User's Blog!\nwordpre INFO     Table Prefix: wp_\nwordpre INFO   (Passwords are not shown for security reasons)\nwordpre INFO  ########################################################################\nwordpre INFO\nnami    INFO  wordpress successfully initialized\nINFO  ==\u0026gt; Starting wordpress...\n[Thu Dec 27 04:30:59.684053 2018] [ssl:warn] [pid 116] AH01909: localhost:443:0 server certificate does NOT include an ID which matches the server name\n[Thu Dec 27 04:30:59.684690 2018] [ssl:warn] [pid 116] AH01909: localhost:443:0 server certificate does NOT include an ID which matches the server name\n[Thu Dec 27 04:30:59.738783 2018] [ssl:warn] [pid 116] AH01909: localhost:443:0 server certificate does NOT include an ID which matches the server name\n[Thu Dec 27 04:30:59.739701 2018] [ssl:warn] [pid 116] AH01909: localhost:443:0 server certificate does NOT include an ID which matches the server name\n[Thu Dec 27 04:30:59.765798 2018] [mpm_prefork:notice] [pid 116] AH00163: Apache/2.4.37 (Unix) OpenSSL/1.1.0j PHP/7.2.13 configured -- resuming normal operations\n[Thu Dec 27 04:30:59.765874 2018] [core:notice] [pid 116] AH00094: Command line: 'httpd -f /bitnami/apache/conf/httpd.conf -D FOREGROUND'\n172.17.0.1 - - [27/Dec/2018:04:31:00 +0000] \u0026quot;GET / HTTP/1.1\u0026quot; 200 3718\n172.17.0.1 - - [27/Dec/2018:04:31:01 +0000] \u0026quot;GET /wp-includes/js/wp-embed.min.js?ver=5.0.2 HTTP/1.1\u0026quot; 200 753\n172.17.0.1 - - [27/Dec/2018:04:31:01 +0000] \u0026quot;GET /wp-includes/css/dist/block-library/theme.min.css?ver=5.0.2 HTTP/1.1\u0026quot; 200 452\n172.17.0.1 - - [27/Dec/2018:04:31:01 +0000] \u0026quot;GET /wp-includes/css/dist/block-library/style.min.css?ver=5.0.2 HTTP/1.1\u0026quot; 200 4281\n172.17.0.1 - - [27/Dec/2018:04:31:01 +0000] \u0026quot;GET /wp-content/themes/twentynineteen/style.css?ver=1.1 HTTP/1.1\u0026quot; 200 19371\n172.17.0.1 - - [27/Dec/2018:04:31:01 +0000] \u0026quot;GET /wp-content/themes/twentynineteen/print.css?ver=1.1 HTTP/1.1\u0026quot; 200 1230\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd that folks is all I have for now, be sure to check out the \u003ca href=\"https://ksonnet.io/docs/\"\u003eKsonnet official documentation\u003c/a\u003e and \u003ccode\u003eks help\u003c/code\u003e to know more about what ksonnet can do to help you deploy your applications to any kubernetes cluster.\u003c/p\u003e\n\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\n\u003cp\u003eAlso you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://kainlite.github.io/blog/deploying_my_apps_with_helm/",
      "url": "https://kainlite.github.io/blog/deploying_my_apps_with_helm/",
      "title": "Deploying my apps with Helm",
      "date_published": "2018-12-24T00:00:00Z",
      "content_html": "\n\n\u003ch3 id=\"deploying-my-apps-with-helm\"\u003e\u003cstrong\u003eDeploying my apps with Helm\u003c/strong\u003e\u003c/h3\u003e\n\n\u003cp\u003eIf you are already familiar with \u003ca href=\"https://helm.sh/\"\u003eHelm\u003c/a\u003e, and the different types of kubernetes workloads / resource types you might be wondering how to install apps directly to kubernetes, yes, you don\u0026rsquo;t have to re-invent the wheel for your mysql installation, or your postgres, or nginx, jenkins, You name it. Helm solves that problem with \u003ca href=\"https://github.com/helm/charts\"\u003eCharts\u003c/a\u003e, this list has the official charts maintained by the community, where the folder incubator may refer to charts that are still not compliant with the \u003ca href=\"https://github.com/helm/charts/blob/master/CONTRIBUTING.md#technical-requirements\"\u003etechnical requirements\u003c/a\u003e but probably usable and the folder stable is for \u003cem\u003egraduated\u003c/em\u003e charts. This is not the only source of charts as you can imagine, You can use any source for your charts, even just the \u003ca href=\"https://docs.helm.sh/using_helm/#helm-install-installing-a-package\"\u003etgz\u003c/a\u003e files, as we will see in this post.\u003c/p\u003e\n\n\u003cp\u003eHow do I search for charts?:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm search wordpress\nNAME                    CHART VERSION   APP VERSION     DESCRIPTION\nstable/wordpress        3.3.0           4.9.8           Web publishing platform for building blogs and websites.\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eNote that I\u0026rsquo;m not a fan of Wordpress or PHP itself, but it seems like the most common example everywhere. As we can see here it says stable/wordpress so we know that we\u0026rsquo;re using the official repo in the folder stable, but what if we don\u0026rsquo;t want that chart, but someone else provides one with more features or something that You like better. Let\u0026rsquo;s use the one from \u003ca href=\"https://bitnami.com/stack/wordpress/helm\"\u003eBitnami\u003c/a\u003e, so if we check their page you can select different kind of deployments but for it to work we need to add another external repo:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ehelm repo add bitnami https://charts.bitnami.com/bitnami\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eSo if we search again we will now see two options (at the moment of this writing, the latest version is actually 5.0.2):\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm search wordpress\nNAME                    CHART VERSION   APP VERSION     DESCRIPTION\nbitnami/wordpress       5.0.2           5.0.2           Web publishing platform for building blogs and websites.\nstable/wordpress        3.3.0           4.9.8           Web publishing platform for building blogs and websites.\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eLet\u0026rsquo;s check the \u003ca href=\"https://github.com/helm/charts/tree/master/stable/wordpress\"\u003edocumentation\u003c/a\u003e of the chart to create our \u003ccode\u003evalues.yaml\u003c/code\u003e file, note that in this example the stable wordpress chart it\u0026rsquo;s also maintained by Bitnami, so they have the same configuration :), this won\u0026rsquo;t always be the case but it simplifies things for us.\u003c/p\u003e\n\n\u003cp\u003eOur example \u003ccode\u003evalues.yaml\u003c/code\u003e will look like:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ewordpressBlogName: \u0026quot;Testing Helm Charts\u0026quot;\npersistence:\n  size: 1Gi\ningress:\n  enabled: true\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eWe will only change the blog name by default, the persistent volume size and also enable \u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\"\u003eingress\u003c/a\u003e (Our app should be available through \u003ccode\u003ewordpress.local\u003c/code\u003e inside the cluster), if you are using minikube be sure to enable the \u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\"\u003eingress\u003c/a\u003e addon.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ minikube addons enable ingress\ningress was successfully enabled\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eWe can then install \u003ccode\u003estable/wordpress\u003c/code\u003e or \u003ccode\u003ebitnami/wordpress\u003c/code\u003e, we will follow up with the one from Bitnami repo.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm install bitnami/wordpress \\\n--set image.repository=bitnami/wordpress \\\n--set image.tag=5.0.2 \\\n-f values.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAs it\u0026rsquo;s a common good practice to use specific versions we will do it here, it\u0026rsquo;s better to do it this way because you can easily move between known versions and also avoid unknown states, this can happen by misunderstanding what latest means, \u003ca href=\"https://medium.com/@mccode/the-misunderstood-docker-tag-latest-af3babfd6375\"\u003efollow the example\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eYou should see something like:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eNAME:   plucking-condor\nLAST DEPLOYED: Mon Dec 24 13:06:38 2018\nNAMESPACE: default\nSTATUS: DEPLOYED\n\nRESOURCES:\n==\u0026gt; v1/Pod(related)\nNAME                                        READY  STATUS             RESTARTS  AGE\nplucking-condor-wordpress-84845db8b5-hkqhc  0/1    ContainerCreating  0         0s\nplucking-condor-mariadb-0                   0/1    Pending            0         0s\n\n==\u0026gt; v1/Secret\n\nNAME                       AGE\nplucking-condor-mariadb    0s\nplucking-condor-wordpress  0s\n\n==\u0026gt; v1/ConfigMap\nplucking-condor-mariadb        0s\nplucking-condor-mariadb-tests  0s\n\n==\u0026gt; v1/PersistentVolumeClaim\nplucking-condor-wordpress  0s\n\n==\u0026gt; v1/Service\nplucking-condor-mariadb    0s\nplucking-condor-wordpress  0s\n\n==\u0026gt; v1beta1/Deployment\nplucking-condor-wordpress  0s\n\n==\u0026gt; v1beta1/StatefulSet\nplucking-condor-mariadb  0s\n\n==\u0026gt; v1beta1/Ingress\nwordpress.local-plucking-condor  0s\n\n\nNOTES:\n1. Get the WordPress URL:\n\n  You should be able to access your new WordPress installation through\n  http://wordpress.local/admin\n\n2. Login with the following credentials to see your blog\n\n  echo Username: user\n  echo Password: $(kubectl get secret --namespace default plucking-condor-wordpress -o jsonpath=\u0026quot;{.data.wordpress-password}\u0026quot; | base64 --decode)\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eDepending on the cluster provider or installation itself, you might need to replace the \u003ccode\u003epersistence.storageClass\u003c/code\u003e to match what your cluster has, note that in the values file is represented like JSON with dot notation but in your \u003ccode\u003evalues.yaml\u003c/code\u003e you need to stick to YAML format and indent \u003ccode\u003estorageClass\u003c/code\u003e under persistence as usual, the kubernetes API parses and uses JSON but YAML seems more human friendly.\u003c/p\u003e\n\n\u003cp\u003eAt this point we should a working wordpress installation, also move between versions, but be aware that the application is in charge of the database schema and updating it to match what the new version needs, this can also be troublesome rolling back or when downgrading, so if you use persistent data \u003cem\u003eALWAYS\u003c/em\u003e have a working backup, because when things go south, you will want to quickly go back to a known state, also note that I said \u0026ldquo;working backup\u0026rdquo;, yes, test that the backup works and that You can restore it somewhere else before doing anything destructive or that can has repercussions, this will bring you peace of mind and better ways to organize yourself while upgrading, etc.\u003c/p\u003e\n\n\u003cp\u003eNow let\u0026rsquo;s check that all resources are indeed working and that we can use our recently installed app.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ kubectl get all\nNAME                                             READY     STATUS        RESTARTS   AGE\npod/plucking-condor-mariadb-0                    1/1       Running       0          12m\npod/plucking-condor-wordpress-84845db8b5-hkqhc   1/1       Running       0          12m\n\nNAME                                TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/kubernetes                  ClusterIP      10.96.0.1        \u0026lt;none\u0026gt;           443/TCP                      37h\nservice/plucking-condor-mariadb     ClusterIP      10.106.219.59    \u0026lt;none\u0026gt;           3306/TCP                     12m\nservice/plucking-condor-wordpress   LoadBalancer   10.100.239.163   10.100.239.163   80:31764/TCP,443:32308/TCP   12m\n\nNAME                                        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/plucking-condor-wordpress   1         1         1            1           12m\n\nNAME                                                   DESIRED   CURRENT   READY     AGE\nreplicaset.apps/plucking-condor-wordpress-84845db8b5   1         1         1         12m\n\nNAME                                       DESIRED   CURRENT   AGE\nstatefulset.apps/plucking-condor-mariadb   1         1         12m\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eYou can deploy it to a custom namespace (In this case I deployed it to the default namespace), the only change for that would be to set the parameter \u003ccode\u003e--namespace\u003c/code\u003e in the \u003ccode\u003ehelm install\u003c/code\u003e line.\u003c/p\u003e\n\n\u003cp\u003eIf you use minikube then ingress will expose a nodeport that we can find using \u003ccode\u003eminikube service list\u003c/code\u003e then using the browser or curl to navigate our freshly installed wordpress.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e $ minikube service list\n|-------------|---------------------------|--------------------------------|\n|  NAMESPACE  |           NAME            |              URL               |\n|-------------|---------------------------|--------------------------------|\n| default     | kubernetes                | No node port                   |\n| default     | plucking-condor-mariadb   | No node port                   |\n| default     | plucking-condor-wordpress | http://192.168.99.100:31764    |\n|             |                           | http://192.168.99.100:32308    |\n| kube-system | default-http-backend      | http://192.168.99.100:30001    |\n| kube-system | kube-dns                  | No node port                   |\n| kube-system | kubernetes-dashboard      | No node port                   |\n| kube-system | tiller-deploy             | No node port                   |\n|-------------|---------------------------|--------------------------------|\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eIn the cloud or on premises this will indeed be different and you should have a publicly available installation using your own domain name (In this case http is at: \u003ca href=\"http://192.168.99.100:31764\"\u003ehttp://192.168.99.100:31764\u003c/a\u003e and https at: \u003ca href=\"http://192.168.99.100:32308\"\u003ehttp://192.168.99.100:32308\u003c/a\u003e, and \u003ca href=\"http://192.168.99.100:30001\"\u003ehttp://192.168.99.100:30001\u003c/a\u003e is the default backend for the ingress controller), your ips can be different but the basics are the same.\u003c/p\u003e\n\n\u003cp\u003eSample screenshot:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/wordpress-example.png\" alt=\"Wordpress example\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"notes\"\u003eNotes\u003c/h3\u003e\n\n\u003cp\u003eAs long as we have the \u003ca href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/\"\u003epersistent volume\u003c/a\u003e our data should be preserved in this case the PV is used for tha database, but we could add another volume to preserve images, etc.\u003c/p\u003e\n\n\u003cp\u003eClean everything up:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ehelm del --purge plucking-condor\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThat\u0026rsquo;s all I have for now, I will be adding more content next week.\u003c/p\u003e\n\n\u003ch3 id=\"don-t-repeat-yourself\"\u003eDon\u0026rsquo;t Repeat Yourself\u003c/h3\u003e\n\n\u003cp\u003eDRY is a good design goal and part of the art of a good template is knowing when to add a new template and when to update or use an existing one. While helm and go helps with that, there is no perfect tool so we will explore other options in the following posts, explore what the community provides and what seems like a suitable tool for you. Happy Helming!.\u003c/p\u003e\n\n\u003ch3 id=\"upcoming-topics\"\u003eUpcoming topics\u003c/h3\u003e\n\n\u003cp\u003eThe following posts will be about package managers, development deployment tools, etc. It\u0026rsquo;s hard to put all the tools in a category, but they are trying to solve similar problems in different ways, and we will be exploring the ones that seem more promising to me, if you would like me to cover any other tool/project/whatever, just send me a message :)\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eGetting started with Ksonnet and friends.\u003c/li\u003e\n\u003cli\u003eGetting started with Skaffold.\u003c/li\u003e\n\u003cli\u003eGetting started with Gitkube.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\n\u003cp\u003eAlso you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }, 
    {
      "id": "https://kainlite.github.io/blog/getting_started_with_helm/",
      "url": "https://kainlite.github.io/blog/getting_started_with_helm/",
      "title": "Getting started with Helm",
      "date_published": "2018-12-23T00:00:00Z",
      "content_html": "\n\n\u003ch3 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h3\u003e\n\n\u003cp\u003eThis tutorial will show you how to create a simple chart and also how to deploy it to kubernetes using \u003ca href=\"https://helm.sh/\"\u003eHelm\u003c/a\u003e, in the examples I will be using \u003ca href=\"https://kubernetes.io/docs/tasks/tools/install-minikube\"\u003eminikube\u003c/a\u003e or you can \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003echeck out this repo\u003c/a\u003e that has a good overview of minikube, once installed and started (\u003ccode\u003eminikube start\u003c/code\u003e) that command will download and configure the local environment, you can follow with the following example:\u003c/p\u003e\n\n\u003cp\u003eCreate the chart:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ehelm create hello-world\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAlways use valid DNS names if you are going to have services, otherwise you will have issues later on.\u003c/p\u003e\n\n\u003cp\u003eInspect the contents, as you will notice every resource is just a kubernetes resource with some placeholders and basic logic to get something more reusable:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ecd hello-world\n\ncharts       \u0026lt;--- Dependencies, charts that your chart depends on.\nChart.yaml   \u0026lt;--- Metadata mostly, defines the version of your chart, etc.\ntemplates    \u0026lt;--- Here is where the magic happens.\nvalues.yaml  \u0026lt;--- Default values file (this is used to replace in the templates at runtime)\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eNote: the following link explains the basics of \u003ca href=\"https://docs.helm.sh/developing_charts/#managing-dependencies-manually-via-the-charts-directory\"\u003edependencies\u003c/a\u003e, your chart can have as many dependencies as you need, the only thing that you need to do is add or install the other charts as dependencies.\u003c/p\u003e\n\n\u003cp\u003eThe file \u003ccode\u003evalues.yaml\u003c/code\u003e by default will look like the following snippet:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ereplicaCount: 1\n\nimage:\n  repository: nginx\n  tag: stable\n  pullPolicy: IfNotPresent\n\nnameOverride: \u0026quot;\u0026quot;\nfullnameOverride: \u0026quot;\u0026quot;\n\nservice:\n  type: ClusterIP\n  port: 80\n\ningress:\n  enabled: false\n  annotations: {}\n    # kubernetes.io/ingress.class: nginx\n    # kubernetes.io/tls-acme: \u0026quot;true\u0026quot;\n  path: /\n  hosts:\n    - chart-example.local\n  tls: []\n  #  - secretName: chart-example-tls\n  #    hosts:\n  #      - chart-example.local\n\nresources: {}\nnodeSelector: {}\ntolerations: []\naffinity: {}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe next step would be to check the \u003ccode\u003etemplates\u003c/code\u003e folder:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edeployment.yaml  \u0026lt;--- Standard kubernetes deployment with go templates variables.\n_helpers.tpl     \u0026lt;--- This file defines some common variables.\ningress.yaml     \u0026lt;--- Ingress route, etc.\nNOTES.txt        \u0026lt;--- Once deployed this file will display the details of our deployment, usually login data, how to connect, etc.\nservice.yaml     \u0026lt;--- The service that we will use internally and/or via ingress to reach our deployed service.\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eGo \u003ca href=\"https://blog.gopheracademy.com/advent-2017/using-go-templates/\"\u003etemplates\u003c/a\u003e basics, if you need a refresher or a crash course in go templates, also always be sure to check Helm\u0026rsquo;s own \u003ca href=\"https://github.com/helm/helm/blob/master/docs/chart_template_guide/functions_and_pipelines.md\"\u003edocumentation\u003c/a\u003e and also some \u003ca href=\"https://github.com/helm/helm/blob/master/docs/charts_tips_and_tricks.md\"\u003etips and tricks\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s check the \u003ca href=\"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\"\u003edeployment\u003c/a\u003e file:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003eapiVersion: apps/v1beta2\nkind: Deployment\nmetadata:\n  name: {{ include \u0026quot;hello-world.fullname\u0026quot; . }}\n  labels:\n    app.kubernetes.io/name: {{ include \u0026quot;hello-world.name\u0026quot; . }}\n    helm.sh/chart: {{ include \u0026quot;hello-world.chart\u0026quot; . }}\n    app.kubernetes.io/instance: {{ .Release.Name }}\n    app.kubernetes.io/managed-by: {{ .Release.Service }}\nspec:\n  replicas: {{ .Values.replicaCount }}\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: {{ include \u0026quot;hello-world.name\u0026quot; . }}\n      app.kubernetes.io/instance: {{ .Release.Name }}\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: {{ include \u0026quot;hello-world.name\u0026quot; . }}\n        app.kubernetes.io/instance: {{ .Release.Name }}\n    spec:\n      containers:\n        - name: {{ .Chart.Name }}\n          image: \u0026quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}\u0026quot;\n          imagePullPolicy: {{ .Values.image.pullPolicy }}\n          ports:\n            - name: http\n              containerPort: 80\n              protocol: TCP\n          livenessProbe:\n            httpGet:\n              path: /\n              port: http\n          readinessProbe:\n            httpGet:\n              path: /\n              port: http\n          resources:\n{{ toYaml .Values.resources | indent 12 }}\n    {{- with .Values.nodeSelector }}\n      nodeSelector:\n{{ toYaml . | indent 8 }}\n    {{- end }}\n    {{- with .Values.affinity }}\n      affinity:\n{{ toYaml . | indent 8 }}\n    {{- end }}\n    {{- with .Values.tolerations }}\n      tolerations:\n{{ toYaml . | indent 8 }}\n    {{- end }}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAs you can see everything will get replaced by what you define in the \u003ccode\u003evalues.yaml\u003c/code\u003e file and everything is under \u003ccode\u003e.Values\u003c/code\u003e unless you define a local variable or some other variable using helpers for example.\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s check the \u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/service/\"\u003eservice\u003c/a\u003e file:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003eapiVersion: v1\nkind: Service\nmetadata:\n  name: {{ include \u0026quot;hello-world.fullname\u0026quot; . }}\n  labels:\n    app.kubernetes.io/name: {{ include \u0026quot;hello-world.name\u0026quot; . }}\n    helm.sh/chart: {{ include \u0026quot;hello-world.chart\u0026quot; . }}\n    app.kubernetes.io/instance: {{ .Release.Name }}\n    app.kubernetes.io/managed-by: {{ .Release.Service }}\nspec:\n  type: {{ .Values.service.type }}\n  ports:\n    - port: {{ .Values.service.port }}\n      targetPort: http\n      protocol: TCP\n      name: http\n  selector:\n    app.kubernetes.io/name: {{ include \u0026quot;hello-world.name\u0026quot; . }}\n    app.kubernetes.io/instance: {{ .Release.Name }}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eLet\u0026rsquo;s check the \u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\"\u003eingress\u003c/a\u003e file:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e{{- if .Values.ingress.enabled -}}\n{{- $fullName := include \u0026quot;hello-world.fullname\u0026quot; . -}}\n{{- $ingressPath := .Values.ingress.path -}}\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: {{ $fullName }}\n  labels:\n    app.kubernetes.io/name: {{ include \u0026quot;hello-world.name\u0026quot; . }}\n    helm.sh/chart: {{ include \u0026quot;hello-world.chart\u0026quot; . }}\n    app.kubernetes.io/instance: {{ .Release.Name }}\n    app.kubernetes.io/managed-by: {{ .Release.Service }}\n{{- with .Values.ingress.annotations }}\n  annotations:\n{{ toYaml . | indent 4 }}\n{{- end }}\nspec:\n{{- if .Values.ingress.tls }}\n  tls:\n  {{- range .Values.ingress.tls }}\n    - hosts:\n      {{- range .hosts }}\n        - {{ . | quote }}\n      {{- end }}\n      secretName: {{ .secretName }}\n  {{- end }}\n{{- end }}\n  rules:\n  {{- range .Values.ingress.hosts }}\n    - host: {{ . | quote }}\n      http:\n        paths:\n          - path: {{ $ingressPath }}\n            backend:\n              serviceName: {{ $fullName }}\n              servicePort: http\n  {{- end }}\n{{- end }}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe ingress file is one of the most interesting ones in my humble opinion because it has a if else example and also local variables (\u003ccode\u003e$fullName\u003c/code\u003e for example), also iterates over a possible slice of dns record names (hosts), and the same if you have certs for them (a good way to get let\u0026rsquo;s encrypt certificates automatically is using cert-manager, in the next post I will expand on this example adding a basic web app with mysql and ssl/tls).\u003c/p\u003e\n\n\u003cp\u003eAfter checking that everything is up to our needs the only thing missing is to finally deploy it to kubernetes (But first let\u0026rsquo;s install tiller):\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm init\n$HELM_HOME has been configured at /home/gabriel/.helm.\n\nTiller (the Helm server-side component) has been installed into your Kubernetes Cluster.\n\nPlease note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.\nTo prevent this, run `helm init` with the --tiller-tls-verify flag.\nFor more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation\nHappy Helming!\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eNote that many of the complains that Helm receives are because of the admin-y capabilities that Tiller has. A good note on the security issues that Tiller can suffer and some possible mitigation alternatives can be found on the \u003ca href=\"https://engineering.bitnami.com/articles/helm-security.html\"\u003eBitnami page\u003c/a\u003e, this mostly applies to multi-tenant clusters. And also be sure to check \u003ca href=\"https://docs.helm.sh/using_helm/#securing-your-helm-installation\"\u003eSecuring Helm\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eDeploy our chart:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm install --name my-nginx -f values.yaml .\nNAME:   my-nginx\nLAST DEPLOYED: Sun Dec 23 00:30:11 2018\nNAMESPACE: default\nSTATUS: DEPLOYED\n\nRESOURCES:\n==\u0026gt; v1/Service\nNAME                  AGE\nmy-nginx-hello-world  0s\n\n==\u0026gt; v1beta2/Deployment\nmy-nginx-hello-world  0s\n\n==\u0026gt; v1/Pod(related)\n\nNAME                                   READY  STATUS   RESTARTS  AGE\nmy-nginx-hello-world-6f948db8d5-s76zl  0/1    Pending  0         0s\n\nNOTES:\n1. Get the application URL by running these commands:\n  export POD_NAME=$(kubectl get pods --namespace default -l \u0026quot;app.kubernetes.io/name=hello-world,app.kubernetes.io/instance=my-nginx\u0026quot; -o jsonpath=\u0026quot;{.items[0].metadata.name}\u0026quot;)\n  echo \u0026quot;Visit http://127.0.0.1:8080 to use your application\u0026quot;\n  kubectl port-forward $POD_NAME 8080:80\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eOur deployment was successful and we can see that our pod is waiting to be scheduled.\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s check that our service is there:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ kubectl get services\nNAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE\nkubernetes             ClusterIP   10.96.0.1       \u0026lt;none\u0026gt;        443/TCP   1h\nmy-nginx-hello-world   ClusterIP   10.111.222.70   \u0026lt;none\u0026gt;        80/TCP    5m\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd now we can test that everything is okay by running another pod in interactive mode, for example:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ kubectl run -i --tty alpine --image=alpine -- sh\nIf you don't see a command prompt, try pressing enter.\n\n/ # apk add curl\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz\n(1/5) Installing ca-certificates (20171114-r3)\n(2/5) Installing nghttp2-libs (1.32.0-r0)\n(3/5) Installing libssh2 (1.8.0-r3)\n(4/5) Installing libcurl (7.61.1-r1)\n(5/5) Installing curl (7.61.1-r1)\nExecuting busybox-1.28.4-r2.trigger\nExecuting ca-certificates-20171114-r3.trigger\nOK: 6 MiB in 18 packages\n\n/ # curl -v my-nginx-hello-world\n* Rebuilt URL to: my-nginx-hello-world/\n*   Trying 10.111.222.70...\n* TCP_NODELAY set\n* Connected to my-nginx-hello-world (10.111.222.70) port 80 (#0)\n\u0026gt; GET / HTTP/1.1\n\u0026gt; Host: my-nginx-hello-world\n\u0026gt; User-Agent: curl/7.61.1\n\u0026gt; Accept: */*\n\u0026gt;\n\u0026lt; HTTP/1.1 200 OK\n\u0026lt; Server: nginx/1.14.2\n\u0026lt; Date: Sun, 23 Dec 2018 03:45:31 GMT\n\u0026lt; Content-Type: text/html\n\u0026lt; Content-Length: 612\n\u0026lt; Last-Modified: Tue, 04 Dec 2018 14:44:49 GMT\n\u0026lt; Connection: keep-alive\n\u0026lt; ETag: \u0026quot;5c0692e1-264\u0026quot;\n\u0026lt; Accept-Ranges: bytes\n\u0026lt;\n\u0026lt;!DOCTYPE html\u0026gt;\n\u0026lt;html\u0026gt;\n\u0026lt;head\u0026gt;\n\u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt;\n\u0026lt;style\u0026gt;\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n\u0026lt;/style\u0026gt;\n\u0026lt;/head\u0026gt;\n\u0026lt;body\u0026gt;\n\u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt;\n\u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;For online documentation and support please refer to\n\u0026lt;a href=\u0026quot;http://nginx.org/\u0026quot;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt;\nCommercial support is available at\n\u0026lt;a href=\u0026quot;http://nginx.com/\u0026quot;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;/body\u0026gt;\n\u0026lt;/html\u0026gt;\n* Connection #0 to host my-nginx-hello-world left intact\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd voila we see our nginx deployed there and accessible via service name to our other pods (this is fantastic for microservices).\u003c/p\u003e\n\n\u003cp\u003eOur current deployment can be checked like this:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm ls\nNAME            REVISION        UPDATED                         STATUS          CHART                   APP VERSION     NAMESPACE\nmy-nginx        1               Sun Dec 23 00:30:11 2018        DEPLOYED        hello-world-0.1.0       1.0             default\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe last example would be to upgrade our deployment, lets change the \u003ccode\u003etag\u003c/code\u003e in the \u003ccode\u003evalues.yaml\u003c/code\u003e file from \u003ccode\u003estable\u003c/code\u003e to \u003ccode\u003emainline\u003c/code\u003e and update also the metadata file (\u003ccode\u003eChart.yaml\u003c/code\u003e) to let Helm know that this is a new version of our chart.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e $ helm upgrade my-nginx . -f values.yaml\nRelease \u0026quot;my-nginx\u0026quot; has been upgraded. Happy Helming!\nLAST DEPLOYED: Sun Dec 23 00:55:22 2018\nNAMESPACE: default\nSTATUS: DEPLOYED\n\nRESOURCES:\n==\u0026gt; v1/Pod(related)\nNAME                                   READY  STATUS             RESTARTS  AGE\nmy-nginx-hello-world-6f948db8d5-s76zl  1/1    Running            0         25m\nmy-nginx-hello-world-c5cdcc95c-shgc6   0/1    ContainerCreating  0         0s\n\n==\u0026gt; v1/Service\n\nNAME                  AGE\nmy-nginx-hello-world  25m\n\n==\u0026gt; v1beta2/Deployment\nmy-nginx-hello-world  25m\n\n\nNOTES:\n1. Get the application URL by running these commands:\n  export POD_NAME=$(kubectl get pods --namespace default -l \u0026quot;app.kubernetes.io/name=hello-world,app.kubernetes.io/instance=my-nginx\u0026quot; -o jsonpath=\u0026quot;{.items[0].metadata.name}\u0026quot;)\n  echo \u0026quot;Visit http://127.0.0.1:8080 to use your application\u0026quot;\n  kubectl port-forward $POD_NAME 8080:80\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eNote that I always specify the -f values.yaml just for explicitness.\u003c/p\u003e\n\n\u003cp\u003eIt seems that our upgrade went well, let\u0026rsquo;s see what Helm sees\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm ls\nNAME            REVISION        UPDATED                         STATUS          CHART                   APP VERSION     NAMESPACE\nmy-nginx        2               Sun Dec 23 00:55:22 2018        DEPLOYED        hello-world-0.1.1       1.0             default\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eBut before we go let\u0026rsquo;s validate that it did deployed the nginx version that we wanted to have:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ kubectl exec my-nginx-hello-world-c5cdcc95c-shgc6 -- /usr/sbin/nginx -v\nnginx version: nginx/1.15.7\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAt the moment of this writing mainline is 1.15.7, we could rollback to the previous version by doing:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e$ helm rollback my-nginx 1\nRollback was a success! Happy Helming!\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eBasically this command needs a deployment name \u003ccode\u003emy-nginx\u003c/code\u003e and the revision number to rollback to in this case \u003ccode\u003e1\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eLet\u0026rsquo;s check the versions again:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ kubectl exec my-nginx-hello-world-6f948db8d5-bsml2 -- /usr/sbin/nginx -v\nnginx version: nginx/1.14.2\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eLet\u0026rsquo;s clean up:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ helm del --purge my-nginx\nrelease \u0026quot;my-nginx\u0026quot; deleted\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eIf you need to see what will be sent to the kubernetes API then you can use the following command (sometimes it\u0026rsquo;s really useful for debugging or to inject a sidecar using pipes):\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e$ helm template . -name my-nginx -f values.yaml\n# Source: hello-world/templates/service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: ame-hello-world\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eAnd that folks is all I have for now, be sure to check own \u003ca href=\"https://docs.helm.sh/\"\u003eHelm Documentation\u003c/a\u003e and \u003ccode\u003ehelm help\u003c/code\u003e to know more about what helm can do to help you deploy your applications to any kubernetes cluster.\u003c/p\u003e\n\n\u003ch3 id=\"don-t-repeat-yourself\"\u003eDon\u0026rsquo;t Repeat Yourself\u003c/h3\u003e\n\n\u003cp\u003eDRY is a good design goal and part of the art of a good template is knowing when to add a new template and when to update an existing one. While you\u0026rsquo;re figuring that out, accept that you\u0026rsquo;ll be doing some refactoring. Helm and go makes that easy and fast.\u003c/p\u003e\n\n\u003ch3 id=\"upcoming-topics\"\u003eUpcoming topics\u003c/h3\u003e\n\n\u003cp\u003eThe following posts will be about package managers, development deployment tools, etc. It\u0026rsquo;s hard to put all the tools in a category, but they are trying to solve similar problems in different ways, and we will be exploring the ones that seem more promising to me, if you would like me to cover any other tool/project/whatever, just send me a message :)\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kainlite.github.io/blog/deploying_my_apps_with_helm/\"\u003eExpand on helm, search and install community charts\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kainlite.github.io/blog/getting_started_with_ksonnet/\"\u003eGetting started with Ksonnet and friends\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eGetting started with Skaffold.\u003c/li\u003e\n\u003cli\u003eGetting started with Gitkube.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"errata\"\u003eErrata\u003c/h3\u003e\n\n\u003cp\u003eIf you spot any error or have any suggestion, please send me a message so it gets fixed.\u003c/p\u003e\n\n\u003cp\u003eAlso you can check the source code and changes in the \u003ca href=\"https://github.com/kainlite/kainlite.github.io\"\u003egenerated code\u003c/a\u003e and the \u003ca href=\"https://github.com/kainlite/blog\"\u003esources here\u003c/a\u003e\u003c/p\u003e\n"
    }
  ]
}
