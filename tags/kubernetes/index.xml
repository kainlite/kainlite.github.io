<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on Kubernetes, CI/CD, Git, Linux, Containers, Golang... and more</title>
    <link>https://kainlite.github.io/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on Kubernetes, CI/CD, Git, Linux, Containers, Golang... and more</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 06 Jan 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://kainlite.github.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Why do I need a service mesh?</title>
      <link>https://kainlite.github.io/blog/why_do_i_need_a_service_mesh/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kainlite.github.io/blog/why_do_i_need_a_service_mesh/</guid>
      <description>

&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;This time we will see how to get started with &lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt; and why do we need to use a service mesh.&lt;/p&gt;

&lt;p&gt;In this example I will be using &lt;a href=&#34;https://m.do.co/c/01d040b789de&#34;&gt;Digital Ocean&lt;/a&gt; (that&amp;rsquo;s my referral link), note that I do not have any association with Digital Ocean but they give you $100 to test their products for 60 days, if you spend $25 I get another $25.&lt;/p&gt;

&lt;h3 id=&#34;istio&#34;&gt;Istio&lt;/h3&gt;

&lt;p&gt;So&amp;hellip; You might be wondering some of those questions: why Istio? Why do I need a service mesh?, when do I need that? And I want to help you with some answers:&lt;/p&gt;

&lt;p&gt;Why do I need a service mesh? Basically because in cloud environments you cannot trust that the network will be reliable 100% of the time, that the latency will be low, that the network is secure and the bandwidth is infinite, the service mesh is just an extra layer to help microservices communicate with each other safely and reliably.&lt;/p&gt;

&lt;p&gt;When do I need to have one? This one can be tricky and will depend on your environment, but the moment that you start experiencing network issues between your microservices would be a good moment to do it, it could be done before of course, but it will highly depend on the project, if you can start early with it the better and easier to implement will be, always have in mind the benefits of added security, observability and likely performance improvement.&lt;/p&gt;

&lt;p&gt;Why Istio? This will be a small series of service meshes for kubernetes and I decided to start with Istio.&lt;/p&gt;

&lt;p&gt;In case you don&amp;rsquo;t agree with my explanations that&amp;rsquo;s ok, this is a TL;DR version and also I simplified things a lot, for a more complete overview you can check &lt;a href=&#34;https://blog.buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/&#34;&gt;this&lt;/a&gt; article or &lt;a href=&#34;https://www.oreilly.com/ideas/do-you-need-a-service-mesh&#34;&gt;this one&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;let-s-get-started&#34;&gt;Let&amp;rsquo;s get started&lt;/h3&gt;

&lt;p&gt;First of all we need to download and install Istio in our cluster, the recommended way of doing it is using helm (In this case I will be using the no Tiller alternative, but it could be done with helm install as well, check here for &lt;a href=&#34;https://istio.io/docs/setup/kubernetes/helm-install/&#34;&gt;more info&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ curl -L https://git.io/getLatestIstio | sh -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will download and extract the latest release, in this case 1.0.5 at this moment.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s install Istio&amp;hellip; only pay attention to the first 3 commands, then you can skip until the end of the code block, I post all the output because I like full examples :)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;istio-1.0.5 $ helm template install/kubernetes/helm/istio --name istio --namespace istio-system --set grafana.enabled=true &amp;gt; $HOME/istio.yaml
istio-1.0.5 $ kubectl create namespace istio-system
namespace &amp;quot;istio-system&amp;quot; created

istio-1.0.5 $ kubectl apply -f $HOME/istio.yaml
configmap &amp;quot;istio-galley-configuration&amp;quot; created
configmap &amp;quot;istio-statsd-prom-bridge&amp;quot; created
configmap &amp;quot;prometheus&amp;quot; created
configmap &amp;quot;istio-security-custom-resources&amp;quot; created
configmap &amp;quot;istio&amp;quot; created
configmap &amp;quot;istio-sidecar-injector&amp;quot; created
serviceaccount &amp;quot;istio-galley-service-account&amp;quot; created
serviceaccount &amp;quot;istio-egressgateway-service-account&amp;quot; created
serviceaccount &amp;quot;istio-ingressgateway-service-account&amp;quot; created
serviceaccount &amp;quot;istio-mixer-service-account&amp;quot; created
serviceaccount &amp;quot;istio-pilot-service-account&amp;quot; created
serviceaccount &amp;quot;prometheus&amp;quot; created
serviceaccount &amp;quot;istio-cleanup-secrets-service-account&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-cleanup-secrets-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-cleanup-secrets-istio-system&amp;quot; created
job.batch &amp;quot;istio-cleanup-secrets&amp;quot; created
serviceaccount &amp;quot;istio-security-post-install-account&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-security-post-install-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-security-post-install-role-binding-istio-system&amp;quot; created
job.batch &amp;quot;istio-security-post-install&amp;quot; created
serviceaccount &amp;quot;istio-citadel-service-account&amp;quot; created
serviceaccount &amp;quot;istio-sidecar-injector-service-account&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;virtualservices.networking.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;destinationrules.networking.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;serviceentries.networking.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;gateways.networking.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;envoyfilters.networking.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;httpapispecbindings.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;httpapispecs.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;quotaspecbindings.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;quotaspecs.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;rules.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;attributemanifests.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;bypasses.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;circonuses.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;deniers.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;fluentds.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;kubernetesenvs.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;listcheckers.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;memquotas.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;noops.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;opas.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;prometheuses.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;rbacs.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;redisquotas.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;servicecontrols.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;signalfxs.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;solarwindses.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;stackdrivers.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;statsds.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;stdios.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;apikeys.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;authorizations.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;checknothings.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;kuberneteses.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;listentries.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;logentries.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;edges.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;metrics.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;quotas.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;reportnothings.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;servicecontrolreports.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;tracespans.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;rbacconfigs.rbac.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;serviceroles.rbac.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;servicerolebindings.rbac.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;adapters.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;instances.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;templates.config.istio.io&amp;quot; created
customresourcedefinition.apiextensions.k8s.io &amp;quot;handlers.config.istio.io&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-galley-istio-system&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-egressgateway-istio-system&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-ingressgateway-istio-system&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-mixer-istio-system&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-pilot-istio-system&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;prometheus-istio-system&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-citadel-istio-system&amp;quot; created
clusterrole.rbac.authorization.k8s.io &amp;quot;istio-sidecar-injector-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-galley-admin-role-binding-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-egressgateway-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-ingressgateway-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-mixer-admin-role-binding-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-pilot-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;prometheus-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-citadel-istio-system&amp;quot; created
clusterrolebinding.rbac.authorization.k8s.io &amp;quot;istio-sidecar-injector-admin-role-binding-istio-system&amp;quot; created
service &amp;quot;istio-galley&amp;quot; created
service &amp;quot;istio-egressgateway&amp;quot; created
service &amp;quot;istio-ingressgateway&amp;quot; created
service &amp;quot;istio-policy&amp;quot; created
service &amp;quot;istio-telemetry&amp;quot; created
service &amp;quot;istio-pilot&amp;quot; created
service &amp;quot;prometheus&amp;quot; created
service &amp;quot;istio-citadel&amp;quot; created
service &amp;quot;istio-sidecar-injector&amp;quot; created
deployment.extensions &amp;quot;istio-galley&amp;quot; created
deployment.extensions &amp;quot;istio-egressgateway&amp;quot; created
deployment.extensions &amp;quot;istio-ingressgateway&amp;quot; created
deployment.extensions &amp;quot;istio-policy&amp;quot; created
deployment.extensions &amp;quot;istio-telemetry&amp;quot; created
deployment.extensions &amp;quot;istio-pilot&amp;quot; created
deployment.extensions &amp;quot;prometheus&amp;quot; created
deployment.extensions &amp;quot;istio-citadel&amp;quot; created
deployment.extensions &amp;quot;istio-sidecar-injector&amp;quot; created
gateway.networking.istio.io &amp;quot;istio-autogenerated-k8s-ingress&amp;quot; created
horizontalpodautoscaler.autoscaling &amp;quot;istio-egressgateway&amp;quot; created
horizontalpodautoscaler.autoscaling &amp;quot;istio-ingressgateway&amp;quot; created
horizontalpodautoscaler.autoscaling &amp;quot;istio-policy&amp;quot; created
horizontalpodautoscaler.autoscaling &amp;quot;istio-telemetry&amp;quot; created
horizontalpodautoscaler.autoscaling &amp;quot;istio-pilot&amp;quot; created
mutatingwebhookconfiguration.admissionregistration.k8s.io &amp;quot;istio-sidecar-injector&amp;quot; created
attributemanifest.config.istio.io &amp;quot;istioproxy&amp;quot; created
attributemanifest.config.istio.io &amp;quot;kubernetes&amp;quot; created
stdio.config.istio.io &amp;quot;handler&amp;quot; created
logentry.config.istio.io &amp;quot;accesslog&amp;quot; created
logentry.config.istio.io &amp;quot;tcpaccesslog&amp;quot; created
rule.config.istio.io &amp;quot;stdio&amp;quot; created
rule.config.istio.io &amp;quot;stdiotcp&amp;quot; created
metric.config.istio.io &amp;quot;requestcount&amp;quot; created
metric.config.istio.io &amp;quot;requestduration&amp;quot; created
metric.config.istio.io &amp;quot;requestsize&amp;quot; created
metric.config.istio.io &amp;quot;responsesize&amp;quot; created
metric.config.istio.io &amp;quot;tcpbytesent&amp;quot; created
metric.config.istio.io &amp;quot;tcpbytereceived&amp;quot; created
prometheus.config.istio.io &amp;quot;handler&amp;quot; created
rule.config.istio.io &amp;quot;promhttp&amp;quot; created
rule.config.istio.io &amp;quot;promtcp&amp;quot; created
kubernetesenv.config.istio.io &amp;quot;handler&amp;quot; created
rule.config.istio.io &amp;quot;kubeattrgenrulerule&amp;quot; created
rule.config.istio.io &amp;quot;tcpkubeattrgenrulerule&amp;quot; created
kubernetes.config.istio.io &amp;quot;attributes&amp;quot; created
destinationrule.networking.istio.io &amp;quot;istio-policy&amp;quot; created
destinationrule.networking.istio.io &amp;quot;istio-telemetry&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WOAH, What did just happen?, a lot of new resources were created, basically we just generated the manifest from the helm chart and applied that to our cluster.&lt;/p&gt;

&lt;p&gt;So lets see what&amp;rsquo;s running and what that means:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ kubectl get pods -n istio-system
NAME                                      READY     STATUS      RESTARTS   AGE
istio-citadel-856f994c58-l96p8            1/1       Running     0          3m
istio-cleanup-secrets-xqqj4               0/1       Completed   0          3m
istio-egressgateway-5649fcf57-7zwkh       1/1       Running     0          3m
istio-galley-7665f65c9c-tzn7d             1/1       Running     0          3m
istio-ingressgateway-6755b9bbf6-bh84r     1/1       Running     0          3m
istio-pilot-56855d999b-c4cp5              2/2       Running     0          3m
istio-policy-6fcb6d655f-9544z             2/2       Running     0          3m
istio-sidecar-injector-768c79f7bf-th8zh   1/1       Running     0          3m
istio-telemetry-664d896cf5-jdcwv          2/2       Running     0          3m
prometheus-76b7745b64-f8jxn               1/1       Running     0          3m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A few minutes later, almost everything is up, but what&amp;rsquo;s all that? Istio has several components, see the following overview extracted from &lt;a href=&#34;https://github.com/istio/istio&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Envoy&lt;/strong&gt;: Sidecar proxies per microservice to handle ingress/egress traffic between services in the cluster and from a service to external services. The proxies form a secure microservice mesh providing a rich set of functions like discovery, rich layer-7 routing, circuit breakers, policy enforcement and telemetry recording/reporting functions.
Note: The service mesh is not an overlay network. It simplifies and enhances how microservices in an application talk to each other over the network provided by the underlying platform.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mixer&lt;/strong&gt;: Central component that is leveraged by the proxies and microservices to enforce policies such as authorization, rate limits, quotas, authentication, request tracing and telemetry collection.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pilot&lt;/strong&gt;: A component responsible for configuring the proxies at runtime.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Citadel&lt;/strong&gt;: A centralized component responsible for certificate issuance and rotation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Node Agent&lt;/strong&gt;: A per-node component responsible for certificate issuance and rotation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Galley&lt;/strong&gt;: Central component for validating, ingesting, aggregating, transforming and distributing config within Istio.&lt;/p&gt;

&lt;p&gt;Ok so, a lot of new things were installed but how do I know it&amp;rsquo;s working? let&amp;rsquo;s deploy a &lt;a href=&#34;https://istio.io/docs/examples/bookinfo/&#34;&gt;test application&lt;/a&gt; and check it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ export PATH=&amp;quot;$PATH:~/istio-1.0.5/bin&amp;quot;
istio-1.0.5/samples/bookinfo $ kubectl apply -f &amp;lt;(istioctl kube-inject -f platform/kube/bookinfo.yaml)
service &amp;quot;details&amp;quot; created
deployment.extensions &amp;quot;details-v1&amp;quot; created
service &amp;quot;ratings&amp;quot; created
deployment.extensions &amp;quot;ratings-v1&amp;quot; created
service &amp;quot;reviews&amp;quot; created
deployment.extensions &amp;quot;reviews-v1&amp;quot; created
deployment.extensions &amp;quot;reviews-v2&amp;quot; created
deployment.extensions &amp;quot;reviews-v3&amp;quot; created
service &amp;quot;productpage&amp;quot; created
deployment.extensions &amp;quot;productpage-v1&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That command not only deployed the application but injected the Istio sidecar to each pod:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ kubectl get pods
NAME                              READY     STATUS    RESTARTS   AGE
details-v1-8bd954dbb-zhrqq        2/2       Running   0          2m
productpage-v1-849c786f96-kpfx9   2/2       Running   0          2m
ratings-v1-68d648d6fd-w68qb       2/2       Running   0          2m
reviews-v1-b4c984bdc-9s6j5        2/2       Running   0          2m
reviews-v2-575446d5db-r6kwc       2/2       Running   0          2m
reviews-v3-74458c4889-kr4wb       2/2       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As we can see each pod has 2 containers in it, the app container and istio-proxy. You can also configure &lt;a href=&#34;https://istio.io/docs/setup/kubernetes/sidecar-injection/#automatic-sidecar-injection&#34;&gt;automatic sidecar injection&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also all services are running:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ kubectl get services
NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
details       ClusterIP   10.245.134.179   &amp;lt;none&amp;gt;        9080/TCP   3m
kubernetes    ClusterIP   10.245.0.1       &amp;lt;none&amp;gt;        443/TCP    3d
productpage   ClusterIP   10.245.32.221    &amp;lt;none&amp;gt;        9080/TCP   3m
ratings       ClusterIP   10.245.159.112   &amp;lt;none&amp;gt;        9080/TCP   3m
reviews       ClusterIP   10.245.77.125    &amp;lt;none&amp;gt;        9080/TCP   3m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But how do I access the app?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;istio-1.0.5/samples/bookinfo $ kubectl apply -f networking/bookinfo-gateway.yaml
gateway.networking.istio.io &amp;quot;bookinfo-gateway&amp;quot; created
virtualservice.networking.istio.io &amp;quot;bookinfo&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In Istio a Gateway configures a load balancer for HTTP/TCP traffic, most commonly operating at the edge of the mesh to enable ingress traffic for an application (L4-L6).&lt;/p&gt;

&lt;p&gt;After that we need to set some environmnet variables to fetch the LB ip, port, etc.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.status.loadBalancer.ingress[0].ip}&#39;)
$ export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;http2&amp;quot;)].port}&#39;)
$ export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;https&amp;quot;)].port}&#39;)
$ export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT

curl -o /dev/null -s -w &amp;quot;%{http_code}\n&amp;quot; http://${GATEWAY_URL}/productpage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the latest curl returns 200 then we&amp;rsquo;re good, you can also browse the app &lt;code&gt;open http://$\{GATEWAY_URL\}/productpage&lt;/code&gt; and you will see something like the following image:
&lt;figure&gt;
    &lt;img src=&#34;https://kainlite.github.io/img/productpage-example.png&#34; width=&#34;100%&#34;/&gt; &lt;figcaption&gt;
            &lt;h4&gt;Product page example&lt;/h4&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;Also you can use &lt;a href=&#34;https://grafana.com/&#34;&gt;Grafana&lt;/a&gt; to check some metrics about the service usage, etc. (You don&amp;rsquo;t have to worry about prometheus since it&amp;rsquo;s enabled by default). Spin up the port-forward so we don&amp;rsquo;t have to expose grafana: to the world with: &lt;code&gt;kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=grafana -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 3000:3000&lt;/code&gt;, and then &lt;code&gt;open http://localhost:3000&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As a general advice check all the settings that Istio offers try the ones that you think that could be useful for your project and always measure and compare.&lt;/p&gt;

&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Do mind that &lt;strong&gt;pilot&lt;/strong&gt; pod requires at least 4 Gbs of memory, so you will need at least one node with that amount of memory.&lt;/li&gt;
&lt;li&gt;You can check the load balancer status under: Manage -&amp;gt; Networking -&amp;gt; Load balancers. And if everything is okay your LB will say Healthy.&lt;/li&gt;
&lt;li&gt;Grafana is not enabled by default but we do enable it via helm with &lt;code&gt;--set grafana.enabled=true&lt;/code&gt;, if you want to check all the possible options &lt;a href=&#34;https://istio.io/docs/reference/config/installation-options/&#34;&gt;go here&lt;/a&gt;, if you are using more than two &lt;code&gt;--set&lt;/code&gt; options I would recommend creating a &lt;code&gt;values.yaml&lt;/code&gt; file and use that instead.&lt;/li&gt;
&lt;li&gt;Istio is a big beast and should be treated carefully, there is a lot more to learn and test out. We only scratched the surface here.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;upcoming-posts&#34;&gt;Upcoming posts&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;More examples using Istio.&lt;/li&gt;
&lt;li&gt;Linkerd.&lt;/li&gt;
&lt;li&gt;Maybe some Golang fun.&lt;/li&gt;
&lt;li&gt;Serverless or kubeless, that&amp;rsquo;s the question.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;errata&#34;&gt;Errata&lt;/h3&gt;

&lt;p&gt;If you spot any error or have any suggestion, please send me a message so it gets fixed.&lt;/p&gt;

&lt;p&gt;Also, you can check the source code and changes in the &lt;a href=&#34;https://github.com/kainlite/kainlite.github.io&#34;&gt;generated code&lt;/a&gt; and the &lt;a href=&#34;https://github.com/kainlite/blog&#34;&gt;sources here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting started with skaffold</title>
      <link>https://kainlite.github.io/blog/getting_started_with_skaffold/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kainlite.github.io/blog/getting_started_with_skaffold/</guid>
      <description>

&lt;h3 id=&#34;skaffold&#34;&gt;&lt;strong&gt;Skaffold&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;This time we will see how to get started with &lt;a href=&#34;https://github.com/GoogleContainerTools/skaffold&#34;&gt;Skaffold&lt;/a&gt;, it seems a relatively mature project, and it does a lot more than some of the previous explored alternatives: &lt;em&gt;Skaffold is a command line tool that facilitates continuous development for Kubernetes applications. You can iterate on your application source code locally then deploy to local or remote Kubernetes clusters. Skaffold handles the workflow for building, pushing and deploying your application. It also provides building blocks and describe customizations for a CI/CD pipeline.&lt;/em&gt; (Extracted from &lt;a href=&#34;https://github.com/GoogleContainerTools/skaffold&#34;&gt;github&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;In this example I will be using &lt;a href=&#34;https://m.do.co/c/01d040b789de&#34;&gt;Digital Ocean&lt;/a&gt; (that&amp;rsquo;s my referral link), note that I do not have any association with Digital Ocean but they give you $100 to test their products for 60 days, if you spend $25 I get another $25, I got the idea from &lt;a href=&#34;https://www.youtube.com/watch?v=fhYSKEy0s8w&#34;&gt;Pelado Nerd Spanish Youtube Channel&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;let-s-get-started&#34;&gt;Let&amp;rsquo;s get started&lt;/h3&gt;

&lt;p&gt;Once you have created your account and added your credit card you will get the $100 of free credit, then you will have to go to Manage on the left side panel and click on Kubernetes, then create your cluster with the amount of nodes that you consider necessary but remember to power them off or delete these resources so you don&amp;rsquo;t waste the free credit or your credit card itself. Once you have created your cluster and downloaded the kubectl config you&amp;rsquo;re ready to go.&lt;/p&gt;

&lt;p&gt;We will be working with the chat bot again you can see the original &lt;a href=&#34;https://kainlite.github.io/blog/go_echobot/&#34;&gt;article here&lt;/a&gt;, and the repo &lt;a href=&#34;https://github.com/kainlite/echobot/tree/skaffold&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s tell our kubectl to use our recently downloaded config:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ export KUBECONFIG=/home/kainlite/Downloads/k8s-1-13-1-do-2-nyc1-1546545313076-kubeconfig.yaml
$ kubectl get nodes -o wide

NAME                 STATUS    ROLES     AGE       VERSION   EXTERNAL-IP       OS-IMAGE                       KERNEL-VERSION   CONTAINER-RUNTIME
crazy-wozniak-8306   Ready     &amp;lt;none&amp;gt;    6h        v1.13.1   178.128.154.205   Debian GNU/Linux 9 (stretch)   4.9.0-8-amd64    docker://18.9.0
crazy-wozniak-830t   Ready     &amp;lt;none&amp;gt;    6h        v1.13.1   167.99.224.115    Debian GNU/Linux 9 (stretch)   4.9.0-8-amd64    docker://18.9.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your config might have a slightly different name, but it should be similar. We can see in the output a lot of information about our nodes (workers).&lt;/p&gt;

&lt;p&gt;But let&amp;rsquo;s cut to the chase, we are here for &lt;em&gt;Skaffold&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/v0.20.0/skaffold-linux-amd64 &amp;amp;&amp;amp; chmod +x skaffold &amp;amp;&amp;amp; sudo mv skaffold /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can install the binary using the provided line (linux) or downloading it from the &lt;a href=&#34;https://github.com/GoogleContainerTools/skaffold/releases&#34;&gt;releases page&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Once installed we can see the &lt;a href=&#34;https://github.com/GoogleContainerTools/skaffold/tree/master/examples&#34;&gt;examples&lt;/a&gt;, I will be using the getting-started example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: skaffold/v1beta2
kind: Config
build:
  artifacts:
  - image: kainlite/echobot
deploy:
  kubectl:
    manifests:
      - k8s-*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With very litle YAML we can accomplish a lot.&lt;/p&gt;

&lt;p&gt;We need a manifest file that matches that pattern so skaffold can deploy/re-deploy our application, so let&amp;rsquo;s generate one with &lt;code&gt;kubectl run echobot --image=kainlite/echobot --dry-run -o yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    run: echobot
  name: echobot
spec:
  replicas: 1
  selector:
    matchLabels:
      run: echobot
  strategy: {}
  template:
    metadata:
      labels:
        run: echobot
    spec:
      containers:
      - image: kainlite/echobot
        name: echobot
        env:
        - name: SLACK_API_TOKEN
          value: really_long_token
        livenessProbe:
          exec:
            command:
            - &#39;/bin/sh&#39;
            - &#39;-c&#39;
            - &#39;/app/health_check.sh&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above command can be used to generate any kind of k8s resource :), I stripped it a bit, because there were fields that I didn&amp;rsquo;t want in and added some that we need for it to work.&lt;/p&gt;

&lt;p&gt;Then the only thing left to do is testing that everything works properly:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ skaffold build

Starting build...
Building [kainlite/echobot]...
Sending build context to Docker daemon  66.56kB
Step 1/12 : FROM golang:1.11.2-alpine as builder
 ---&amp;gt; 57915f96905a
Step 2/12 : WORKDIR /app
 ---&amp;gt; Using cache
 ---&amp;gt; e04488a7f16b
Step 3/12 : RUN adduser -D -g &#39;app&#39; app &amp;amp;&amp;amp;     chown -R app:app /app &amp;amp;&amp;amp;     apk add git &amp;amp;&amp;amp; apk add gcc musl-dev
 ---&amp;gt; Running in 1339601fff6f
fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz
(1/6) Installing nghttp2-libs (1.32.0-r0)
(2/6) Installing libssh2 (1.8.0-r3)
(3/6) Installing libcurl (7.61.1-r1)
(4/6) Installing expat (2.2.5-r0)
(5/6) Installing pcre2 (10.31-r0)
(6/6) Installing git (2.18.1-r0)
Executing busybox-1.28.4-r1.trigger
OK: 19 MiB in 20 packages
(1/12) Installing binutils (2.30-r5)
(2/12) Installing gmp (6.1.2-r1)
(3/12) Installing isl (0.18-r0)
(4/12) Installing libgomp (6.4.0-r9)
(5/12) Installing libatomic (6.4.0-r9)
(6/12) Installing pkgconf (1.5.3-r0)
(7/12) Installing libgcc (6.4.0-r9)
(8/12) Installing mpfr3 (3.1.5-r1)
(9/12) Installing mpc1 (1.0.3-r1)
(10/12) Installing libstdc++ (6.4.0-r9)
(11/12) Installing gcc (6.4.0-r9)
(12/12) Installing musl-dev (1.1.19-r10)
Executing busybox-1.28.4-r1.trigger
OK: 113 MiB in 32 packages
 ---&amp;gt; 0e7a97e577dc
Step 4/12 : ADD . /app/
 ---&amp;gt; 72cfd4dea99b
Step 5/12 : RUN go get -d -v ./... &amp;amp;&amp;amp; go build -o main . &amp;amp;&amp;amp; chown -R app:app /app /home/app
 ---&amp;gt; Running in 4482bfd3e8f7
go: finding github.com/gorilla/websocket v1.4.0
go: finding github.com/nlopes/slack v0.4.0
go: finding github.com/pkg/errors v0.8.0
go: downloading github.com/nlopes/slack v0.4.0
go: downloading github.com/pkg/errors v0.8.0
go: downloading github.com/gorilla/websocket v1.4.0
 ---&amp;gt; 8ea604c7fb37
Step 6/12 : FROM golang:1.11.2-alpine
 ---&amp;gt; 57915f96905a
Step 7/12 : WORKDIR /app
 ---&amp;gt; Using cache
 ---&amp;gt; e04488a7f16b
Step 8/12 : RUN adduser -D -g &#39;app&#39; app &amp;amp;&amp;amp;     chown -R app:app /app
 ---&amp;gt; Using cache
 ---&amp;gt; 33b206dba7e4
Step 9/12 : COPY --from=builder --chown=app /app/health_check.sh /app/health_check.sh
 ---&amp;gt; Using cache
 ---&amp;gt; 34d3cd1a5bb0
Step 10/12 : COPY --from=builder --chown=app /app/main /app/main
 ---&amp;gt; Using cache
 ---&amp;gt; 0c3d838b25dc
Step 11/12 : USER app
 ---&amp;gt; Using cache
 ---&amp;gt; 95c2bf90800c
Step 12/12 : CMD [&amp;quot;/app/main&amp;quot;]
 ---&amp;gt; Using cache
 ---&amp;gt; 3541257ff16c
Successfully built 3541257ff16c
Successfully tagged 1fca8a8c999a8cd9b943456b70d90807:latest
The push refers to repository [docker.io/kainlite/echobot]
ee06a8f42495: Preparing
12468476a0ef: Preparing
ec122f36b39d: Preparing
e94f3271cc73: Preparing
93391cb9fd4b: Preparing
cb9d0f9550f6: Preparing
93448d8c2605: Preparing
c54f8a17910a: Preparing
df64d3292fd6: Preparing
cb9d0f9550f6: Waiting
c54f8a17910a: Waiting
93448d8c2605: Waiting
e94f3271cc73: Layer already exists
93391cb9fd4b: Layer already exists
12468476a0ef: Layer already exists
ec122f36b39d: Layer already exists
ee06a8f42495: Layer already exists
93448d8c2605: Layer already exists
cb9d0f9550f6: Layer already exists
df64d3292fd6: Layer already exists
c54f8a17910a: Layer already exists
fc03e3d-dirty-3541257: digest: sha256:99c6d3d5b226a1947e8f96c0a5f963c8e499848d271f121ad50551046a0dc7ca size: 2197
Build complete in 48.642618413s
Starting test...
Test complete in 9.15µs
kainlite/echobot -&amp;gt; kainlite/echobot:fc03e3d-dirty-3541257
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As we can see skaffold build not only did the docker build but also tagged and pushed the image to &lt;a href=&#34;https://cloud.docker.com/repository/docker/kainlite/echobot/tags&#34;&gt;docker hub&lt;/a&gt;, which is really nice and really useful to build a CI/CD system with it.&lt;/p&gt;

&lt;p&gt;But wait, we need to deploy that to our cluster, right on:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ skaffold deploy
Starting build...
Building [kainlite/echobot]...
Sending build context to Docker daemon  66.56kB
Step 1/12 : FROM golang:1.11.2-alpine as builder
 ---&amp;gt; 57915f96905a
Step 2/12 : WORKDIR /app
 ---&amp;gt; Using cache
 ---&amp;gt; e04488a7f16b
Step 3/12 : RUN adduser -D -g &#39;app&#39; app &amp;amp;&amp;amp;     chown -R app:app /app &amp;amp;&amp;amp;     apk add git &amp;amp;&amp;amp; apk add gcc musl-dev
 ---&amp;gt; Using cache
 ---&amp;gt; 0e7a97e577dc
Step 4/12 : ADD . /app/
 ---&amp;gt; Using cache
 ---&amp;gt; 72cfd4dea99b
Step 5/12 : RUN go get -d -v ./... &amp;amp;&amp;amp; go build -o main . &amp;amp;&amp;amp; chown -R app:app /app /home/app
 ---&amp;gt; Using cache
 ---&amp;gt; 8ea604c7fb37
Step 6/12 : FROM golang:1.11.2-alpine
 ---&amp;gt; 57915f96905a
Step 7/12 : WORKDIR /app
 ---&amp;gt; Using cache
 ---&amp;gt; e04488a7f16b
Step 8/12 : RUN adduser -D -g &#39;app&#39; app &amp;amp;&amp;amp;     chown -R app:app /app
 ---&amp;gt; Using cache
 ---&amp;gt; 33b206dba7e4
Step 9/12 : COPY --from=builder --chown=app /app/health_check.sh /app/health_check.sh
 ---&amp;gt; Using cache
 ---&amp;gt; 34d3cd1a5bb0
Step 10/12 : COPY --from=builder --chown=app /app/main /app/main
 ---&amp;gt; Using cache
 ---&amp;gt; 0c3d838b25dc
Step 11/12 : USER app
 ---&amp;gt; Using cache
 ---&amp;gt; 95c2bf90800c
Step 12/12 : CMD [&amp;quot;/app/main&amp;quot;]
 ---&amp;gt; Using cache
 ---&amp;gt; 3541257ff16c
Successfully built 3541257ff16c
Successfully tagged 510226574761304cc9d64a343d5bdbff:latest
The push refers to repository [docker.io/kainlite/echobot]
ee06a8f42495: Preparing
12468476a0ef: Preparing
ec122f36b39d: Preparing
e94f3271cc73: Preparing
93391cb9fd4b: Preparing
cb9d0f9550f6: Preparing
93448d8c2605: Preparing
c54f8a17910a: Preparing
df64d3292fd6: Preparing
cb9d0f9550f6: Waiting
93448d8c2605: Waiting
c54f8a17910a: Waiting
df64d3292fd6: Waiting
12468476a0ef: Layer already exists
e94f3271cc73: Layer already exists
cb9d0f9550f6: Layer already exists
ec122f36b39d: Layer already exists
93391cb9fd4b: Layer already exists
ee06a8f42495: Layer already exists
c54f8a17910a: Layer already exists
df64d3292fd6: Layer already exists
93448d8c2605: Mounted from library/golang
fc03e3d-dirty-3541257: digest: sha256:99c6d3d5b226a1947e8f96c0a5f963c8e499848d271f121ad50551046a0dc7ca size: 2197
Build complete in 15.136865292s
Starting test...
Test complete in 17.912µs
Starting deploy...
kubectl client version: 1.10
kubectl version 1.12.0 or greater is recommended for use with skaffold
deployment.extensions &amp;quot;echobot&amp;quot; configured
Deploy complete in 5.676513226s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Deploy does a lot like with gitkube, it build the image, pushes it to the registry and then makes the deployment to the cluster, as you can see in there skaffold relies on kubectl and I have an old version of it.&lt;/p&gt;

&lt;p&gt;After a few seconds we can see that our deployment has been triggered and we have a new pod being created for it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ kubectl get pods
NAME                       READY     STATUS              RESTARTS   AGE
echobot-57fdcccf76-4qwvq   0/1       ContainerCreating   0          5s
echobot-6fcd78658c-njvpx   0/1       Terminating         0          9m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Skaffold also has another nice option that it&amp;rsquo;s called &lt;em&gt;dev&lt;/em&gt; it watches the folder for changes and re-deploys the app so you can focus on code.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s clean up and call it a day:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;$ skaffold delete
Cleaning up...
deployment.extensions &amp;quot;echobot&amp;quot; deleted
Cleanup complete in 3.833219278s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;

&lt;p&gt;I really liked the workflow that skaffold provides, I hope that I can use it some more in the near future. And remember to shutdown the kubernetes cluster if you are using Digital Ocean so you don&amp;rsquo;t get charged by surprise later on.&lt;/p&gt;

&lt;h3 id=&#34;errata&#34;&gt;Errata&lt;/h3&gt;

&lt;p&gt;If you spot any error or have any suggestion, please send me a message so it gets fixed.&lt;/p&gt;

&lt;p&gt;Also, you can check the source code and changes in the &lt;a href=&#34;https://github.com/kainlite/kainlite.github.io&#34;&gt;generated code&lt;/a&gt; and the &lt;a href=&#34;https://github.com/kainlite/blog&#34;&gt;sources here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploying my apps with Helm</title>
      <link>https://kainlite.github.io/blog/deploying_my_apps_with_helm/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kainlite.github.io/blog/deploying_my_apps_with_helm/</guid>
      <description>

&lt;h3 id=&#34;deploying-my-apps-with-helm&#34;&gt;&lt;strong&gt;Deploying my apps with Helm&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;If you are already familiar with &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt;, and the different types of kubernetes workloads / resource types you might be wondering how to install apps directly to kubernetes, yes, you don&amp;rsquo;t have to re-invent the wheel for your mysql installation, or your postgres, or nginx, jenkins, You name it. Helm solves that problem with &lt;a href=&#34;https://github.com/helm/charts&#34;&gt;Charts&lt;/a&gt;, this list has the official charts maintained by the community, where the folder incubator may refer to charts that are still not compliant with the &lt;a href=&#34;https://github.com/helm/charts/blob/master/CONTRIBUTING.md#technical-requirements&#34;&gt;technical requirements&lt;/a&gt; but probably usable and the folder stable is for &lt;em&gt;graduated&lt;/em&gt; charts. This is not the only source of charts as you can imagine, You can use any source for your charts, even just the &lt;a href=&#34;https://docs.helm.sh/using_helm/#helm-install-installing-a-package&#34;&gt;tgz&lt;/a&gt; files, as we will see in this post.&lt;/p&gt;

&lt;p&gt;How do I search for charts?:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm search wordpress
NAME                    CHART VERSION   APP VERSION     DESCRIPTION
stable/wordpress        3.3.0           4.9.8           Web publishing platform for building blogs and websites.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that I&amp;rsquo;m not a fan of Wordpress or PHP itself, but it seems like the most common example everywhere. As we can see here it says stable/wordpress so we know that we&amp;rsquo;re using the official repo in the folder stable, but what if we don&amp;rsquo;t want that chart, but someone else provides one with more features or something that You like better. Let&amp;rsquo;s use the one from &lt;a href=&#34;https://bitnami.com/stack/wordpress/helm&#34;&gt;Bitnami&lt;/a&gt;, so if we check their page you can select different kind of deployments but for it to work we need to add another external repo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So if we search again we will now see two options (at the moment of this writing, the latest version is actually 5.0.2):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm search wordpress
NAME                    CHART VERSION   APP VERSION     DESCRIPTION
bitnami/wordpress       5.0.2           5.0.2           Web publishing platform for building blogs and websites.
stable/wordpress        3.3.0           4.9.8           Web publishing platform for building blogs and websites.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s check the &lt;a href=&#34;https://github.com/helm/charts/tree/master/stable/wordpress&#34;&gt;documentation&lt;/a&gt; of the chart to create our &lt;code&gt;values.yaml&lt;/code&gt; file, note that in this example the stable wordpress chart it&amp;rsquo;s also maintained by Bitnami, so they have the same configuration :), this won&amp;rsquo;t always be the case but it simplifies things for us.&lt;/p&gt;

&lt;p&gt;Our example &lt;code&gt;values.yaml&lt;/code&gt; will look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wordpressBlogName: &amp;quot;Testing Helm Charts&amp;quot;
persistence:
  size: 1Gi
ingress:
  enabled: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will only change the blog name by default, the persistent volume size and also enable &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;ingress&lt;/a&gt; (Our app should be available through &lt;code&gt;wordpress.local&lt;/code&gt; inside the cluster), if you are using minikube be sure to enable the &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;ingress&lt;/a&gt; addon.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ minikube addons enable ingress
ingress was successfully enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then install &lt;code&gt;stable/wordpress&lt;/code&gt; or &lt;code&gt;bitnami/wordpress&lt;/code&gt;, we will follow up with the one from Bitnami repo.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm install bitnami/wordpress \
--set image.repository=bitnami/wordpress \
--set image.tag=5.0.2 \
-f values.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As it&amp;rsquo;s a common good practice to use specific versions we will do it here, it&amp;rsquo;s better to do it this way because you can easily move between known versions and also avoid unknown states, this can happen by misunderstanding what latest means, &lt;a href=&#34;https://medium.com/@mccode/the-misunderstood-docker-tag-latest-af3babfd6375&#34;&gt;follow the example&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You should see something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;NAME:   plucking-condor
LAST DEPLOYED: Mon Dec 24 13:06:38 2018
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
==&amp;gt; v1/Pod(related)
NAME                                        READY  STATUS             RESTARTS  AGE
plucking-condor-wordpress-84845db8b5-hkqhc  0/1    ContainerCreating  0         0s
plucking-condor-mariadb-0                   0/1    Pending            0         0s

==&amp;gt; v1/Secret

NAME                       AGE
plucking-condor-mariadb    0s
plucking-condor-wordpress  0s

==&amp;gt; v1/ConfigMap
plucking-condor-mariadb        0s
plucking-condor-mariadb-tests  0s

==&amp;gt; v1/PersistentVolumeClaim
plucking-condor-wordpress  0s

==&amp;gt; v1/Service
plucking-condor-mariadb    0s
plucking-condor-wordpress  0s

==&amp;gt; v1beta1/Deployment
plucking-condor-wordpress  0s

==&amp;gt; v1beta1/StatefulSet
plucking-condor-mariadb  0s

==&amp;gt; v1beta1/Ingress
wordpress.local-plucking-condor  0s


NOTES:
1. Get the WordPress URL:

  You should be able to access your new WordPress installation through
  http://wordpress.local/admin

2. Login with the following credentials to see your blog

  echo Username: user
  echo Password: $(kubectl get secret --namespace default plucking-condor-wordpress -o jsonpath=&amp;quot;{.data.wordpress-password}&amp;quot; | base64 --decode)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Depending on the cluster provider or installation itself, you might need to replace the &lt;code&gt;persistence.storageClass&lt;/code&gt; to match what your cluster has, note that in the values file is represented like JSON with dot notation but in your &lt;code&gt;values.yaml&lt;/code&gt; you need to stick to YAML format and indent &lt;code&gt;storageClass&lt;/code&gt; under persistence as usual, the kubernetes API parses and uses JSON but YAML seems more human friendly.&lt;/p&gt;

&lt;p&gt;At this point we should a working wordpress installation, also move between versions, but be aware that the application is in charge of the database schema and updating it to match what the new version needs, this can also be troublesome rolling back or when downgrading, so if you use persistent data &lt;em&gt;ALWAYS&lt;/em&gt; have a working backup, because when things go south, you will want to quickly go back to a known state, also note that I said &amp;ldquo;working backup&amp;rdquo;, yes, test that the backup works and that You can restore it somewhere else before doing anything destructive or that can has repercussions, this will bring you peace of mind and better ways to organize yourself while upgrading, etc.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s check that all resources are indeed working and that we can use our recently installed app.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl get all
NAME                                             READY     STATUS        RESTARTS   AGE
pod/plucking-condor-mariadb-0                    1/1       Running       0          12m
pod/plucking-condor-wordpress-84845db8b5-hkqhc   1/1       Running       0          12m

NAME                                TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE
service/kubernetes                  ClusterIP      10.96.0.1        &amp;lt;none&amp;gt;           443/TCP                      37h
service/plucking-condor-mariadb     ClusterIP      10.106.219.59    &amp;lt;none&amp;gt;           3306/TCP                     12m
service/plucking-condor-wordpress   LoadBalancer   10.100.239.163   10.100.239.163   80:31764/TCP,443:32308/TCP   12m

NAME                                        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/plucking-condor-wordpress   1         1         1            1           12m

NAME                                                   DESIRED   CURRENT   READY     AGE
replicaset.apps/plucking-condor-wordpress-84845db8b5   1         1         1         12m

NAME                                       DESIRED   CURRENT   AGE
statefulset.apps/plucking-condor-mariadb   1         1         12m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can deploy it to a custom namespace (In this case I deployed it to the default namespace), the only change for that would be to set the parameter &lt;code&gt;--namespace&lt;/code&gt; in the &lt;code&gt;helm install&lt;/code&gt; line.&lt;/p&gt;

&lt;p&gt;If you use minikube then ingress will expose a nodeport that we can find using &lt;code&gt;minikube service list&lt;/code&gt; then using the browser or curl to navigate our freshly installed wordpress.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; $ minikube service list
|-------------|---------------------------|--------------------------------|
|  NAMESPACE  |           NAME            |              URL               |
|-------------|---------------------------|--------------------------------|
| default     | kubernetes                | No node port                   |
| default     | plucking-condor-mariadb   | No node port                   |
| default     | plucking-condor-wordpress | http://192.168.99.100:31764    |
|             |                           | http://192.168.99.100:32308    |
| kube-system | default-http-backend      | http://192.168.99.100:30001    |
| kube-system | kube-dns                  | No node port                   |
| kube-system | kubernetes-dashboard      | No node port                   |
| kube-system | tiller-deploy             | No node port                   |
|-------------|---------------------------|--------------------------------|
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the cloud or on premises this will indeed be different and you should have a publicly available installation using your own domain name (In this case http is at: &lt;a href=&#34;http://192.168.99.100:31764&#34;&gt;http://192.168.99.100:31764&lt;/a&gt; and https at: &lt;a href=&#34;http://192.168.99.100:32308&#34;&gt;http://192.168.99.100:32308&lt;/a&gt;, and &lt;a href=&#34;http://192.168.99.100:30001&#34;&gt;http://192.168.99.100:30001&lt;/a&gt; is the default backend for the ingress controller), your ips can be different but the basics are the same.&lt;/p&gt;

&lt;p&gt;Sample screenshot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kainlite.github.io/img/wordpress-example.png&#34; alt=&#34;Wordpress example&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;

&lt;p&gt;As long as we have the &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;persistent volume&lt;/a&gt; our data should be preserved in this case the PV is used for tha database, but we could add another volume to preserve images, etc.&lt;/p&gt;

&lt;p&gt;Clean everything up:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm del --purge plucking-condor
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s all I have for now, I will be adding more content next week.&lt;/p&gt;

&lt;h3 id=&#34;don-t-repeat-yourself&#34;&gt;Don&amp;rsquo;t Repeat Yourself&lt;/h3&gt;

&lt;p&gt;DRY is a good design goal and part of the art of a good template is knowing when to add a new template and when to update or use an existing one. While helm and go helps with that, there is no perfect tool so we will explore other options in the following posts, explore what the community provides and what seems like a suitable tool for you. Happy Helming!.&lt;/p&gt;

&lt;h3 id=&#34;upcoming-topics&#34;&gt;Upcoming topics&lt;/h3&gt;

&lt;p&gt;The following posts will be about package managers, development deployment tools, etc. It&amp;rsquo;s hard to put all the tools in a category, but they are trying to solve similar problems in different ways, and we will be exploring the ones that seem more promising to me, if you would like me to cover any other tool/project/whatever, just send me a message :)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Getting started with Ksonnet and friends.&lt;/li&gt;
&lt;li&gt;Getting started with Skaffold.&lt;/li&gt;
&lt;li&gt;Getting started with Gitkube.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;errata&#34;&gt;Errata&lt;/h3&gt;

&lt;p&gt;If you spot any error or have any suggestion, please send me a message so it gets fixed.&lt;/p&gt;

&lt;p&gt;Also you can check the source code and changes in the &lt;a href=&#34;https://github.com/kainlite/kainlite.github.io&#34;&gt;generated code&lt;/a&gt; and the &lt;a href=&#34;https://github.com/kainlite/blog&#34;&gt;sources here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting started with Helm</title>
      <link>https://kainlite.github.io/blog/getting_started_with_helm/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kainlite.github.io/blog/getting_started_with_helm/</guid>
      <description>

&lt;h3 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;This tutorial will show you how to create a simple chart and also how to deploy it to kubernetes using &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt;, in the examples I will be using &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-minikube&#34;&gt;minikube&lt;/a&gt; or you can &lt;a href=&#34;https://github.com/kainlite/kainlite.github.io&#34;&gt;check out this repo&lt;/a&gt; that has a good overview of minikube, once installed and started (&lt;code&gt;minikube start&lt;/code&gt;) that command will download and configure the local environment, you can follow with the following example:&lt;/p&gt;

&lt;p&gt;Create the chart:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm create hello-world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Always use valid DNS names if you are going to have services, otherwise you will have issues later on.&lt;/p&gt;

&lt;p&gt;Inspect the contents, as you will notice every resource is just a kubernetes resource with some placeholders and basic logic to get something more reusable:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd hello-world

charts       &amp;lt;--- Dependencies, charts that your chart depends on.
Chart.yaml   &amp;lt;--- Metadata mostly, defines the version of your chart, etc.
templates    &amp;lt;--- Here is where the magic happens.
values.yaml  &amp;lt;--- Default values file (this is used to replace in the templates at runtime)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note: the following link explains the basics of &lt;a href=&#34;https://docs.helm.sh/developing_charts/#managing-dependencies-manually-via-the-charts-directory&#34;&gt;dependencies&lt;/a&gt;, your chart can have as many dependencies as you need, the only thing that you need to do is add or install the other charts as dependencies.&lt;/p&gt;

&lt;p&gt;The file &lt;code&gt;values.yaml&lt;/code&gt; by default will look like the following snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;replicaCount: 1

image:
  repository: nginx
  tag: stable
  pullPolicy: IfNotPresent

nameOverride: &amp;quot;&amp;quot;
fullnameOverride: &amp;quot;&amp;quot;

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: &amp;quot;true&amp;quot;
  path: /
  hosts:
    - chart-example.local
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
nodeSelector: {}
tolerations: []
affinity: {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next step would be to check the &lt;code&gt;templates&lt;/code&gt; folder:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;deployment.yaml  &amp;lt;--- Standard kubernetes deployment with go templates variables.
_helpers.tpl     &amp;lt;--- This file defines some common variables.
ingress.yaml     &amp;lt;--- Ingress route, etc.
NOTES.txt        &amp;lt;--- Once deployed this file will display the details of our deployment, usually login data, how to connect, etc.
service.yaml     &amp;lt;--- The service that we will use internally and/or via ingress to reach our deployed service.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Go &lt;a href=&#34;https://blog.gopheracademy.com/advent-2017/using-go-templates/&#34;&gt;templates&lt;/a&gt; basics, if you need a refresher or a crash course in go templates, also always be sure to check Helm&amp;rsquo;s own &lt;a href=&#34;https://github.com/helm/helm/blob/master/docs/chart_template_guide/functions_and_pipelines.md&#34;&gt;documentation&lt;/a&gt; and also some &lt;a href=&#34;https://github.com/helm/helm/blob/master/docs/charts_tips_and_tricks.md&#34;&gt;tips and tricks&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check the &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;deployment&lt;/a&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: {{ include &amp;quot;hello-world.fullname&amp;quot; . }}
  labels:
    app.kubernetes.io/name: {{ include &amp;quot;hello-world.name&amp;quot; . }}
    helm.sh/chart: {{ include &amp;quot;hello-world.chart&amp;quot; . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include &amp;quot;hello-world.name&amp;quot; . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include &amp;quot;hello-world.name&amp;quot; . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      containers:
        - name: {{ .Chart.Name }}
          image: &amp;quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&amp;quot;
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
{{ toYaml .Values.resources | indent 12 }}
    {{- with .Values.nodeSelector }}
      nodeSelector:
{{ toYaml . | indent 8 }}
    {{- end }}
    {{- with .Values.affinity }}
      affinity:
{{ toYaml . | indent 8 }}
    {{- end }}
    {{- with .Values.tolerations }}
      tolerations:
{{ toYaml . | indent 8 }}
    {{- end }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see everything will get replaced by what you define in the &lt;code&gt;values.yaml&lt;/code&gt; file and everything is under &lt;code&gt;.Values&lt;/code&gt; unless you define a local variable or some other variable using helpers for example.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check the &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34;&gt;service&lt;/a&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: {{ include &amp;quot;hello-world.fullname&amp;quot; . }}
  labels:
    app.kubernetes.io/name: {{ include &amp;quot;hello-world.name&amp;quot; . }}
    helm.sh/chart: {{ include &amp;quot;hello-world.chart&amp;quot; . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: {{ include &amp;quot;hello-world.name&amp;quot; . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s check the &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;ingress&lt;/a&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{{- if .Values.ingress.enabled -}}
{{- $fullName := include &amp;quot;hello-world.fullname&amp;quot; . -}}
{{- $ingressPath := .Values.ingress.path -}}
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: {{ $fullName }}
  labels:
    app.kubernetes.io/name: {{ include &amp;quot;hello-world.name&amp;quot; . }}
    helm.sh/chart: {{ include &amp;quot;hello-world.chart&amp;quot; . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
{{- with .Values.ingress.annotations }}
  annotations:
{{ toYaml . | indent 4 }}
{{- end }}
spec:
{{- if .Values.ingress.tls }}
  tls:
  {{- range .Values.ingress.tls }}
    - hosts:
      {{- range .hosts }}
        - {{ . | quote }}
      {{- end }}
      secretName: {{ .secretName }}
  {{- end }}
{{- end }}
  rules:
  {{- range .Values.ingress.hosts }}
    - host: {{ . | quote }}
      http:
        paths:
          - path: {{ $ingressPath }}
            backend:
              serviceName: {{ $fullName }}
              servicePort: http
  {{- end }}
{{- end }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The ingress file is one of the most interesting ones in my humble opinion because it has a if else example and also local variables (&lt;code&gt;$fullName&lt;/code&gt; for example), also iterates over a possible slice of dns record names (hosts), and the same if you have certs for them (a good way to get let&amp;rsquo;s encrypt certificates automatically is using cert-manager, in the next post I will expand on this example adding a basic web app with mysql and ssl/tls).&lt;/p&gt;

&lt;p&gt;After checking that everything is up to our needs the only thing missing is to finally deploy it to kubernetes (But first let&amp;rsquo;s install tiller):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm init
$HELM_HOME has been configured at /home/gabriel/.helm.

Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.

Please note: by default, Tiller is deployed with an insecure &#39;allow unauthenticated users&#39; policy.
To prevent this, run `helm init` with the --tiller-tls-verify flag.
For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation
Happy Helming!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that many of the complains that Helm receives are because of the admin-y capabilities that Tiller has. A good note on the security issues that Tiller can suffer and some possible mitigation alternatives can be found on the &lt;a href=&#34;https://engineering.bitnami.com/articles/helm-security.html&#34;&gt;Bitnami page&lt;/a&gt;, this mostly applies to multi-tenant clusters. And also be sure to check &lt;a href=&#34;https://docs.helm.sh/using_helm/#securing-your-helm-installation&#34;&gt;Securing Helm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Deploy our chart:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm install --name my-nginx -f values.yaml .
NAME:   my-nginx
LAST DEPLOYED: Sun Dec 23 00:30:11 2018
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
==&amp;gt; v1/Service
NAME                  AGE
my-nginx-hello-world  0s

==&amp;gt; v1beta2/Deployment
my-nginx-hello-world  0s

==&amp;gt; v1/Pod(related)

NAME                                   READY  STATUS   RESTARTS  AGE
my-nginx-hello-world-6f948db8d5-s76zl  0/1    Pending  0         0s

NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l &amp;quot;app.kubernetes.io/name=hello-world,app.kubernetes.io/instance=my-nginx&amp;quot; -o jsonpath=&amp;quot;{.items[0].metadata.name}&amp;quot;)
  echo &amp;quot;Visit http://127.0.0.1:8080 to use your application&amp;quot;
  kubectl port-forward $POD_NAME 8080:80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our deployment was successful and we can see that our pod is waiting to be scheduled.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check that our service is there:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl get services
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes             ClusterIP   10.96.0.1       &amp;lt;none&amp;gt;        443/TCP   1h
my-nginx-hello-world   ClusterIP   10.111.222.70   &amp;lt;none&amp;gt;        80/TCP    5m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now we can test that everything is okay by running another pod in interactive mode, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl run -i --tty alpine --image=alpine -- sh
If you don&#39;t see a command prompt, try pressing enter.

/ # apk add curl
fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz
(1/5) Installing ca-certificates (20171114-r3)
(2/5) Installing nghttp2-libs (1.32.0-r0)
(3/5) Installing libssh2 (1.8.0-r3)
(4/5) Installing libcurl (7.61.1-r1)
(5/5) Installing curl (7.61.1-r1)
Executing busybox-1.28.4-r2.trigger
Executing ca-certificates-20171114-r3.trigger
OK: 6 MiB in 18 packages

/ # curl -v my-nginx-hello-world
* Rebuilt URL to: my-nginx-hello-world/
*   Trying 10.111.222.70...
* TCP_NODELAY set
* Connected to my-nginx-hello-world (10.111.222.70) port 80 (#0)
&amp;gt; GET / HTTP/1.1
&amp;gt; Host: my-nginx-hello-world
&amp;gt; User-Agent: curl/7.61.1
&amp;gt; Accept: */*
&amp;gt;
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Server: nginx/1.14.2
&amp;lt; Date: Sun, 23 Dec 2018 03:45:31 GMT
&amp;lt; Content-Type: text/html
&amp;lt; Content-Length: 612
&amp;lt; Last-Modified: Tue, 04 Dec 2018 14:44:49 GMT
&amp;lt; Connection: keep-alive
&amp;lt; ETag: &amp;quot;5c0692e1-264&amp;quot;
&amp;lt; Accept-Ranges: bytes
&amp;lt;
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&amp;lt;style&amp;gt;
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;p&amp;gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&amp;lt;/p&amp;gt;

&amp;lt;p&amp;gt;For online documentation and support please refer to
&amp;lt;a href=&amp;quot;http://nginx.org/&amp;quot;&amp;gt;nginx.org&amp;lt;/a&amp;gt;.&amp;lt;br/&amp;gt;
Commercial support is available at
&amp;lt;a href=&amp;quot;http://nginx.com/&amp;quot;&amp;gt;nginx.com&amp;lt;/a&amp;gt;.&amp;lt;/p&amp;gt;

&amp;lt;p&amp;gt;&amp;lt;em&amp;gt;Thank you for using nginx.&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
* Connection #0 to host my-nginx-hello-world left intact
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And voila we see our nginx deployed there and accessible via service name to our other pods (this is fantastic for microservices).&lt;/p&gt;

&lt;p&gt;Our current deployment can be checked like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm ls
NAME            REVISION        UPDATED                         STATUS          CHART                   APP VERSION     NAMESPACE
my-nginx        1               Sun Dec 23 00:30:11 2018        DEPLOYED        hello-world-0.1.0       1.0             default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last example would be to upgrade our deployment, lets change the &lt;code&gt;tag&lt;/code&gt; in the &lt;code&gt;values.yaml&lt;/code&gt; file from &lt;code&gt;stable&lt;/code&gt; to &lt;code&gt;mainline&lt;/code&gt; and update also the metadata file (&lt;code&gt;Chart.yaml&lt;/code&gt;) to let Helm know that this is a new version of our chart.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; $ helm upgrade my-nginx . -f values.yaml
Release &amp;quot;my-nginx&amp;quot; has been upgraded. Happy Helming!
LAST DEPLOYED: Sun Dec 23 00:55:22 2018
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
==&amp;gt; v1/Pod(related)
NAME                                   READY  STATUS             RESTARTS  AGE
my-nginx-hello-world-6f948db8d5-s76zl  1/1    Running            0         25m
my-nginx-hello-world-c5cdcc95c-shgc6   0/1    ContainerCreating  0         0s

==&amp;gt; v1/Service

NAME                  AGE
my-nginx-hello-world  25m

==&amp;gt; v1beta2/Deployment
my-nginx-hello-world  25m


NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l &amp;quot;app.kubernetes.io/name=hello-world,app.kubernetes.io/instance=my-nginx&amp;quot; -o jsonpath=&amp;quot;{.items[0].metadata.name}&amp;quot;)
  echo &amp;quot;Visit http://127.0.0.1:8080 to use your application&amp;quot;
  kubectl port-forward $POD_NAME 8080:80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that I always specify the -f values.yaml just for explicitness.&lt;/p&gt;

&lt;p&gt;It seems that our upgrade went well, let&amp;rsquo;s see what Helm sees&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm ls
NAME            REVISION        UPDATED                         STATUS          CHART                   APP VERSION     NAMESPACE
my-nginx        2               Sun Dec 23 00:55:22 2018        DEPLOYED        hello-world-0.1.1       1.0             default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But before we go let&amp;rsquo;s validate that it did deployed the nginx version that we wanted to have:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec my-nginx-hello-world-c5cdcc95c-shgc6 -- /usr/sbin/nginx -v
nginx version: nginx/1.15.7
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the moment of this writing mainline is 1.15.7, we could rollback to the previous version by doing:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm rollback my-nginx 1
Rollback was a success! Happy Helming!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Basically this command needs a deployment name &lt;code&gt;my-nginx&lt;/code&gt; and the revision number to rollback to in this case &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check the versions again:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec my-nginx-hello-world-6f948db8d5-bsml2 -- /usr/sbin/nginx -v
nginx version: nginx/1.14.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s clean up:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm del --purge my-nginx
release &amp;quot;my-nginx&amp;quot; deleted
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you need to see what will be sent to the kubernetes API then you can use the following command (sometimes it&amp;rsquo;s really useful for debugging or to inject a sidecar using pipes):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm template . -name my-nginx -f values.yaml
# Source: hello-world/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ame-hello-world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that folks is all I have for now, be sure to check own &lt;a href=&#34;https://docs.helm.sh/&#34;&gt;Helm Documentation&lt;/a&gt; and &lt;code&gt;helm help&lt;/code&gt; to know more about what helm can do to help you deploy your applications to any kubernetes cluster.&lt;/p&gt;

&lt;h3 id=&#34;don-t-repeat-yourself&#34;&gt;Don&amp;rsquo;t Repeat Yourself&lt;/h3&gt;

&lt;p&gt;DRY is a good design goal and part of the art of a good template is knowing when to add a new template and when to update an existing one. While you&amp;rsquo;re figuring that out, accept that you&amp;rsquo;ll be doing some refactoring. Helm and go makes that easy and fast.&lt;/p&gt;

&lt;h3 id=&#34;upcoming-topics&#34;&gt;Upcoming topics&lt;/h3&gt;

&lt;p&gt;The following posts will be about package managers, development deployment tools, etc. It&amp;rsquo;s hard to put all the tools in a category, but they are trying to solve similar problems in different ways, and we will be exploring the ones that seem more promising to me, if you would like me to cover any other tool/project/whatever, just send me a message :)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kainlite.github.io/blog/deploying_my_apps_with_helm/&#34;&gt;Expand on helm, search and install community charts&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kainlite.github.io/blog/getting_started_with_ksonnet/&#34;&gt;Getting started with Ksonnet and friends&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Getting started with Skaffold.&lt;/li&gt;
&lt;li&gt;Getting started with Gitkube.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;errata&#34;&gt;Errata&lt;/h3&gt;

&lt;p&gt;If you spot any error or have any suggestion, please send me a message so it gets fixed.&lt;/p&gt;

&lt;p&gt;Also you can check the source code and changes in the &lt;a href=&#34;https://github.com/kainlite/kainlite.github.io&#34;&gt;generated code&lt;/a&gt; and the &lt;a href=&#34;https://github.com/kainlite/blog&#34;&gt;sources here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
